{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pycaret.regression import *\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split, validation_curve, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Datas/data_frame_florian.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>count</th>\n",
       "      <th>heure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  holiday  workingday  weather  temp  humidity  windspeed  count  \\\n",
       "0       1        0           0        1  9.84        81        0.0     16   \n",
       "1       1        0           0        1  9.02        80        0.0     40   \n",
       "2       1        0           0        1  9.02        80        0.0     32   \n",
       "3       1        0           0        1  9.84        75        0.0     13   \n",
       "4       1        0           0        1  9.84        75        0.0      1   \n",
       "\n",
       "   heure  \n",
       "0      0  \n",
       "1      1  \n",
       "2      2  \n",
       "3      3  \n",
       "4      4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_13afd_row42_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_13afd_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_13afd_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_13afd_row0_col1\" class=\"data row0 col1\" >1554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_13afd_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_13afd_row1_col1\" class=\"data row1 col1\" >count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_13afd_row2_col0\" class=\"data row2 col0\" >Original Data</td>\n",
       "      <td id=\"T_13afd_row2_col1\" class=\"data row2 col1\" >(10886, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_13afd_row3_col0\" class=\"data row3 col0\" >Missing Values</td>\n",
       "      <td id=\"T_13afd_row3_col1\" class=\"data row3 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_13afd_row4_col0\" class=\"data row4 col0\" >Numeric Features</td>\n",
       "      <td id=\"T_13afd_row4_col1\" class=\"data row4 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_13afd_row5_col0\" class=\"data row5 col0\" >Categorical Features</td>\n",
       "      <td id=\"T_13afd_row5_col1\" class=\"data row5 col1\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_13afd_row6_col0\" class=\"data row6 col0\" >Ordinal Features</td>\n",
       "      <td id=\"T_13afd_row6_col1\" class=\"data row6 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_13afd_row7_col0\" class=\"data row7 col0\" >High Cardinality Features</td>\n",
       "      <td id=\"T_13afd_row7_col1\" class=\"data row7 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_13afd_row8_col0\" class=\"data row8 col0\" >High Cardinality Method</td>\n",
       "      <td id=\"T_13afd_row8_col1\" class=\"data row8 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_13afd_row9_col0\" class=\"data row9 col0\" >Transformed Train Set</td>\n",
       "      <td id=\"T_13afd_row9_col1\" class=\"data row9 col1\" >(7620, 14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_13afd_row10_col0\" class=\"data row10 col0\" >Transformed Test Set</td>\n",
       "      <td id=\"T_13afd_row10_col1\" class=\"data row10 col1\" >(3266, 14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_13afd_row11_col0\" class=\"data row11 col0\" >Shuffle Train-Test</td>\n",
       "      <td id=\"T_13afd_row11_col1\" class=\"data row11 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_13afd_row12_col0\" class=\"data row12 col0\" >Stratify Train-Test</td>\n",
       "      <td id=\"T_13afd_row12_col1\" class=\"data row12 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_13afd_row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_13afd_row13_col1\" class=\"data row13 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_13afd_row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
       "      <td id=\"T_13afd_row14_col1\" class=\"data row14 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_13afd_row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_13afd_row15_col1\" class=\"data row15 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_13afd_row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
       "      <td id=\"T_13afd_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_13afd_row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_13afd_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_13afd_row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_13afd_row18_col1\" class=\"data row18 col1\" >reg-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_13afd_row19_col0\" class=\"data row19 col0\" >USI</td>\n",
       "      <td id=\"T_13afd_row19_col1\" class=\"data row19 col1\" >d0f2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_13afd_row20_col0\" class=\"data row20 col0\" >Imputation Type</td>\n",
       "      <td id=\"T_13afd_row20_col1\" class=\"data row20 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_13afd_row21_col0\" class=\"data row21 col0\" >Iterative Imputation Iteration</td>\n",
       "      <td id=\"T_13afd_row21_col1\" class=\"data row21 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_13afd_row22_col0\" class=\"data row22 col0\" >Numeric Imputer</td>\n",
       "      <td id=\"T_13afd_row22_col1\" class=\"data row22 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_13afd_row23_col0\" class=\"data row23 col0\" >Iterative Imputation Numeric Model</td>\n",
       "      <td id=\"T_13afd_row23_col1\" class=\"data row23 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_13afd_row24_col0\" class=\"data row24 col0\" >Categorical Imputer</td>\n",
       "      <td id=\"T_13afd_row24_col1\" class=\"data row24 col1\" >constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_13afd_row25_col0\" class=\"data row25 col0\" >Iterative Imputation Categorical Model</td>\n",
       "      <td id=\"T_13afd_row25_col1\" class=\"data row25 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_13afd_row26_col0\" class=\"data row26 col0\" >Unknown Categoricals Handling</td>\n",
       "      <td id=\"T_13afd_row26_col1\" class=\"data row26 col1\" >least_frequent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_13afd_row27_col0\" class=\"data row27 col0\" >Normalize</td>\n",
       "      <td id=\"T_13afd_row27_col1\" class=\"data row27 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_13afd_row28_col0\" class=\"data row28 col0\" >Normalize Method</td>\n",
       "      <td id=\"T_13afd_row28_col1\" class=\"data row28 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_13afd_row29_col0\" class=\"data row29 col0\" >Transformation</td>\n",
       "      <td id=\"T_13afd_row29_col1\" class=\"data row29 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_13afd_row30_col0\" class=\"data row30 col0\" >Transformation Method</td>\n",
       "      <td id=\"T_13afd_row30_col1\" class=\"data row30 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_13afd_row31_col0\" class=\"data row31 col0\" >PCA</td>\n",
       "      <td id=\"T_13afd_row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_13afd_row32_col0\" class=\"data row32 col0\" >PCA Method</td>\n",
       "      <td id=\"T_13afd_row32_col1\" class=\"data row32 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_13afd_row33_col0\" class=\"data row33 col0\" >PCA Components</td>\n",
       "      <td id=\"T_13afd_row33_col1\" class=\"data row33 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_13afd_row34_col0\" class=\"data row34 col0\" >Ignore Low Variance</td>\n",
       "      <td id=\"T_13afd_row34_col1\" class=\"data row34 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_13afd_row35_col0\" class=\"data row35 col0\" >Combine Rare Levels</td>\n",
       "      <td id=\"T_13afd_row35_col1\" class=\"data row35 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_13afd_row36_col0\" class=\"data row36 col0\" >Rare Level Threshold</td>\n",
       "      <td id=\"T_13afd_row36_col1\" class=\"data row36 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_13afd_row37_col0\" class=\"data row37 col0\" >Numeric Binning</td>\n",
       "      <td id=\"T_13afd_row37_col1\" class=\"data row37 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_13afd_row38_col0\" class=\"data row38 col0\" >Remove Outliers</td>\n",
       "      <td id=\"T_13afd_row38_col1\" class=\"data row38 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_13afd_row39_col0\" class=\"data row39 col0\" >Outliers Threshold</td>\n",
       "      <td id=\"T_13afd_row39_col1\" class=\"data row39 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_13afd_row40_col0\" class=\"data row40 col0\" >Remove Multicollinearity</td>\n",
       "      <td id=\"T_13afd_row40_col1\" class=\"data row40 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_13afd_row41_col0\" class=\"data row41 col0\" >Multicollinearity Threshold</td>\n",
       "      <td id=\"T_13afd_row41_col1\" class=\"data row41 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "      <td id=\"T_13afd_row42_col0\" class=\"data row42 col0\" >Remove Perfect Collinearity</td>\n",
       "      <td id=\"T_13afd_row42_col1\" class=\"data row42 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "      <td id=\"T_13afd_row43_col0\" class=\"data row43 col0\" >Clustering</td>\n",
       "      <td id=\"T_13afd_row43_col1\" class=\"data row43 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "      <td id=\"T_13afd_row44_col0\" class=\"data row44 col0\" >Clustering Iteration</td>\n",
       "      <td id=\"T_13afd_row44_col1\" class=\"data row44 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "      <td id=\"T_13afd_row45_col0\" class=\"data row45 col0\" >Polynomial Features</td>\n",
       "      <td id=\"T_13afd_row45_col1\" class=\"data row45 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "      <td id=\"T_13afd_row46_col0\" class=\"data row46 col0\" >Polynomial Degree</td>\n",
       "      <td id=\"T_13afd_row46_col1\" class=\"data row46 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "      <td id=\"T_13afd_row47_col0\" class=\"data row47 col0\" >Trignometry Features</td>\n",
       "      <td id=\"T_13afd_row47_col1\" class=\"data row47 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "      <td id=\"T_13afd_row48_col0\" class=\"data row48 col0\" >Polynomial Threshold</td>\n",
       "      <td id=\"T_13afd_row48_col1\" class=\"data row48 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "      <td id=\"T_13afd_row49_col0\" class=\"data row49 col0\" >Group Features</td>\n",
       "      <td id=\"T_13afd_row49_col1\" class=\"data row49 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "      <td id=\"T_13afd_row50_col0\" class=\"data row50 col0\" >Feature Selection</td>\n",
       "      <td id=\"T_13afd_row50_col1\" class=\"data row50 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "      <td id=\"T_13afd_row51_col0\" class=\"data row51 col0\" >Feature Selection Method</td>\n",
       "      <td id=\"T_13afd_row51_col1\" class=\"data row51 col1\" >classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "      <td id=\"T_13afd_row52_col0\" class=\"data row52 col0\" >Features Selection Threshold</td>\n",
       "      <td id=\"T_13afd_row52_col1\" class=\"data row52 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "      <td id=\"T_13afd_row53_col0\" class=\"data row53 col0\" >Feature Interaction</td>\n",
       "      <td id=\"T_13afd_row53_col1\" class=\"data row53 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "      <td id=\"T_13afd_row54_col0\" class=\"data row54 col0\" >Feature Ratio</td>\n",
       "      <td id=\"T_13afd_row54_col1\" class=\"data row54 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "      <td id=\"T_13afd_row55_col0\" class=\"data row55 col0\" >Interaction Threshold</td>\n",
       "      <td id=\"T_13afd_row55_col1\" class=\"data row55 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "      <td id=\"T_13afd_row56_col0\" class=\"data row56 col0\" >Transform Target</td>\n",
       "      <td id=\"T_13afd_row56_col1\" class=\"data row56 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13afd_level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "      <td id=\"T_13afd_row57_col0\" class=\"data row57 col0\" >Transform Target Method</td>\n",
       "      <td id=\"T_13afd_row57_col1\" class=\"data row57 col1\" >box-cox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9f118fd460>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_pc = setup(data=df,target=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2fa74_ th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2fa74_row0_col0, #T_2fa74_row0_col5, #T_2fa74_row0_col6, #T_2fa74_row1_col0, #T_2fa74_row1_col1, #T_2fa74_row1_col2, #T_2fa74_row1_col3, #T_2fa74_row1_col4, #T_2fa74_row1_col5, #T_2fa74_row1_col6, #T_2fa74_row2_col0, #T_2fa74_row2_col1, #T_2fa74_row2_col2, #T_2fa74_row2_col3, #T_2fa74_row2_col4, #T_2fa74_row3_col0, #T_2fa74_row3_col1, #T_2fa74_row3_col2, #T_2fa74_row3_col3, #T_2fa74_row3_col4, #T_2fa74_row3_col5, #T_2fa74_row3_col6, #T_2fa74_row4_col0, #T_2fa74_row4_col1, #T_2fa74_row4_col2, #T_2fa74_row4_col3, #T_2fa74_row4_col4, #T_2fa74_row4_col5, #T_2fa74_row4_col6, #T_2fa74_row5_col0, #T_2fa74_row5_col1, #T_2fa74_row5_col2, #T_2fa74_row5_col3, #T_2fa74_row5_col4, #T_2fa74_row5_col5, #T_2fa74_row5_col6, #T_2fa74_row6_col0, #T_2fa74_row6_col1, #T_2fa74_row6_col2, #T_2fa74_row6_col3, #T_2fa74_row6_col4, #T_2fa74_row6_col5, #T_2fa74_row6_col6, #T_2fa74_row7_col0, #T_2fa74_row7_col1, #T_2fa74_row7_col2, #T_2fa74_row7_col3, #T_2fa74_row7_col4, #T_2fa74_row7_col5, #T_2fa74_row7_col6, #T_2fa74_row8_col0, #T_2fa74_row8_col1, #T_2fa74_row8_col2, #T_2fa74_row8_col3, #T_2fa74_row8_col4, #T_2fa74_row8_col5, #T_2fa74_row8_col6, #T_2fa74_row9_col0, #T_2fa74_row9_col1, #T_2fa74_row9_col2, #T_2fa74_row9_col3, #T_2fa74_row9_col4, #T_2fa74_row9_col5, #T_2fa74_row9_col6, #T_2fa74_row10_col0, #T_2fa74_row10_col1, #T_2fa74_row10_col2, #T_2fa74_row10_col3, #T_2fa74_row10_col4, #T_2fa74_row10_col5, #T_2fa74_row10_col6, #T_2fa74_row11_col0, #T_2fa74_row11_col1, #T_2fa74_row11_col2, #T_2fa74_row11_col3, #T_2fa74_row11_col4, #T_2fa74_row11_col5, #T_2fa74_row11_col6, #T_2fa74_row12_col0, #T_2fa74_row12_col1, #T_2fa74_row12_col2, #T_2fa74_row12_col3, #T_2fa74_row12_col4, #T_2fa74_row12_col5, #T_2fa74_row12_col6, #T_2fa74_row13_col0, #T_2fa74_row13_col1, #T_2fa74_row13_col2, #T_2fa74_row13_col3, #T_2fa74_row13_col4, #T_2fa74_row13_col5, #T_2fa74_row13_col6, #T_2fa74_row14_col0, #T_2fa74_row14_col1, #T_2fa74_row14_col2, #T_2fa74_row14_col3, #T_2fa74_row14_col4, #T_2fa74_row14_col5, #T_2fa74_row14_col6, #T_2fa74_row15_col0, #T_2fa74_row15_col1, #T_2fa74_row15_col2, #T_2fa74_row15_col3, #T_2fa74_row15_col4, #T_2fa74_row15_col5, #T_2fa74_row15_col6, #T_2fa74_row16_col0, #T_2fa74_row16_col1, #T_2fa74_row16_col2, #T_2fa74_row16_col3, #T_2fa74_row16_col4, #T_2fa74_row16_col5, #T_2fa74_row16_col6, #T_2fa74_row17_col0, #T_2fa74_row17_col1, #T_2fa74_row17_col2, #T_2fa74_row17_col3, #T_2fa74_row17_col4, #T_2fa74_row17_col5, #T_2fa74_row17_col6, #T_2fa74_row18_col0, #T_2fa74_row18_col1, #T_2fa74_row18_col2, #T_2fa74_row18_col3, #T_2fa74_row18_col4, #T_2fa74_row18_col5, #T_2fa74_row18_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2fa74_row0_col1, #T_2fa74_row0_col2, #T_2fa74_row0_col3, #T_2fa74_row0_col4, #T_2fa74_row2_col5, #T_2fa74_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_2fa74_row0_col7, #T_2fa74_row1_col7, #T_2fa74_row2_col7, #T_2fa74_row3_col7, #T_2fa74_row4_col7, #T_2fa74_row5_col7, #T_2fa74_row6_col7, #T_2fa74_row7_col7, #T_2fa74_row8_col7, #T_2fa74_row9_col7, #T_2fa74_row10_col7, #T_2fa74_row11_col7, #T_2fa74_row12_col7, #T_2fa74_row13_col7, #T_2fa74_row14_col7, #T_2fa74_row17_col7, #T_2fa74_row18_col7 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_2fa74_row15_col7, #T_2fa74_row16_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2fa74_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th class=\"col_heading level0 col6\" >MAPE</th>\n",
       "      <th class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2fa74_level0_row0\" class=\"row_heading level0 row0\" >lightgbm</th>\n",
       "      <td id=\"T_2fa74_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_2fa74_row0_col1\" class=\"data row0 col1\" >46.4723</td>\n",
       "      <td id=\"T_2fa74_row0_col2\" class=\"data row0 col2\" >4665.6666</td>\n",
       "      <td id=\"T_2fa74_row0_col3\" class=\"data row0 col3\" >68.1756</td>\n",
       "      <td id=\"T_2fa74_row0_col4\" class=\"data row0 col4\" >0.8544</td>\n",
       "      <td id=\"T_2fa74_row0_col5\" class=\"data row0 col5\" >0.4662</td>\n",
       "      <td id=\"T_2fa74_row0_col6\" class=\"data row0 col6\" >0.5161</td>\n",
       "      <td id=\"T_2fa74_row0_col7\" class=\"data row0 col7\" >0.1470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fa74_level0_row1\" class=\"row_heading level0 row1\" >xgboost</th>\n",
       "      <td id=\"T_2fa74_row1_col0\" class=\"data row1 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_2fa74_row1_col1\" class=\"data row1 col1\" >46.8919</td>\n",
       "      <td id=\"T_2fa74_row1_col2\" class=\"data row1 col2\" >4802.6399</td>\n",
       "      <td id=\"T_2fa74_row1_col3\" class=\"data row1 col3\" >69.2062</td>\n",
       "      <td id=\"T_2fa74_row1_col4\" class=\"data row1 col4\" >0.8499</td>\n",
       "      <td id=\"T_2fa74_row1_col5\" class=\"data row1 col5\" >0.5248</td>\n",
       "      <td id=\"T_2fa74_row1_col6\" class=\"data row1 col6\" >0.5512</td>\n",
       "      <td id=\"T_2fa74_row1_col7\" class=\"data row1 col7\" >57.3730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fa74_level0_row2\" class=\"row_heading level0 row2\" >rf</th>\n",
       "      <td id=\"T_2fa74_row2_col0\" class=\"data row2 col0\" >Random Forest Regressor</td>\n",
       "      <td id=\"T_2fa74_row2_col1\" class=\"data row2 col1\" >46.9835</td>\n",
       "      <td id=\"T_2fa74_row2_col2\" class=\"data row2 col2\" >5061.6922</td>\n",
       "      <td id=\"T_2fa74_row2_col3\" class=\"data row2 col3\" >71.0117</td>\n",
       "      <td id=\"T_2fa74_row2_col4\" class=\"data row2 col4\" >0.8418</td>\n",
       "      <td id=\"T_2fa74_row2_col5\" class=\"data row2 col5\" >0.4329</td>\n",
       "      <td id=\"T_2fa74_row2_col6\" class=\"data row2 col6\" >0.4434</td>\n",
       "      <td id=\"T_2fa74_row2_col7\" class=\"data row2 col7\" >0.5170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fa74_level0_row3\" class=\"row_heading level0 row3\" >et</th>\n",
       "      <td id=\"T_2fa74_row3_col0\" class=\"data row3 col0\" >Extra Trees Regressor</td>\n",
       "      <td id=\"T_2fa74_row3_col1\" class=\"data row3 col1\" >47.6544</td>\n",
       "      <td id=\"T_2fa74_row3_col2\" class=\"data row3 col2\" >5362.3959</td>\n",
       "      <td id=\"T_2fa74_row3_col3\" class=\"data row3 col3\" >73.0886</td>\n",
       "      <td id=\"T_2fa74_row3_col4\" class=\"data row3 col4\" >0.8324</td>\n",
       "      <td id=\"T_2fa74_row3_col5\" class=\"data row3 col5\" >0.4405</td>\n",
       "      <td id=\"T_2fa74_row3_col6\" class=\"data row3 col6\" >0.4494</td>\n",
       "      <td id=\"T_2fa74_row3_col7\" class=\"data row3 col7\" >0.4220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fa74_level0_row4\" class=\"row_heading level0 row4\" >gbr</th>\n",
       "      <td id=\"T_2fa74_row4_col0\" class=\"data row4 col0\" >Gradient Boosting Regressor</td>\n",
       "      <td id=\"T_2fa74_row4_col1\" class=\"data row4 col1\" >57.9211</td>\n",
       "      <td id=\"T_2fa74_row4_col2\" class=\"data row4 col2\" >7155.6422</td>\n",
       "      <td id=\"T_2fa74_row4_col3\" class=\"data row4 col3\" >84.4636</td>\n",
       "      <td id=\"T_2fa74_row4_col4\" class=\"data row4 col4\" >0.7762</td>\n",
       "      <td id=\"T_2fa74_row4_col5\" class=\"data row4 col5\" >0.6562</td>\n",
       "      <td id=\"T_2fa74_row4_col6\" class=\"data row4 col6\" >0.8847</td>\n",
       "      <td id=\"T_2fa74_row4_col7\" class=\"data row4 col7\" >0.1550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fa74_level0_row5\" class=\"row_heading level0 row5\" >dt</th>\n",
       "      <td id=\"T_2fa74_row5_col0\" class=\"data row5 col0\" >Decision Tree Regressor</td>\n",
       "      <td id=\"T_2fa74_row5_col1\" class=\"data row5 col1\" >60.9916</td>\n",
       "      <td id=\"T_2fa74_row5_col2\" class=\"data row5 col2\" >9518.2946</td>\n",
       "      <td id=\"T_2fa74_row5_col3\" class=\"data row5 col3\" >97.4206</td>\n",
       "      <td id=\"T_2fa74_row5_col4\" class=\"data row5 col4\" >0.7019</td>\n",
       "      <td id=\"T_2fa74_row5_col5\" class=\"data row5 col5\" >0.5511</td>\n",
       "      <td id=\"T_2fa74_row5_col6\" class=\"data row5 col6\" >0.5258</td>\n",
       "      <td id=\"T_2fa74_row5_col7\" class=\"data row5 col7\" >0.0170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fa74_level0_row6\" class=\"row_heading level0 row6\" >ada</th>\n",
       "      <td id=\"T_2fa74_row6_col0\" class=\"data row6 col0\" >AdaBoost Regressor</td>\n",
       "      <td id=\"T_2fa74_row6_col1\" class=\"data row6 col1\" >91.9719</td>\n",
       "      <td id=\"T_2fa74_row6_col2\" class=\"data row6 col2\" >13504.7697</td>\n",
       "      <td id=\"T_2fa74_row6_col3\" class=\"data row6 col3\" >116.1151</td>\n",
       "      <td id=\"T_2fa74_row6_col4\" class=\"data row6 col4\" >0.5764</td>\n",
       "      <td id=\"T_2fa74_row6_col5\" class=\"data row6 col5\" >1.0140</td>\n",
       "      <td id=\"T_2fa74_row6_col6\" class=\"data row6 col6\" >2.3493</td>\n",
       "      <td id=\"T_2fa74_row6_col7\" class=\"data row6 col7\" >0.1110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fa74_level0_row7\" class=\"row_heading level0 row7\" >knn</th>\n",
       "      <td id=\"T_2fa74_row7_col0\" class=\"data row7 col0\" >K Neighbors Regressor</td>\n",
       "      <td id=\"T_2fa74_row7_col1\" class=\"data row7 col1\" >86.1317</td>\n",
       "      <td id=\"T_2fa74_row7_col2\" class=\"data row7 col2\" >15818.6448</td>\n",
       "      <td id=\"T_2fa74_row7_col3\" class=\"data row7 col3\" >125.6354</td>\n",
       "      <td id=\"T_2fa74_row7_col4\" class=\"data row7 col4\" >0.5052</td>\n",
       "      <td id=\"T_2fa74_row7_col5\" class=\"data row7 col5\" >0.8912</td>\n",
       "      <td id=\"T_2fa74_row7_col6\" class=\"data row7 col6\" >1.7102</td>\n",
       "      <td id=\"T_2fa74_row7_col7\" class=\"data row7 col7\" >0.0180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fa74_level0_row8\" class=\"row_heading level0 row8\" >br</th>\n",
       "      <td id=\"T_2fa74_row8_col0\" class=\"data row8 col0\" >Bayesian Ridge</td>\n",
       "      <td id=\"T_2fa74_row8_col1\" class=\"data row8 col1\" >106.5706</td>\n",
       "      <td id=\"T_2fa74_row8_col2\" class=\"data row8 col2\" >20967.0774</td>\n",
       "      <td id=\"T_2fa74_row8_col3\" class=\"data row8 col3\" >144.7058</td>\n",
       "      <td id=\"T_2fa74_row8_col4\" class=\"data row8 col4\" >0.3436</td>\n",
       "      <td id=\"T_2fa74_row8_col5\" class=\"data row8 col5\" >1.2039</td>\n",
       "      <td id=\"T_2fa74_row8_col6\" class=\"data row8 col6\" >3.1394</td>\n",
       "      <td id=\"T_2fa74_row8_col7\" class=\"data row8 col7\" >0.0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fa74_level0_row9\" class=\"row_heading level0 row9\" >ridge</th>\n",
       "      <td id=\"T_2fa74_row9_col0\" class=\"data row9 col0\" >Ridge Regression</td>\n",
       "      <td id=\"T_2fa74_row9_col1\" class=\"data row9 col1\" >106.6117</td>\n",
       "      <td id=\"T_2fa74_row9_col2\" class=\"data row9 col2\" >20967.4389</td>\n",
       "      <td id=\"T_2fa74_row9_col3\" class=\"data row9 col3\" >144.7059</td>\n",
       "      <td id=\"T_2fa74_row9_col4\" class=\"data row9 col4\" >0.3436</td>\n",
       "      <td id=\"T_2fa74_row9_col5\" class=\"data row9 col5\" >1.2043</td>\n",
       "      <td id=\"T_2fa74_row9_col6\" class=\"data row9 col6\" >3.1443</td>\n",
       "      <td id=\"T_2fa74_row9_col7\" class=\"data row9 col7\" >0.0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fa74_level0_row10\" class=\"row_heading level0 row10\" >lr</th>\n",
       "      <td id=\"T_2fa74_row10_col0\" class=\"data row10 col0\" >Linear Regression</td>\n",
       "      <td id=\"T_2fa74_row10_col1\" class=\"data row10 col1\" >106.6127</td>\n",
       "      <td id=\"T_2fa74_row10_col2\" class=\"data row10 col2\" >20967.4944</td>\n",
       "      <td id=\"T_2fa74_row10_col3\" class=\"data row10 col3\" >144.7061</td>\n",
       "      <td id=\"T_2fa74_row10_col4\" class=\"data row10 col4\" >0.3436</td>\n",
       "      <td id=\"T_2fa74_row10_col5\" class=\"data row10 col5\" >1.2043</td>\n",
       "      <td id=\"T_2fa74_row10_col6\" class=\"data row10 col6\" >3.1444</td>\n",
       "      <td id=\"T_2fa74_row10_col7\" class=\"data row10 col7\" >0.3770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fa74_level0_row11\" class=\"row_heading level0 row11\" >lar</th>\n",
       "      <td id=\"T_2fa74_row11_col0\" class=\"data row11 col0\" >Least Angle Regression</td>\n",
       "      <td id=\"T_2fa74_row11_col1\" class=\"data row11 col1\" >106.6802</td>\n",
       "      <td id=\"T_2fa74_row11_col2\" class=\"data row11 col2\" >20993.9983</td>\n",
       "      <td id=\"T_2fa74_row11_col3\" class=\"data row11 col3\" >144.7938</td>\n",
       "      <td id=\"T_2fa74_row11_col4\" class=\"data row11 col4\" >0.3428</td>\n",
       "      <td id=\"T_2fa74_row11_col5\" class=\"data row11 col5\" >1.2040</td>\n",
       "      <td id=\"T_2fa74_row11_col6\" class=\"data row11 col6\" >3.1449</td>\n",
       "      <td id=\"T_2fa74_row11_col7\" class=\"data row11 col7\" >0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fa74_level0_row12\" class=\"row_heading level0 row12\" >lasso</th>\n",
       "      <td id=\"T_2fa74_row12_col0\" class=\"data row12 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_2fa74_row12_col1\" class=\"data row12 col1\" >106.5506</td>\n",
       "      <td id=\"T_2fa74_row12_col2\" class=\"data row12 col2\" >20998.1704</td>\n",
       "      <td id=\"T_2fa74_row12_col3\" class=\"data row12 col3\" >144.8168</td>\n",
       "      <td id=\"T_2fa74_row12_col4\" class=\"data row12 col4\" >0.3425</td>\n",
       "      <td id=\"T_2fa74_row12_col5\" class=\"data row12 col5\" >1.2003</td>\n",
       "      <td id=\"T_2fa74_row12_col6\" class=\"data row12 col6\" >3.1338</td>\n",
       "      <td id=\"T_2fa74_row12_col7\" class=\"data row12 col7\" >0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fa74_level0_row13\" class=\"row_heading level0 row13\" >en</th>\n",
       "      <td id=\"T_2fa74_row13_col0\" class=\"data row13 col0\" >Elastic Net</td>\n",
       "      <td id=\"T_2fa74_row13_col1\" class=\"data row13 col1\" >107.2217</td>\n",
       "      <td id=\"T_2fa74_row13_col2\" class=\"data row13 col2\" >21377.9919</td>\n",
       "      <td id=\"T_2fa74_row13_col3\" class=\"data row13 col3\" >146.1344</td>\n",
       "      <td id=\"T_2fa74_row13_col4\" class=\"data row13 col4\" >0.3305</td>\n",
       "      <td id=\"T_2fa74_row13_col5\" class=\"data row13 col5\" >1.1940</td>\n",
       "      <td id=\"T_2fa74_row13_col6\" class=\"data row13 col6\" >3.1477</td>\n",
       "      <td id=\"T_2fa74_row13_col7\" class=\"data row13 col7\" >0.0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fa74_level0_row14\" class=\"row_heading level0 row14\" >huber</th>\n",
       "      <td id=\"T_2fa74_row14_col0\" class=\"data row14 col0\" >Huber Regressor</td>\n",
       "      <td id=\"T_2fa74_row14_col1\" class=\"data row14 col1\" >102.2220</td>\n",
       "      <td id=\"T_2fa74_row14_col2\" class=\"data row14 col2\" >21893.2293</td>\n",
       "      <td id=\"T_2fa74_row14_col3\" class=\"data row14 col3\" >147.8248</td>\n",
       "      <td id=\"T_2fa74_row14_col4\" class=\"data row14 col4\" >0.3152</td>\n",
       "      <td id=\"T_2fa74_row14_col5\" class=\"data row14 col5\" >1.1341</td>\n",
       "      <td id=\"T_2fa74_row14_col6\" class=\"data row14 col6\" >2.4793</td>\n",
       "      <td id=\"T_2fa74_row14_col7\" class=\"data row14 col7\" >0.0660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fa74_level0_row15\" class=\"row_heading level0 row15\" >omp</th>\n",
       "      <td id=\"T_2fa74_row15_col0\" class=\"data row15 col0\" >Orthogonal Matching Pursuit</td>\n",
       "      <td id=\"T_2fa74_row15_col1\" class=\"data row15 col1\" >125.7841</td>\n",
       "      <td id=\"T_2fa74_row15_col2\" class=\"data row15 col2\" >27404.1708</td>\n",
       "      <td id=\"T_2fa74_row15_col3\" class=\"data row15 col3\" >165.4551</td>\n",
       "      <td id=\"T_2fa74_row15_col4\" class=\"data row15 col4\" >0.1419</td>\n",
       "      <td id=\"T_2fa74_row15_col5\" class=\"data row15 col5\" >1.4102</td>\n",
       "      <td id=\"T_2fa74_row15_col6\" class=\"data row15 col6\" >5.4652</td>\n",
       "      <td id=\"T_2fa74_row15_col7\" class=\"data row15 col7\" >0.0080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fa74_level0_row16\" class=\"row_heading level0 row16\" >llar</th>\n",
       "      <td id=\"T_2fa74_row16_col0\" class=\"data row16 col0\" >Lasso Least Angle Regression</td>\n",
       "      <td id=\"T_2fa74_row16_col1\" class=\"data row16 col1\" >140.6487</td>\n",
       "      <td id=\"T_2fa74_row16_col2\" class=\"data row16 col2\" >31997.9307</td>\n",
       "      <td id=\"T_2fa74_row16_col3\" class=\"data row16 col3\" >178.8056</td>\n",
       "      <td id=\"T_2fa74_row16_col4\" class=\"data row16 col4\" >-0.0021</td>\n",
       "      <td id=\"T_2fa74_row16_col5\" class=\"data row16 col5\" >1.5574</td>\n",
       "      <td id=\"T_2fa74_row16_col6\" class=\"data row16 col6\" >7.6325</td>\n",
       "      <td id=\"T_2fa74_row16_col7\" class=\"data row16 col7\" >0.0080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fa74_level0_row17\" class=\"row_heading level0 row17\" >dummy</th>\n",
       "      <td id=\"T_2fa74_row17_col0\" class=\"data row17 col0\" >Dummy Regressor</td>\n",
       "      <td id=\"T_2fa74_row17_col1\" class=\"data row17 col1\" >140.6487</td>\n",
       "      <td id=\"T_2fa74_row17_col2\" class=\"data row17 col2\" >31997.9307</td>\n",
       "      <td id=\"T_2fa74_row17_col3\" class=\"data row17 col3\" >178.8056</td>\n",
       "      <td id=\"T_2fa74_row17_col4\" class=\"data row17 col4\" >-0.0021</td>\n",
       "      <td id=\"T_2fa74_row17_col5\" class=\"data row17 col5\" >1.5574</td>\n",
       "      <td id=\"T_2fa74_row17_col6\" class=\"data row17 col6\" >7.6325</td>\n",
       "      <td id=\"T_2fa74_row17_col7\" class=\"data row17 col7\" >0.0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fa74_level0_row18\" class=\"row_heading level0 row18\" >par</th>\n",
       "      <td id=\"T_2fa74_row18_col0\" class=\"data row18 col0\" >Passive Aggressive Regressor</td>\n",
       "      <td id=\"T_2fa74_row18_col1\" class=\"data row18 col1\" >141.3248</td>\n",
       "      <td id=\"T_2fa74_row18_col2\" class=\"data row18 col2\" >36238.9801</td>\n",
       "      <td id=\"T_2fa74_row18_col3\" class=\"data row18 col3\" >184.1105</td>\n",
       "      <td id=\"T_2fa74_row18_col4\" class=\"data row18 col4\" >-0.1549</td>\n",
       "      <td id=\"T_2fa74_row18_col5\" class=\"data row18 col5\" >1.3984</td>\n",
       "      <td id=\"T_2fa74_row18_col6\" class=\"data row18 col6\" >5.1430</td>\n",
       "      <td id=\"T_2fa74_row18_col7\" class=\"data row18 col7\" >0.0230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9f34c368e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.pop(\"count\")\n",
    "X = df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>heure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  holiday  workingday  weather  temp  humidity  windspeed  heure\n",
       "0       1        0           0        1  9.84        81        0.0      0\n",
       "1       1        0           0        1  9.02        80        0.0      1\n",
       "2       1        0           0        1  9.02        80        0.0      2\n",
       "3       1        0           0        1  9.84        75        0.0      3\n",
       "4       1        0           0        1  9.84        75        0.0      4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor()\n",
    "cat_feature = [\"season\",\"weather\"]\n",
    "cat_pip = make_pipeline(OneHotEncoder(handle_unknown='ignore'))\n",
    "num_feature = [\"temp\",\"humidity\",\"windspeed\",\"heure\"]\n",
    "num_pip = make_pipeline(StandardScaler())\n",
    "preprocessor = make_column_transformer((cat_pip,cat_feature),(num_pip,num_feature),remainder=\"passthrough\")\n",
    "\n",
    "pip = make_pipeline(preprocessor,xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_xgb = pip.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8588667899172001"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_importance(model_xgb[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f0': 117.0,\n",
       " 'f1': 149.0,\n",
       " 'f2': 70.0,\n",
       " 'f3': 108.0,\n",
       " 'f4': 104.0,\n",
       " 'f5': 84.0,\n",
       " 'f6': 65.0,\n",
       " 'f8': 1175.0,\n",
       " 'f9': 1110.0,\n",
       " 'f10': 802.0,\n",
       " 'f11': 1171.0,\n",
       " 'f12': 101.0,\n",
       " 'f13': 270.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_score = model_xgb[1].get_booster().get_fscore()\n",
    "xgb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pipeline-2',\n",
       " Pipeline(steps=[('standardscaler', StandardScaler())]),\n",
       " ['temp', 'humidity', 'windspeed', 'heure'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb[0].transformers_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['season_1', 'season_2', 'season_3', 'season_4', 'weather_1',\n",
       "       'weather_2', 'weather_3', 'weather_4'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb[0].transformers_[0][1][\"onehotencoder\"].get_feature_names(cat_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('remainder', 'passthrough', [1, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb[0].transformers_[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>heure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  holiday  workingday  weather  temp  humidity  windspeed  heure\n",
       "0       1        0           0        1  9.84        81        0.0      0\n",
       "1       1        0           0        1  9.02        80        0.0      1\n",
       "2       1        0           0        1  9.02        80        0.0      2\n",
       "3       1        0           0        1  9.84        75        0.0      3\n",
       "4       1        0           0        1  9.84        75        0.0      4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pipeline-1',\n",
       " Pipeline(steps=[('onehotencoder', OneHotEncoder(handle_unknown='ignore'))]),\n",
       " ['season', 'weather'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb[0].transformers_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_feature = ['season_1', 'season_2', 'season_3', 'season_4', 'weather_1','weather_2', 'weather_3','temp', 'humidity', 'windspeed', 'heure',\"holiday\",\"workingday\"]\n",
    "len(liste_feature)\n",
    "len(list(xgb_score.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x7f7fa02915e0>,\n",
       "  <matplotlib.axis.YTick at 0x7f7fa027ae20>,\n",
       "  <matplotlib.axis.YTick at 0x7f7fa027a490>,\n",
       "  <matplotlib.axis.YTick at 0x7f7fa022f8e0>,\n",
       "  <matplotlib.axis.YTick at 0x7f7fa01f0160>,\n",
       "  <matplotlib.axis.YTick at 0x7f7fa01f07f0>,\n",
       "  <matplotlib.axis.YTick at 0x7f7fa01f0f40>,\n",
       "  <matplotlib.axis.YTick at 0x7f7fa01f76d0>,\n",
       "  <matplotlib.axis.YTick at 0x7f7fa01f0f10>,\n",
       "  <matplotlib.axis.YTick at 0x7f7fa01dcc40>,\n",
       "  <matplotlib.axis.YTick at 0x7f7fa01fe160>,\n",
       "  <matplotlib.axis.YTick at 0x7f7fa01fe7f0>,\n",
       "  <matplotlib.axis.YTick at 0x7f7fa01fef40>],\n",
       " [Text(0, 0, 'season_1'),\n",
       "  Text(0, 1, 'season_2'),\n",
       "  Text(0, 2, 'season_3'),\n",
       "  Text(0, 3, 'season_4'),\n",
       "  Text(0, 4, 'weather_1'),\n",
       "  Text(0, 5, 'weather_2'),\n",
       "  Text(0, 6, 'weather_3'),\n",
       "  Text(0, 7, 'temp'),\n",
       "  Text(0, 8, 'humidity'),\n",
       "  Text(0, 9, 'windspeed'),\n",
       "  Text(0, 10, 'heure'),\n",
       "  Text(0, 11, 'holiday'),\n",
       "  Text(0, 12, 'workingday')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "y_pos = range(0,len(liste_feature))\n",
    "\n",
    "plt.barh(y_pos,list(xgb_score.values()))\n",
    "plt.yticks(y_pos,liste_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[117.0,\n",
       " 149.0,\n",
       " 70.0,\n",
       " 108.0,\n",
       " 104.0,\n",
       " 84.0,\n",
       " 65.0,\n",
       " 1175.0,\n",
       " 1110.0,\n",
       " 802.0,\n",
       " 1171.0,\n",
       " 101.0,\n",
       " 270.0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(xgb_score.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost avec les bons train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2011-01-01 00:00:00\n",
       "1       2011-01-01 01:00:00\n",
       "2       2011-01-01 02:00:00\n",
       "3       2011-01-01 03:00:00\n",
       "4       2011-01-01 04:00:00\n",
       "               ...         \n",
       "9034    2012-08-19 19:00:00\n",
       "9035    2012-08-19 20:00:00\n",
       "9036    2012-08-19 21:00:00\n",
       "9037    2012-08-19 22:00:00\n",
       "9038    2012-08-19 23:00:00\n",
       "Name: datetime, Length: 9039, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv(\"Datas/data_frame_test_florian.csv\")\n",
    "X_train = pd.read_csv(\"Datas/data_frame_train_florian.csv\")\n",
    "date = X_test.pop(\"datetime\")\n",
    "X_train.pop(\"datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>count</th>\n",
       "      <th>heure</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.34</td>\n",
       "      <td>62</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.52</td>\n",
       "      <td>74</td>\n",
       "      <td>8.9981</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.70</td>\n",
       "      <td>70</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.70</td>\n",
       "      <td>70</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.70</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  holiday  workingday  weather   temp  humidity  windspeed  count  \\\n",
       "0       3        0           0        1  30.34        62     7.0015    168   \n",
       "1       3        0           0        1  29.52        74     8.9981     79   \n",
       "2       3        0           0        1  28.70        70    11.0014     69   \n",
       "3       3        0           0        1  28.70        70     7.0015     35   \n",
       "4       3        0           0        1  28.70        70     0.0000     12   \n",
       "\n",
       "   heure  month  year  \n",
       "0      0      9  2012  \n",
       "1      1      9  2012  \n",
       "2      2      9  2012  \n",
       "3      3      9  2012  \n",
       "4      4      9  2012  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train.pop(\"count\")\n",
    "y_test = X_test.pop(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>heure</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  holiday  workingday  weather  temp  humidity  windspeed  heure  \\\n",
       "0       1        0           0        1  9.84        81        0.0      0   \n",
       "1       1        0           0        1  9.02        80        0.0      1   \n",
       "2       1        0           0        1  9.02        80        0.0      2   \n",
       "3       1        0           0        1  9.84        75        0.0      3   \n",
       "4       1        0           0        1  9.84        75        0.0      4   \n",
       "\n",
       "   month  year  \n",
       "0      1  2011  \n",
       "1      1  2011  \n",
       "2      1  2011  \n",
       "3      1  2011  \n",
       "4      1  2011  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor()\n",
    "cat_feature = [\"season\",\"weather\",\"year\"]\n",
    "cat_pip = make_pipeline(OneHotEncoder(handle_unknown='ignore'))\n",
    "num_feature = [\"temp\",\"humidity\",\"windspeed\",\"heure\",\"month\"]\n",
    "num_pip = make_pipeline(StandardScaler())\n",
    "preprocessor = make_column_transformer((cat_pip,cat_feature),(num_pip,num_feature),remainder=\"passthrough\")\n",
    "\n",
    "pip = make_pipeline(preprocessor,xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9794626556375536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9006326610144423"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = pip.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "print(model_xgb.score(X_train,y_train))\n",
    "model_xgb.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7fa0043d60>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = y_test - model_xgb.predict(X_test)\n",
    "\n",
    "plt.scatter(range(0,len(res)),res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           0,
           62,
           30.34,
           "2012-09-01 00:00:00"
          ],
          [
           1,
           74,
           29.52,
           "2012-09-01 01:00:00"
          ],
          [
           2,
           70,
           28.7,
           "2012-09-01 02:00:00"
          ],
          [
           3,
           70,
           28.7,
           "2012-09-01 03:00:00"
          ],
          [
           4,
           70,
           28.7,
           "2012-09-01 04:00:00"
          ],
          [
           5,
           79,
           27.88,
           "2012-09-01 05:00:00"
          ],
          [
           6,
           79,
           27.88,
           "2012-09-01 06:00:00"
          ],
          [
           7,
           58,
           30.34,
           "2012-09-01 07:00:00"
          ],
          [
           8,
           58,
           31.16,
           "2012-09-01 08:00:00"
          ],
          [
           9,
           58,
           31.16,
           "2012-09-01 09:00:00"
          ],
          [
           10,
           55,
           31.98,
           "2012-09-01 10:00:00"
          ],
          [
           11,
           55,
           32.8,
           "2012-09-01 11:00:00"
          ],
          [
           12,
           55,
           32.8,
           "2012-09-01 12:00:00"
          ],
          [
           13,
           52,
           33.62,
           "2012-09-01 13:00:00"
          ],
          [
           14,
           44,
           35.26,
           "2012-09-01 14:00:00"
          ],
          [
           15,
           44,
           35.26,
           "2012-09-01 15:00:00"
          ],
          [
           16,
           49,
           34.44,
           "2012-09-01 16:00:00"
          ],
          [
           17,
           52,
           33.62,
           "2012-09-01 17:00:00"
          ],
          [
           18,
           52,
           33.62,
           "2012-09-01 18:00:00"
          ],
          [
           19,
           62,
           31.98,
           "2012-09-01 19:00:00"
          ],
          [
           20,
           67,
           31.16,
           "2012-09-01 20:00:00"
          ],
          [
           21,
           89,
           26.24,
           "2012-09-01 21:00:00"
          ],
          [
           22,
           89,
           27.06,
           "2012-09-01 22:00:00"
          ],
          [
           23,
           89,
           27.06,
           "2012-09-01 23:00:00"
          ],
          [
           0,
           89,
           27.06,
           "2012-09-02 00:00:00"
          ],
          [
           1,
           89,
           27.06,
           "2012-09-02 01:00:00"
          ],
          [
           2,
           89,
           27.06,
           "2012-09-02 02:00:00"
          ],
          [
           3,
           89,
           27.06,
           "2012-09-02 03:00:00"
          ],
          [
           4,
           89,
           27.06,
           "2012-09-02 04:00:00"
          ],
          [
           5,
           89,
           27.06,
           "2012-09-02 05:00:00"
          ],
          [
           6,
           89,
           27.06,
           "2012-09-02 06:00:00"
          ],
          [
           7,
           94,
           27.06,
           "2012-09-02 07:00:00"
          ],
          [
           8,
           89,
           27.88,
           "2012-09-02 08:00:00"
          ],
          [
           9,
           84,
           28.7,
           "2012-09-02 09:00:00"
          ],
          [
           10,
           79,
           29.52,
           "2012-09-02 10:00:00"
          ],
          [
           11,
           70,
           30.34,
           "2012-09-02 11:00:00"
          ],
          [
           12,
           70,
           30.34,
           "2012-09-02 12:00:00"
          ],
          [
           13,
           74,
           29.52,
           "2012-09-02 13:00:00"
          ],
          [
           14,
           79,
           29.52,
           "2012-09-02 14:00:00"
          ],
          [
           15,
           74,
           30.34,
           "2012-09-02 15:00:00"
          ],
          [
           16,
           70,
           30.34,
           "2012-09-02 16:00:00"
          ],
          [
           17,
           66,
           31.16,
           "2012-09-02 17:00:00"
          ],
          [
           18,
           74,
           30.34,
           "2012-09-02 18:00:00"
          ],
          [
           19,
           84,
           28.7,
           "2012-09-02 19:00:00"
          ],
          [
           20,
           84,
           28.7,
           "2012-09-02 20:00:00"
          ],
          [
           21,
           70,
           28.7,
           "2012-09-02 21:00:00"
          ],
          [
           22,
           83,
           27.88,
           "2012-09-02 22:00:00"
          ],
          [
           23,
           89,
           27.06,
           "2012-09-02 23:00:00"
          ],
          [
           0,
           94,
           27.06,
           "2012-09-03 00:00:00"
          ],
          [
           1,
           89,
           27.88,
           "2012-09-03 01:00:00"
          ],
          [
           2,
           89,
           27.06,
           "2012-09-03 02:00:00"
          ],
          [
           3,
           89,
           27.06,
           "2012-09-03 03:00:00"
          ],
          [
           4,
           89,
           27.06,
           "2012-09-03 04:00:00"
          ],
          [
           5,
           89,
           27.06,
           "2012-09-03 05:00:00"
          ],
          [
           6,
           94,
           27.06,
           "2012-09-03 06:00:00"
          ],
          [
           7,
           85,
           27.88,
           "2012-09-03 07:00:00"
          ],
          [
           8,
           84,
           28.7,
           "2012-09-03 08:00:00"
          ],
          [
           9,
           84,
           28.7,
           "2012-09-03 09:00:00"
          ],
          [
           10,
           74,
           30.34,
           "2012-09-03 10:00:00"
          ],
          [
           11,
           70,
           30.34,
           "2012-09-03 11:00:00"
          ],
          [
           12,
           62,
           31.16,
           "2012-09-03 12:00:00"
          ],
          [
           13,
           66,
           31.16,
           "2012-09-03 13:00:00"
          ],
          [
           14,
           70,
           30.34,
           "2012-09-03 14:00:00"
          ],
          [
           15,
           70,
           30.34,
           "2012-09-03 15:00:00"
          ],
          [
           16,
           70,
           30.34,
           "2012-09-03 16:00:00"
          ],
          [
           17,
           70,
           30.34,
           "2012-09-03 17:00:00"
          ],
          [
           18,
           66,
           30.34,
           "2012-09-03 18:00:00"
          ],
          [
           19,
           74,
           29.52,
           "2012-09-03 19:00:00"
          ],
          [
           20,
           76,
           29.52,
           "2012-09-03 20:00:00"
          ],
          [
           21,
           76,
           29.52,
           "2012-09-03 21:00:00"
          ],
          [
           22,
           84,
           28.7,
           "2012-09-03 22:00:00"
          ],
          [
           23,
           84,
           28.7,
           "2012-09-03 23:00:00"
          ],
          [
           0,
           84,
           28.7,
           "2012-09-04 00:00:00"
          ],
          [
           1,
           82,
           27.88,
           "2012-09-04 01:00:00"
          ],
          [
           2,
           82,
           27.88,
           "2012-09-04 02:00:00"
          ],
          [
           3,
           89,
           27.06,
           "2012-09-04 03:00:00"
          ],
          [
           4,
           89,
           27.06,
           "2012-09-04 04:00:00"
          ],
          [
           5,
           89,
           27.06,
           "2012-09-04 05:00:00"
          ],
          [
           6,
           89,
           27.88,
           "2012-09-04 06:00:00"
          ],
          [
           7,
           89,
           27.88,
           "2012-09-04 07:00:00"
          ],
          [
           8,
           84,
           28.7,
           "2012-09-04 08:00:00"
          ],
          [
           9,
           79,
           29.52,
           "2012-09-04 09:00:00"
          ],
          [
           10,
           74,
           29.52,
           "2012-09-04 10:00:00"
          ],
          [
           11,
           70,
           30.34,
           "2012-09-04 11:00:00"
          ],
          [
           12,
           70,
           31.16,
           "2012-09-04 12:00:00"
          ],
          [
           13,
           55,
           32.8,
           "2012-09-04 13:00:00"
          ],
          [
           14,
           55,
           32.8,
           "2012-09-04 14:00:00"
          ],
          [
           15,
           59,
           32.8,
           "2012-09-04 15:00:00"
          ],
          [
           16,
           70,
           31.16,
           "2012-09-04 16:00:00"
          ],
          [
           17,
           70,
           31.16,
           "2012-09-04 17:00:00"
          ],
          [
           18,
           75,
           31.16,
           "2012-09-04 18:00:00"
          ],
          [
           19,
           70,
           31.16,
           "2012-09-04 19:00:00"
          ],
          [
           20,
           70,
           30.34,
           "2012-09-04 20:00:00"
          ],
          [
           21,
           74,
           30.34,
           "2012-09-04 21:00:00"
          ],
          [
           22,
           70,
           30.34,
           "2012-09-04 22:00:00"
          ],
          [
           23,
           74,
           29.52,
           "2012-09-04 23:00:00"
          ],
          [
           0,
           74,
           29.52,
           "2012-09-05 00:00:00"
          ],
          [
           1,
           84,
           28.7,
           "2012-09-05 01:00:00"
          ],
          [
           2,
           84,
           28.7,
           "2012-09-05 02:00:00"
          ],
          [
           3,
           79,
           28.7,
           "2012-09-05 03:00:00"
          ],
          [
           4,
           79,
           28.7,
           "2012-09-05 04:00:00"
          ],
          [
           5,
           79,
           28.7,
           "2012-09-05 05:00:00"
          ],
          [
           6,
           79,
           28.7,
           "2012-09-05 06:00:00"
          ],
          [
           7,
           79,
           28.7,
           "2012-09-05 07:00:00"
          ],
          [
           8,
           74,
           29.52,
           "2012-09-05 08:00:00"
          ],
          [
           9,
           70,
           30.34,
           "2012-09-05 09:00:00"
          ],
          [
           10,
           70,
           31.16,
           "2012-09-05 10:00:00"
          ],
          [
           11,
           62,
           31.98,
           "2012-09-05 11:00:00"
          ],
          [
           12,
           70,
           31.98,
           "2012-09-05 12:00:00"
          ],
          [
           13,
           63,
           32.8,
           "2012-09-05 13:00:00"
          ],
          [
           14,
           56,
           33.62,
           "2012-09-05 14:00:00"
          ],
          [
           15,
           70,
           31.98,
           "2012-09-05 15:00:00"
          ],
          [
           16,
           70,
           31.16,
           "2012-09-05 16:00:00"
          ],
          [
           17,
           66,
           31.16,
           "2012-09-05 17:00:00"
          ],
          [
           18,
           75,
           31.16,
           "2012-09-05 18:00:00"
          ],
          [
           19,
           70,
           30.34,
           "2012-09-05 19:00:00"
          ],
          [
           20,
           84,
           29.52,
           "2012-09-05 20:00:00"
          ],
          [
           21,
           79,
           29.52,
           "2012-09-05 21:00:00"
          ],
          [
           22,
           79,
           29.52,
           "2012-09-05 22:00:00"
          ],
          [
           23,
           84,
           28.7,
           "2012-09-05 23:00:00"
          ],
          [
           0,
           84,
           28.7,
           "2012-09-06 00:00:00"
          ],
          [
           1,
           84,
           28.7,
           "2012-09-06 01:00:00"
          ],
          [
           2,
           79,
           29.52,
           "2012-09-06 02:00:00"
          ],
          [
           3,
           84,
           28.7,
           "2012-09-06 03:00:00"
          ],
          [
           4,
           84,
           28.7,
           "2012-09-06 04:00:00"
          ],
          [
           5,
           84,
           28.7,
           "2012-09-06 05:00:00"
          ],
          [
           6,
           84,
           28.7,
           "2012-09-06 06:00:00"
          ],
          [
           7,
           84,
           28.7,
           "2012-09-06 07:00:00"
          ],
          [
           8,
           79,
           28.7,
           "2012-09-06 08:00:00"
          ],
          [
           9,
           94,
           27.06,
           "2012-09-06 09:00:00"
          ],
          [
           10,
           94,
           27.06,
           "2012-09-06 10:00:00"
          ],
          [
           11,
           84,
           28.7,
           "2012-09-06 11:00:00"
          ],
          [
           12,
           79,
           29.52,
           "2012-09-06 12:00:00"
          ],
          [
           13,
           79,
           29.52,
           "2012-09-06 13:00:00"
          ],
          [
           14,
           74,
           30.34,
           "2012-09-06 14:00:00"
          ],
          [
           15,
           66,
           30.34,
           "2012-09-06 15:00:00"
          ],
          [
           16,
           70,
           30.34,
           "2012-09-06 16:00:00"
          ],
          [
           17,
           70,
           30.34,
           "2012-09-06 17:00:00"
          ],
          [
           18,
           70,
           29.52,
           "2012-09-06 18:00:00"
          ],
          [
           19,
           74,
           27.88,
           "2012-09-06 19:00:00"
          ],
          [
           20,
           78,
           27.06,
           "2012-09-06 20:00:00"
          ],
          [
           21,
           89,
           26.24,
           "2012-09-06 21:00:00"
          ],
          [
           22,
           89,
           26.24,
           "2012-09-06 22:00:00"
          ],
          [
           23,
           89,
           26.24,
           "2012-09-06 23:00:00"
          ],
          [
           0,
           89,
           26.24,
           "2012-09-07 00:00:00"
          ],
          [
           1,
           88,
           25.42,
           "2012-09-07 01:00:00"
          ],
          [
           2,
           83,
           25.42,
           "2012-09-07 02:00:00"
          ],
          [
           3,
           83,
           25.42,
           "2012-09-07 03:00:00"
          ],
          [
           4,
           88,
           25.42,
           "2012-09-07 04:00:00"
          ],
          [
           5,
           88,
           25.42,
           "2012-09-07 05:00:00"
          ],
          [
           6,
           88,
           25.42,
           "2012-09-07 06:00:00"
          ],
          [
           7,
           89,
           26.24,
           "2012-09-07 07:00:00"
          ],
          [
           8,
           83,
           27.06,
           "2012-09-07 08:00:00"
          ],
          [
           9,
           79,
           28.7,
           "2012-09-07 09:00:00"
          ],
          [
           10,
           74,
           29.52,
           "2012-09-07 10:00:00"
          ],
          [
           11,
           62,
           31.16,
           "2012-09-07 11:00:00"
          ],
          [
           12,
           59,
           31.98,
           "2012-09-07 12:00:00"
          ],
          [
           13,
           59,
           32.8,
           "2012-09-07 13:00:00"
          ],
          [
           14,
           59,
           32.8,
           "2012-09-07 14:00:00"
          ],
          [
           15,
           55,
           32.8,
           "2012-09-07 15:00:00"
          ],
          [
           16,
           55,
           32.8,
           "2012-09-07 16:00:00"
          ],
          [
           17,
           59,
           31.98,
           "2012-09-07 17:00:00"
          ],
          [
           18,
           62,
           31.16,
           "2012-09-07 18:00:00"
          ],
          [
           19,
           62,
           30.34,
           "2012-09-07 19:00:00"
          ],
          [
           20,
           66,
           29.52,
           "2012-09-07 20:00:00"
          ],
          [
           21,
           74,
           28.7,
           "2012-09-07 21:00:00"
          ],
          [
           22,
           74,
           28.7,
           "2012-09-07 22:00:00"
          ],
          [
           23,
           89,
           27.06,
           "2012-09-07 23:00:00"
          ],
          [
           0,
           89,
           27.06,
           "2012-09-08 00:00:00"
          ],
          [
           1,
           89,
           27.06,
           "2012-09-08 01:00:00"
          ],
          [
           2,
           89,
           27.06,
           "2012-09-08 02:00:00"
          ],
          [
           3,
           89,
           27.06,
           "2012-09-08 03:00:00"
          ],
          [
           4,
           94,
           27.06,
           "2012-09-08 04:00:00"
          ],
          [
           5,
           94,
           27.06,
           "2012-09-08 05:00:00"
          ],
          [
           6,
           89,
           27.06,
           "2012-09-08 06:00:00"
          ],
          [
           7,
           89,
           27.06,
           "2012-09-08 07:00:00"
          ],
          [
           8,
           79,
           28.7,
           "2012-09-08 08:00:00"
          ],
          [
           9,
           74,
           28.7,
           "2012-09-08 09:00:00"
          ],
          [
           10,
           70,
           30.34,
           "2012-09-08 10:00:00"
          ],
          [
           11,
           62,
           31.16,
           "2012-09-08 11:00:00"
          ],
          [
           12,
           55,
           32.8,
           "2012-09-08 12:00:00"
          ],
          [
           13,
           52,
           33.62,
           "2012-09-08 13:00:00"
          ],
          [
           14,
           52,
           33.62,
           "2012-09-08 14:00:00"
          ],
          [
           15,
           88,
           22.96,
           "2012-09-08 15:00:00"
          ],
          [
           16,
           88,
           22.96,
           "2012-09-08 16:00:00"
          ],
          [
           17,
           83,
           23.78,
           "2012-09-08 17:00:00"
          ],
          [
           18,
           83,
           23.78,
           "2012-09-08 18:00:00"
          ],
          [
           19,
           88,
           23.78,
           "2012-09-08 19:00:00"
          ],
          [
           20,
           88,
           23.78,
           "2012-09-08 20:00:00"
          ],
          [
           21,
           83,
           24.6,
           "2012-09-08 21:00:00"
          ],
          [
           22,
           78,
           23.78,
           "2012-09-08 22:00:00"
          ],
          [
           23,
           73,
           23.78,
           "2012-09-08 23:00:00"
          ],
          [
           0,
           73,
           22.96,
           "2012-09-09 00:00:00"
          ],
          [
           1,
           73,
           22.96,
           "2012-09-09 01:00:00"
          ],
          [
           2,
           77,
           22.14,
           "2012-09-09 02:00:00"
          ],
          [
           3,
           73,
           22.14,
           "2012-09-09 03:00:00"
          ],
          [
           4,
           77,
           21.32,
           "2012-09-09 04:00:00"
          ],
          [
           5,
           77,
           21.32,
           "2012-09-09 05:00:00"
          ],
          [
           6,
           77,
           21.32,
           "2012-09-09 06:00:00"
          ],
          [
           7,
           73,
           22.14,
           "2012-09-09 07:00:00"
          ],
          [
           8,
           68,
           23.78,
           "2012-09-09 08:00:00"
          ],
          [
           9,
           61,
           25.42,
           "2012-09-09 09:00:00"
          ],
          [
           10,
           57,
           26.24,
           "2012-09-09 10:00:00"
          ],
          [
           11,
           47,
           27.06,
           "2012-09-09 11:00:00"
          ],
          [
           12,
           47,
           27.06,
           "2012-09-09 12:00:00"
          ],
          [
           13,
           39,
           27.88,
           "2012-09-09 13:00:00"
          ],
          [
           14,
           30,
           29.52,
           "2012-09-09 14:00:00"
          ],
          [
           15,
           32,
           29.52,
           "2012-09-09 15:00:00"
          ],
          [
           16,
           36,
           27.88,
           "2012-09-09 16:00:00"
          ],
          [
           17,
           37,
           28.7,
           "2012-09-09 17:00:00"
          ],
          [
           18,
           36,
           27.06,
           "2012-09-09 18:00:00"
          ],
          [
           19,
           36,
           27.06,
           "2012-09-09 19:00:00"
          ],
          [
           20,
           41,
           25.42,
           "2012-09-09 20:00:00"
          ],
          [
           21,
           46,
           24.6,
           "2012-09-09 21:00:00"
          ],
          [
           22,
           49,
           23.78,
           "2012-09-09 22:00:00"
          ],
          [
           23,
           52,
           22.96,
           "2012-09-09 23:00:00"
          ],
          [
           0,
           52,
           22.96,
           "2012-09-10 00:00:00"
          ],
          [
           1,
           60,
           22.14,
           "2012-09-10 01:00:00"
          ],
          [
           2,
           60,
           22.14,
           "2012-09-10 02:00:00"
          ],
          [
           3,
           68,
           21.32,
           "2012-09-10 03:00:00"
          ],
          [
           4,
           68,
           21.32,
           "2012-09-10 04:00:00"
          ],
          [
           5,
           72,
           20.5,
           "2012-09-10 05:00:00"
          ],
          [
           6,
           72,
           20.5,
           "2012-09-10 06:00:00"
          ],
          [
           7,
           68,
           21.32,
           "2012-09-10 07:00:00"
          ],
          [
           8,
           60,
           22.96,
           "2012-09-10 08:00:00"
          ],
          [
           9,
           53,
           24.6,
           "2012-09-10 09:00:00"
          ],
          [
           10,
           50,
           25.42,
           "2012-09-10 10:00:00"
          ],
          [
           11,
           43,
           25.42,
           "2012-09-10 11:00:00"
          ],
          [
           12,
           44,
           26.24,
           "2012-09-10 12:00:00"
          ],
          [
           13,
           38,
           26.24,
           "2012-09-10 13:00:00"
          ],
          [
           14,
           36,
           27.06,
           "2012-09-10 14:00:00"
          ],
          [
           15,
           31,
           27.06,
           "2012-09-10 15:00:00"
          ],
          [
           16,
           34,
           27.06,
           "2012-09-10 16:00:00"
          ],
          [
           17,
           34,
           27.06,
           "2012-09-10 17:00:00"
          ],
          [
           18,
           35,
           25.42,
           "2012-09-10 18:00:00"
          ],
          [
           19,
           38,
           25.42,
           "2012-09-10 19:00:00"
          ],
          [
           20,
           40,
           24.6,
           "2012-09-10 20:00:00"
          ],
          [
           21,
           49,
           22.96,
           "2012-09-10 21:00:00"
          ],
          [
           22,
           52,
           22.14,
           "2012-09-10 22:00:00"
          ],
          [
           23,
           52,
           22.14,
           "2012-09-10 23:00:00"
          ],
          [
           0,
           59,
           21.32,
           "2012-09-11 00:00:00"
          ],
          [
           1,
           63,
           20.5,
           "2012-09-11 01:00:00"
          ],
          [
           2,
           77,
           19.68,
           "2012-09-11 02:00:00"
          ],
          [
           3,
           67,
           19.68,
           "2012-09-11 03:00:00"
          ],
          [
           4,
           72,
           19.68,
           "2012-09-11 04:00:00"
          ],
          [
           5,
           72,
           18.86,
           "2012-09-11 05:00:00"
          ],
          [
           6,
           77,
           18.86,
           "2012-09-11 06:00:00"
          ],
          [
           7,
           72,
           20.5,
           "2012-09-11 07:00:00"
          ],
          [
           8,
           68,
           22.14,
           "2012-09-11 08:00:00"
          ],
          [
           9,
           49,
           24.6,
           "2012-09-11 09:00:00"
          ],
          [
           10,
           38,
           25.42,
           "2012-09-11 10:00:00"
          ],
          [
           11,
           33,
           26.24,
           "2012-09-11 11:00:00"
          ],
          [
           12,
           33,
           26.24,
           "2012-09-11 12:00:00"
          ],
          [
           13,
           29,
           27.06,
           "2012-09-11 13:00:00"
          ],
          [
           14,
           30,
           27.88,
           "2012-09-11 14:00:00"
          ],
          [
           15,
           28,
           28.7,
           "2012-09-11 15:00:00"
          ],
          [
           16,
           28,
           28.7,
           "2012-09-11 16:00:00"
          ],
          [
           17,
           28,
           28.7,
           "2012-09-11 17:00:00"
          ],
          [
           18,
           36,
           26.24,
           "2012-09-11 18:00:00"
          ],
          [
           19,
           41,
           25.42,
           "2012-09-11 19:00:00"
          ],
          [
           20,
           56,
           23.78,
           "2012-09-11 20:00:00"
          ],
          [
           21,
           60,
           22.96,
           "2012-09-11 21:00:00"
          ],
          [
           22,
           64,
           22.96,
           "2012-09-11 22:00:00"
          ],
          [
           23,
           68,
           22.14,
           "2012-09-11 23:00:00"
          ],
          [
           0,
           72,
           21.32,
           "2012-09-12 00:00:00"
          ],
          [
           1,
           72,
           21.32,
           "2012-09-12 01:00:00"
          ],
          [
           2,
           72,
           21.32,
           "2012-09-12 02:00:00"
          ],
          [
           3,
           77,
           20.5,
           "2012-09-12 03:00:00"
          ],
          [
           4,
           72,
           20.5,
           "2012-09-12 04:00:00"
          ],
          [
           5,
           72,
           20.5,
           "2012-09-12 05:00:00"
          ],
          [
           6,
           72,
           20.5,
           "2012-09-12 06:00:00"
          ],
          [
           7,
           72,
           21.32,
           "2012-09-12 07:00:00"
          ],
          [
           8,
           64,
           22.96,
           "2012-09-12 08:00:00"
          ],
          [
           9,
           64,
           24.6,
           "2012-09-12 09:00:00"
          ],
          [
           10,
           61,
           25.42,
           "2012-09-12 10:00:00"
          ],
          [
           11,
           50,
           27.06,
           "2012-09-12 11:00:00"
          ],
          [
           12,
           36,
           27.88,
           "2012-09-12 12:00:00"
          ],
          [
           13,
           34,
           28.7,
           "2012-09-12 13:00:00"
          ],
          [
           14,
           37,
           28.7,
           "2012-09-12 14:00:00"
          ],
          [
           15,
           37,
           29.52,
           "2012-09-12 15:00:00"
          ],
          [
           16,
           37,
           29.52,
           "2012-09-12 16:00:00"
          ],
          [
           17,
           41,
           28.7,
           "2012-09-12 17:00:00"
          ],
          [
           18,
           44,
           27.06,
           "2012-09-12 18:00:00"
          ],
          [
           19,
           50,
           26.24,
           "2012-09-12 19:00:00"
          ],
          [
           20,
           57,
           25.42,
           "2012-09-12 20:00:00"
          ],
          [
           21,
           60,
           24.6,
           "2012-09-12 21:00:00"
          ],
          [
           22,
           64,
           22.96,
           "2012-09-12 22:00:00"
          ],
          [
           23,
           68,
           22.96,
           "2012-09-12 23:00:00"
          ],
          [
           0,
           73,
           22.96,
           "2012-09-13 00:00:00"
          ],
          [
           1,
           77,
           22.14,
           "2012-09-13 01:00:00"
          ],
          [
           2,
           77,
           22.14,
           "2012-09-13 02:00:00"
          ],
          [
           3,
           83,
           21.32,
           "2012-09-13 03:00:00"
          ],
          [
           4,
           83,
           21.32,
           "2012-09-13 04:00:00"
          ],
          [
           5,
           83,
           21.32,
           "2012-09-13 05:00:00"
          ],
          [
           6,
           82,
           20.5,
           "2012-09-13 06:00:00"
          ],
          [
           7,
           77,
           22.14,
           "2012-09-13 07:00:00"
          ],
          [
           8,
           73,
           22.96,
           "2012-09-13 08:00:00"
          ],
          [
           9,
           64,
           24.6,
           "2012-09-13 09:00:00"
          ],
          [
           10,
           61,
           26.24,
           "2012-09-13 10:00:00"
          ],
          [
           11,
           50,
           27.06,
           "2012-09-13 11:00:00"
          ],
          [
           12,
           44,
           27.88,
           "2012-09-13 12:00:00"
          ],
          [
           13,
           42,
           28.7,
           "2012-09-13 13:00:00"
          ],
          [
           14,
           39,
           29.52,
           "2012-09-13 14:00:00"
          ],
          [
           15,
           42,
           29.52,
           "2012-09-13 15:00:00"
          ],
          [
           16,
           39,
           29.52,
           "2012-09-13 16:00:00"
          ],
          [
           17,
           42,
           29.52,
           "2012-09-13 17:00:00"
          ],
          [
           18,
           57,
           27.88,
           "2012-09-13 18:00:00"
          ],
          [
           19,
           65,
           26.24,
           "2012-09-13 19:00:00"
          ],
          [
           20,
           69,
           25.42,
           "2012-09-13 20:00:00"
          ],
          [
           21,
           65,
           25.42,
           "2012-09-13 21:00:00"
          ],
          [
           22,
           69,
           24.6,
           "2012-09-13 22:00:00"
          ],
          [
           23,
           73,
           23.78,
           "2012-09-13 23:00:00"
          ],
          [
           0,
           73,
           22.96,
           "2012-09-14 00:00:00"
          ],
          [
           1,
           73,
           22.96,
           "2012-09-14 01:00:00"
          ],
          [
           2,
           73,
           22.96,
           "2012-09-14 02:00:00"
          ],
          [
           3,
           77,
           22.14,
           "2012-09-14 03:00:00"
          ],
          [
           4,
           77,
           22.14,
           "2012-09-14 04:00:00"
          ],
          [
           5,
           83,
           22.14,
           "2012-09-14 05:00:00"
          ],
          [
           6,
           88,
           22.14,
           "2012-09-14 06:00:00"
          ],
          [
           7,
           88,
           22.96,
           "2012-09-14 07:00:00"
          ],
          [
           8,
           78,
           24.6,
           "2012-09-14 08:00:00"
          ],
          [
           9,
           78,
           25.42,
           "2012-09-14 09:00:00"
          ],
          [
           10,
           65,
           27.88,
           "2012-09-14 10:00:00"
          ],
          [
           11,
           61,
           27.88,
           "2012-09-14 11:00:00"
          ],
          [
           12,
           54,
           28.7,
           "2012-09-14 12:00:00"
          ],
          [
           13,
           54,
           28.7,
           "2012-09-14 13:00:00"
          ],
          [
           14,
           45,
           29.52,
           "2012-09-14 14:00:00"
          ],
          [
           15,
           48,
           29.52,
           "2012-09-14 15:00:00"
          ],
          [
           16,
           51,
           29.52,
           "2012-09-14 16:00:00"
          ],
          [
           17,
           51,
           29.52,
           "2012-09-14 17:00:00"
          ],
          [
           18,
           45,
           29.52,
           "2012-09-14 18:00:00"
          ],
          [
           19,
           57,
           27.88,
           "2012-09-14 19:00:00"
          ],
          [
           20,
           61,
           27.06,
           "2012-09-14 20:00:00"
          ],
          [
           21,
           73,
           26.24,
           "2012-09-14 21:00:00"
          ],
          [
           22,
           83,
           25.42,
           "2012-09-14 22:00:00"
          ],
          [
           23,
           78,
           25.42,
           "2012-09-14 23:00:00"
          ],
          [
           0,
           83,
           24.6,
           "2012-09-15 00:00:00"
          ],
          [
           1,
           73,
           24.6,
           "2012-09-15 01:00:00"
          ],
          [
           2,
           78,
           23.78,
           "2012-09-15 02:00:00"
          ],
          [
           3,
           73,
           24.6,
           "2012-09-15 03:00:00"
          ],
          [
           4,
           69,
           24.6,
           "2012-09-15 04:00:00"
          ],
          [
           5,
           60,
           23.78,
           "2012-09-15 05:00:00"
          ],
          [
           6,
           49,
           22.14,
           "2012-09-15 06:00:00"
          ],
          [
           7,
           52,
           22.14,
           "2012-09-15 07:00:00"
          ],
          [
           8,
           49,
           22.96,
           "2012-09-15 08:00:00"
          ],
          [
           9,
           43,
           24.6,
           "2012-09-15 09:00:00"
          ],
          [
           10,
           41,
           25.42,
           "2012-09-15 10:00:00"
          ],
          [
           11,
           38,
           26.24,
           "2012-09-15 11:00:00"
          ],
          [
           12,
           36,
           27.06,
           "2012-09-15 12:00:00"
          ],
          [
           13,
           36,
           27.88,
           "2012-09-15 13:00:00"
          ],
          [
           14,
           34,
           27.88,
           "2012-09-15 14:00:00"
          ],
          [
           15,
           34,
           27.88,
           "2012-09-15 15:00:00"
          ],
          [
           16,
           36,
           27.06,
           "2012-09-15 16:00:00"
          ],
          [
           17,
           36,
           27.06,
           "2012-09-15 17:00:00"
          ],
          [
           18,
           36,
           26.24,
           "2012-09-15 18:00:00"
          ],
          [
           19,
           41,
           25.42,
           "2012-09-15 19:00:00"
          ],
          [
           20,
           43,
           24.6,
           "2012-09-15 20:00:00"
          ],
          [
           21,
           52,
           22.96,
           "2012-09-15 21:00:00"
          ],
          [
           22,
           52,
           22.96,
           "2012-09-15 22:00:00"
          ],
          [
           23,
           60,
           22.14,
           "2012-09-15 23:00:00"
          ],
          [
           0,
           64,
           22.14,
           "2012-09-16 00:00:00"
          ],
          [
           1,
           64,
           22.14,
           "2012-09-16 01:00:00"
          ],
          [
           2,
           63,
           21.32,
           "2012-09-16 02:00:00"
          ],
          [
           3,
           68,
           20.5,
           "2012-09-16 03:00:00"
          ],
          [
           4,
           72,
           20.5,
           "2012-09-16 04:00:00"
          ],
          [
           5,
           72,
           20.5,
           "2012-09-16 05:00:00"
          ],
          [
           6,
           72,
           20.5,
           "2012-09-16 06:00:00"
          ],
          [
           7,
           77,
           20.5,
           "2012-09-16 07:00:00"
          ],
          [
           8,
           64,
           22.14,
           "2012-09-16 08:00:00"
          ],
          [
           9,
           60,
           23.78,
           "2012-09-16 09:00:00"
          ],
          [
           10,
           50,
           25.42,
           "2012-09-16 10:00:00"
          ],
          [
           11,
           47,
           26.24,
           "2012-09-16 11:00:00"
          ],
          [
           12,
           44,
           27.06,
           "2012-09-16 12:00:00"
          ],
          [
           13,
           41,
           26.24,
           "2012-09-16 13:00:00"
          ],
          [
           14,
           39,
           27.06,
           "2012-09-16 14:00:00"
          ],
          [
           15,
           41,
           26.24,
           "2012-09-16 15:00:00"
          ],
          [
           16,
           44,
           26.24,
           "2012-09-16 16:00:00"
          ],
          [
           17,
           41,
           27.06,
           "2012-09-16 17:00:00"
          ],
          [
           18,
           50,
           25.42,
           "2012-09-16 18:00:00"
          ],
          [
           19,
           50,
           25.42,
           "2012-09-16 19:00:00"
          ],
          [
           20,
           53,
           24.6,
           "2012-09-16 20:00:00"
          ],
          [
           21,
           56,
           24.6,
           "2012-09-16 21:00:00"
          ],
          [
           22,
           68,
           22.96,
           "2012-09-16 22:00:00"
          ],
          [
           23,
           68,
           22.14,
           "2012-09-16 23:00:00"
          ],
          [
           0,
           68,
           22.14,
           "2012-09-17 00:00:00"
          ],
          [
           1,
           72,
           21.32,
           "2012-09-17 01:00:00"
          ],
          [
           2,
           72,
           21.32,
           "2012-09-17 02:00:00"
          ],
          [
           3,
           77,
           20.5,
           "2012-09-17 03:00:00"
          ],
          [
           4,
           77,
           20.5,
           "2012-09-17 04:00:00"
          ],
          [
           5,
           82,
           19.68,
           "2012-09-17 05:00:00"
          ],
          [
           6,
           82,
           19.68,
           "2012-09-17 06:00:00"
          ],
          [
           7,
           77,
           21.32,
           "2012-09-17 07:00:00"
          ],
          [
           8,
           77,
           22.14,
           "2012-09-17 08:00:00"
          ],
          [
           9,
           68,
           23.78,
           "2012-09-17 09:00:00"
          ],
          [
           10,
           65,
           25.42,
           "2012-09-17 10:00:00"
          ],
          [
           11,
           69,
           25.42,
           "2012-09-17 11:00:00"
          ],
          [
           12,
           69,
           25.42,
           "2012-09-17 12:00:00"
          ],
          [
           13,
           65,
           26.24,
           "2012-09-17 13:00:00"
          ],
          [
           14,
           65,
           26.24,
           "2012-09-17 14:00:00"
          ],
          [
           15,
           65,
           26.24,
           "2012-09-17 15:00:00"
          ],
          [
           16,
           69,
           26.24,
           "2012-09-17 16:00:00"
          ],
          [
           17,
           65,
           26.24,
           "2012-09-17 17:00:00"
          ],
          [
           18,
           73,
           25.42,
           "2012-09-17 18:00:00"
          ],
          [
           19,
           73,
           25.42,
           "2012-09-17 19:00:00"
          ],
          [
           20,
           73,
           25.42,
           "2012-09-17 20:00:00"
          ],
          [
           21,
           83,
           25.42,
           "2012-09-17 21:00:00"
          ],
          [
           22,
           83,
           25.42,
           "2012-09-17 22:00:00"
          ],
          [
           23,
           94,
           24.6,
           "2012-09-17 23:00:00"
          ],
          [
           0,
           94,
           24.6,
           "2012-09-18 00:00:00"
          ],
          [
           1,
           94,
           24.6,
           "2012-09-18 01:00:00"
          ],
          [
           2,
           94,
           24.6,
           "2012-09-18 02:00:00"
          ],
          [
           3,
           94,
           25.42,
           "2012-09-18 03:00:00"
          ],
          [
           4,
           94,
           25.42,
           "2012-09-18 04:00:00"
          ],
          [
           5,
           89,
           26.24,
           "2012-09-18 05:00:00"
          ],
          [
           6,
           89,
           26.24,
           "2012-09-18 06:00:00"
          ],
          [
           7,
           89,
           26.24,
           "2012-09-18 07:00:00"
          ],
          [
           8,
           83,
           27.06,
           "2012-09-18 08:00:00"
          ],
          [
           9,
           83,
           27.06,
           "2012-09-18 09:00:00"
          ],
          [
           10,
           79,
           27.88,
           "2012-09-18 10:00:00"
          ],
          [
           11,
           79,
           27.88,
           "2012-09-18 11:00:00"
          ],
          [
           12,
           83,
           27.88,
           "2012-09-18 12:00:00"
          ],
          [
           13,
           74,
           28.7,
           "2012-09-18 13:00:00"
          ],
          [
           14,
           94,
           24.6,
           "2012-09-18 14:00:00"
          ],
          [
           15,
           88,
           24.6,
           "2012-09-18 15:00:00"
          ],
          [
           16,
           88,
           24.6,
           "2012-09-18 16:00:00"
          ],
          [
           17,
           88,
           24.6,
           "2012-09-18 17:00:00"
          ],
          [
           18,
           88,
           24.6,
           "2012-09-18 18:00:00"
          ],
          [
           19,
           88,
           24.6,
           "2012-09-18 19:00:00"
          ],
          [
           20,
           88,
           24.6,
           "2012-09-18 20:00:00"
          ],
          [
           21,
           88,
           24.6,
           "2012-09-18 21:00:00"
          ],
          [
           22,
           83,
           23.78,
           "2012-09-18 22:00:00"
          ],
          [
           23,
           83,
           22.96,
           "2012-09-18 23:00:00"
          ],
          [
           0,
           68,
           22.96,
           "2012-09-19 00:00:00"
          ],
          [
           1,
           68,
           22.14,
           "2012-09-19 01:00:00"
          ],
          [
           2,
           64,
           22.14,
           "2012-09-19 02:00:00"
          ],
          [
           3,
           63,
           21.32,
           "2012-09-19 03:00:00"
          ],
          [
           4,
           68,
           21.32,
           "2012-09-19 04:00:00"
          ],
          [
           5,
           68,
           21.32,
           "2012-09-19 05:00:00"
          ],
          [
           6,
           63,
           21.32,
           "2012-09-19 06:00:00"
          ],
          [
           7,
           63,
           21.32,
           "2012-09-19 07:00:00"
          ],
          [
           8,
           59,
           21.32,
           "2012-09-19 08:00:00"
          ],
          [
           9,
           60,
           22.14,
           "2012-09-19 09:00:00"
          ],
          [
           10,
           52,
           22.96,
           "2012-09-19 10:00:00"
          ],
          [
           11,
           43,
           24.6,
           "2012-09-19 11:00:00"
          ],
          [
           12,
           43,
           24.6,
           "2012-09-19 12:00:00"
          ],
          [
           13,
           40,
           24.6,
           "2012-09-19 13:00:00"
          ],
          [
           14,
           38,
           25.42,
           "2012-09-19 14:00:00"
          ],
          [
           15,
           35,
           25.42,
           "2012-09-19 15:00:00"
          ],
          [
           16,
           35,
           25.42,
           "2012-09-19 16:00:00"
          ],
          [
           17,
           38,
           24.6,
           "2012-09-19 17:00:00"
          ],
          [
           18,
           40,
           23.78,
           "2012-09-19 18:00:00"
          ],
          [
           19,
           43,
           22.96,
           "2012-09-19 19:00:00"
          ],
          [
           20,
           48,
           21.32,
           "2012-09-19 20:00:00"
          ],
          [
           21,
           59,
           20.5,
           "2012-09-19 21:00:00"
          ],
          [
           22,
           63,
           20.5,
           "2012-09-19 22:00:00"
          ],
          [
           23,
           67,
           19.68,
           "2012-09-19 23:00:00"
          ],
          [
           0,
           72,
           18.86,
           "2012-10-01 00:00:00"
          ],
          [
           1,
           77,
           18.04,
           "2012-10-01 01:00:00"
          ],
          [
           2,
           72,
           18.86,
           "2012-10-01 02:00:00"
          ],
          [
           3,
           77,
           18.04,
           "2012-10-01 03:00:00"
          ],
          [
           4,
           82,
           17.22,
           "2012-10-01 04:00:00"
          ],
          [
           5,
           77,
           18.04,
           "2012-10-01 05:00:00"
          ],
          [
           6,
           77,
           18.04,
           "2012-10-01 06:00:00"
          ],
          [
           7,
           77,
           18.04,
           "2012-10-01 07:00:00"
          ],
          [
           8,
           77,
           18.86,
           "2012-10-01 08:00:00"
          ],
          [
           9,
           63,
           21.32,
           "2012-10-01 09:00:00"
          ],
          [
           10,
           56,
           22.14,
           "2012-10-01 10:00:00"
          ],
          [
           11,
           46,
           23.78,
           "2012-10-01 11:00:00"
          ],
          [
           12,
           43,
           24.6,
           "2012-10-01 12:00:00"
          ],
          [
           13,
           43,
           24.6,
           "2012-10-01 13:00:00"
          ],
          [
           14,
           43,
           24.6,
           "2012-10-01 14:00:00"
          ],
          [
           15,
           43,
           25.42,
           "2012-10-01 15:00:00"
          ],
          [
           16,
           46,
           25.42,
           "2012-10-01 16:00:00"
          ],
          [
           17,
           60,
           22.96,
           "2012-10-01 17:00:00"
          ],
          [
           18,
           64,
           22.96,
           "2012-10-01 18:00:00"
          ],
          [
           19,
           68,
           22.14,
           "2012-10-01 19:00:00"
          ],
          [
           20,
           68,
           22.14,
           "2012-10-01 20:00:00"
          ],
          [
           21,
           73,
           22.14,
           "2012-10-01 21:00:00"
          ],
          [
           22,
           77,
           22.14,
           "2012-10-01 22:00:00"
          ],
          [
           23,
           77,
           22.14,
           "2012-10-01 23:00:00"
          ],
          [
           0,
           73,
           22.96,
           "2012-10-02 00:00:00"
          ],
          [
           1,
           77,
           22.14,
           "2012-10-02 01:00:00"
          ],
          [
           2,
           77,
           22.14,
           "2012-10-02 02:00:00"
          ],
          [
           3,
           88,
           22.14,
           "2012-10-02 03:00:00"
          ],
          [
           4,
           83,
           22.96,
           "2012-10-02 04:00:00"
          ],
          [
           5,
           83,
           22.96,
           "2012-10-02 05:00:00"
          ],
          [
           6,
           83,
           23.78,
           "2012-10-02 06:00:00"
          ],
          [
           7,
           83,
           23.78,
           "2012-10-02 07:00:00"
          ],
          [
           8,
           88,
           24.6,
           "2012-10-02 08:00:00"
          ],
          [
           9,
           88,
           23.78,
           "2012-10-02 09:00:00"
          ],
          [
           10,
           88,
           23.78,
           "2012-10-02 10:00:00"
          ],
          [
           11,
           94,
           23.78,
           "2012-10-02 11:00:00"
          ],
          [
           12,
           88,
           24.6,
           "2012-10-02 12:00:00"
          ],
          [
           13,
           88,
           24.6,
           "2012-10-02 13:00:00"
          ],
          [
           14,
           88,
           24.6,
           "2012-10-02 14:00:00"
          ],
          [
           15,
           83,
           25.42,
           "2012-10-02 15:00:00"
          ],
          [
           16,
           88,
           25.42,
           "2012-10-02 16:00:00"
          ],
          [
           17,
           88,
           25.42,
           "2012-10-02 17:00:00"
          ],
          [
           18,
           94,
           25.42,
           "2012-10-02 18:00:00"
          ],
          [
           19,
           94,
           25.42,
           "2012-10-02 19:00:00"
          ],
          [
           20,
           94,
           25.42,
           "2012-10-02 20:00:00"
          ],
          [
           21,
           94,
           25.42,
           "2012-10-02 21:00:00"
          ],
          [
           22,
           94,
           25.42,
           "2012-10-02 22:00:00"
          ],
          [
           23,
           94,
           25.42,
           "2012-10-02 23:00:00"
          ],
          [
           0,
           94,
           25.42,
           "2012-10-03 00:00:00"
          ],
          [
           1,
           94,
           25.42,
           "2012-10-03 01:00:00"
          ],
          [
           2,
           94,
           25.42,
           "2012-10-03 02:00:00"
          ],
          [
           3,
           94,
           24.6,
           "2012-10-03 03:00:00"
          ],
          [
           4,
           100,
           24.6,
           "2012-10-03 04:00:00"
          ],
          [
           5,
           94,
           25.42,
           "2012-10-03 05:00:00"
          ],
          [
           6,
           94,
           24.6,
           "2012-10-03 06:00:00"
          ],
          [
           7,
           94,
           24.6,
           "2012-10-03 07:00:00"
          ],
          [
           8,
           88,
           25.42,
           "2012-10-03 08:00:00"
          ],
          [
           9,
           83,
           25.42,
           "2012-10-03 09:00:00"
          ],
          [
           10,
           78,
           27.06,
           "2012-10-03 10:00:00"
          ],
          [
           11,
           78,
           27.06,
           "2012-10-03 11:00:00"
          ],
          [
           12,
           70,
           28.7,
           "2012-10-03 12:00:00"
          ],
          [
           13,
           74,
           28.7,
           "2012-10-03 13:00:00"
          ],
          [
           14,
           70,
           29.52,
           "2012-10-03 14:00:00"
          ],
          [
           15,
           62,
           29.52,
           "2012-10-03 15:00:00"
          ],
          [
           16,
           58,
           29.52,
           "2012-10-03 16:00:00"
          ],
          [
           17,
           65,
           28.7,
           "2012-10-03 17:00:00"
          ],
          [
           18,
           65,
           28.7,
           "2012-10-03 18:00:00"
          ],
          [
           19,
           65,
           28.7,
           "2012-10-03 19:00:00"
          ],
          [
           20,
           65,
           28.7,
           "2012-10-03 20:00:00"
          ],
          [
           21,
           74,
           27.06,
           "2012-10-03 21:00:00"
          ],
          [
           22,
           74,
           27.06,
           "2012-10-03 22:00:00"
          ],
          [
           23,
           78,
           27.06,
           "2012-10-03 23:00:00"
          ],
          [
           0,
           89,
           26.24,
           "2012-10-04 00:00:00"
          ],
          [
           1,
           94,
           25.42,
           "2012-10-04 01:00:00"
          ],
          [
           2,
           89,
           26.24,
           "2012-10-04 02:00:00"
          ],
          [
           3,
           88,
           25.42,
           "2012-10-04 03:00:00"
          ],
          [
           4,
           89,
           26.24,
           "2012-10-04 04:00:00"
          ],
          [
           5,
           89,
           26.24,
           "2012-10-04 05:00:00"
          ],
          [
           6,
           94,
           25.42,
           "2012-10-04 06:00:00"
          ],
          [
           7,
           89,
           26.24,
           "2012-10-04 07:00:00"
          ],
          [
           8,
           89,
           26.24,
           "2012-10-04 08:00:00"
          ],
          [
           9,
           89,
           26.24,
           "2012-10-04 09:00:00"
          ],
          [
           10,
           83,
           27.06,
           "2012-10-04 10:00:00"
          ],
          [
           11,
           70,
           28.7,
           "2012-10-04 11:00:00"
          ],
          [
           12,
           54,
           29.52,
           "2012-10-04 12:00:00"
          ],
          [
           13,
           58,
           29.52,
           "2012-10-04 13:00:00"
          ],
          [
           14,
           61,
           28.7,
           "2012-10-04 14:00:00"
          ],
          [
           15,
           54,
           29.52,
           "2012-10-04 15:00:00"
          ],
          [
           16,
           54,
           28.7,
           "2012-10-04 16:00:00"
          ],
          [
           17,
           51,
           28.7,
           "2012-10-04 17:00:00"
          ],
          [
           18,
           57,
           27.06,
           "2012-10-04 18:00:00"
          ],
          [
           19,
           57,
           27.06,
           "2012-10-04 19:00:00"
          ],
          [
           20,
           65,
           26.24,
           "2012-10-04 20:00:00"
          ],
          [
           21,
           69,
           25.42,
           "2012-10-04 21:00:00"
          ],
          [
           22,
           47,
           26.24,
           "2012-10-04 22:00:00"
          ],
          [
           23,
           56,
           24.6,
           "2012-10-04 23:00:00"
          ],
          [
           0,
           73,
           22.96,
           "2012-10-05 00:00:00"
          ],
          [
           1,
           68,
           22.14,
           "2012-10-05 01:00:00"
          ],
          [
           2,
           73,
           22.14,
           "2012-10-05 02:00:00"
          ],
          [
           3,
           73,
           22.14,
           "2012-10-05 03:00:00"
          ],
          [
           4,
           77,
           22.14,
           "2012-10-05 04:00:00"
          ],
          [
           5,
           77,
           21.32,
           "2012-10-05 05:00:00"
          ],
          [
           6,
           83,
           21.32,
           "2012-10-05 06:00:00"
          ],
          [
           7,
           83,
           21.32,
           "2012-10-05 07:00:00"
          ],
          [
           8,
           64,
           23.78,
           "2012-10-05 08:00:00"
          ],
          [
           9,
           60,
           24.6,
           "2012-10-05 09:00:00"
          ],
          [
           10,
           54,
           27.06,
           "2012-10-05 10:00:00"
          ],
          [
           11,
           48,
           28.7,
           "2012-10-05 11:00:00"
          ],
          [
           12,
           42,
           29.52,
           "2012-10-05 12:00:00"
          ],
          [
           13,
           48,
           28.7,
           "2012-10-05 13:00:00"
          ],
          [
           14,
           37,
           30.34,
           "2012-10-05 14:00:00"
          ],
          [
           15,
           39,
           29.52,
           "2012-10-05 15:00:00"
          ],
          [
           16,
           37,
           29.52,
           "2012-10-05 16:00:00"
          ],
          [
           17,
           42,
           28.7,
           "2012-10-05 17:00:00"
          ],
          [
           18,
           57,
           26.24,
           "2012-10-05 18:00:00"
          ],
          [
           19,
           73,
           25.42,
           "2012-10-05 19:00:00"
          ],
          [
           20,
           78,
           24.6,
           "2012-10-05 20:00:00"
          ],
          [
           21,
           69,
           24.6,
           "2012-10-05 21:00:00"
          ],
          [
           22,
           73,
           24.6,
           "2012-10-05 22:00:00"
          ],
          [
           23,
           78,
           23.78,
           "2012-10-05 23:00:00"
          ],
          [
           0,
           83,
           22.96,
           "2012-10-06 00:00:00"
          ],
          [
           1,
           83,
           22.96,
           "2012-10-06 01:00:00"
          ],
          [
           2,
           78,
           22.96,
           "2012-10-06 02:00:00"
          ],
          [
           3,
           77,
           22.14,
           "2012-10-06 03:00:00"
          ],
          [
           4,
           83,
           22.14,
           "2012-10-06 04:00:00"
          ],
          [
           5,
           83,
           22.14,
           "2012-10-06 05:00:00"
          ],
          [
           6,
           88,
           22.14,
           "2012-10-06 06:00:00"
          ],
          [
           7,
           83,
           22.14,
           "2012-10-06 07:00:00"
          ],
          [
           8,
           83,
           22.96,
           "2012-10-06 08:00:00"
          ],
          [
           9,
           73,
           24.6,
           "2012-10-06 09:00:00"
          ],
          [
           10,
           69,
           25.42,
           "2012-10-06 10:00:00"
          ],
          [
           11,
           65,
           26.24,
           "2012-10-06 11:00:00"
          ],
          [
           12,
           54,
           28.7,
           "2012-10-06 12:00:00"
          ],
          [
           13,
           57,
           26.24,
           "2012-10-06 13:00:00"
          ],
          [
           14,
           56,
           24.6,
           "2012-10-06 14:00:00"
          ],
          [
           15,
           46,
           24.6,
           "2012-10-06 15:00:00"
          ],
          [
           16,
           43,
           24.6,
           "2012-10-06 16:00:00"
          ],
          [
           17,
           49,
           22.14,
           "2012-10-06 17:00:00"
          ],
          [
           18,
           48,
           21.32,
           "2012-10-06 18:00:00"
          ],
          [
           19,
           55,
           19.68,
           "2012-10-06 19:00:00"
          ],
          [
           20,
           55,
           19.68,
           "2012-10-06 20:00:00"
          ],
          [
           21,
           59,
           18.86,
           "2012-10-06 21:00:00"
          ],
          [
           22,
           62,
           18.04,
           "2012-10-06 22:00:00"
          ],
          [
           23,
           62,
           18.04,
           "2012-10-06 23:00:00"
          ],
          [
           0,
           62,
           18.04,
           "2012-10-07 00:00:00"
          ],
          [
           1,
           54,
           18.04,
           "2012-10-07 01:00:00"
          ],
          [
           2,
           62,
           17.22,
           "2012-10-07 02:00:00"
          ],
          [
           3,
           62,
           18.04,
           "2012-10-07 03:00:00"
          ],
          [
           4,
           54,
           18.04,
           "2012-10-07 04:00:00"
          ],
          [
           5,
           54,
           18.04,
           "2012-10-07 05:00:00"
          ],
          [
           6,
           54,
           18.04,
           "2012-10-07 06:00:00"
          ],
          [
           7,
           58,
           17.22,
           "2012-10-07 07:00:00"
          ],
          [
           8,
           67,
           17.22,
           "2012-10-07 08:00:00"
          ],
          [
           9,
           71,
           16.4,
           "2012-10-07 09:00:00"
          ],
          [
           10,
           67,
           17.22,
           "2012-10-07 10:00:00"
          ],
          [
           11,
           71,
           17.22,
           "2012-10-07 11:00:00"
          ],
          [
           12,
           71,
           17.22,
           "2012-10-07 12:00:00"
          ],
          [
           13,
           72,
           18.04,
           "2012-10-07 13:00:00"
          ],
          [
           14,
           67,
           18.04,
           "2012-10-07 14:00:00"
          ],
          [
           15,
           77,
           17.22,
           "2012-10-07 15:00:00"
          ],
          [
           16,
           82,
           16.4,
           "2012-10-07 16:00:00"
          ],
          [
           17,
           82,
           16.4,
           "2012-10-07 17:00:00"
          ],
          [
           18,
           82,
           16.4,
           "2012-10-07 18:00:00"
          ],
          [
           19,
           82,
           16.4,
           "2012-10-07 19:00:00"
          ],
          [
           20,
           82,
           16.4,
           "2012-10-07 20:00:00"
          ],
          [
           21,
           87,
           15.58,
           "2012-10-07 21:00:00"
          ],
          [
           22,
           87,
           15.58,
           "2012-10-07 22:00:00"
          ],
          [
           23,
           93,
           14.76,
           "2012-10-07 23:00:00"
          ],
          [
           0,
           76,
           15.58,
           "2012-10-08 00:00:00"
          ],
          [
           1,
           87,
           13.94,
           "2012-10-08 01:00:00"
          ],
          [
           2,
           81,
           13.94,
           "2012-10-08 02:00:00"
          ],
          [
           3,
           81,
           13.94,
           "2012-10-08 03:00:00"
          ],
          [
           4,
           87,
           13.12,
           "2012-10-08 04:00:00"
          ],
          [
           5,
           76,
           13.94,
           "2012-10-08 05:00:00"
          ],
          [
           6,
           76,
           13.94,
           "2012-10-08 06:00:00"
          ],
          [
           7,
           76,
           13.94,
           "2012-10-08 07:00:00"
          ],
          [
           8,
           71,
           14.76,
           "2012-10-08 08:00:00"
          ],
          [
           9,
           66,
           15.58,
           "2012-10-08 09:00:00"
          ],
          [
           10,
           68,
           15.58,
           "2012-10-08 10:00:00"
          ],
          [
           11,
           62,
           16.4,
           "2012-10-08 11:00:00"
          ],
          [
           12,
           63,
           17.22,
           "2012-10-08 12:00:00"
          ],
          [
           13,
           62,
           17.22,
           "2012-10-08 13:00:00"
          ],
          [
           14,
           58,
           17.22,
           "2012-10-08 14:00:00"
          ],
          [
           15,
           58,
           17.22,
           "2012-10-08 15:00:00"
          ],
          [
           16,
           58,
           17.22,
           "2012-10-08 16:00:00"
          ],
          [
           17,
           66,
           17.22,
           "2012-10-08 17:00:00"
          ],
          [
           18,
           66,
           17.22,
           "2012-10-08 18:00:00"
          ],
          [
           19,
           71,
           16.4,
           "2012-10-08 19:00:00"
          ],
          [
           20,
           71,
           16.4,
           "2012-10-08 20:00:00"
          ],
          [
           21,
           76,
           16.4,
           "2012-10-08 21:00:00"
          ],
          [
           22,
           76,
           16.4,
           "2012-10-08 22:00:00"
          ],
          [
           23,
           71,
           16.4,
           "2012-10-08 23:00:00"
          ],
          [
           0,
           82,
           15.58,
           "2012-10-09 00:00:00"
          ],
          [
           1,
           87,
           14.76,
           "2012-10-09 01:00:00"
          ],
          [
           2,
           87,
           14.76,
           "2012-10-09 02:00:00"
          ],
          [
           3,
           87,
           14.76,
           "2012-10-09 03:00:00"
          ],
          [
           4,
           87,
           14.76,
           "2012-10-09 04:00:00"
          ],
          [
           5,
           82,
           15.58,
           "2012-10-09 05:00:00"
          ],
          [
           6,
           82,
           15.58,
           "2012-10-09 06:00:00"
          ],
          [
           7,
           83,
           15.58,
           "2012-10-09 07:00:00"
          ],
          [
           8,
           80,
           17.22,
           "2012-10-09 08:00:00"
          ],
          [
           9,
           77,
           17.22,
           "2012-10-09 09:00:00"
          ],
          [
           10,
           75,
           18.04,
           "2012-10-09 10:00:00"
          ],
          [
           11,
           69,
           19.68,
           "2012-10-09 11:00:00"
          ],
          [
           12,
           69,
           19.68,
           "2012-10-09 12:00:00"
          ],
          [
           13,
           67,
           20.5,
           "2012-10-09 13:00:00"
          ],
          [
           14,
           64,
           22.14,
           "2012-10-09 14:00:00"
          ],
          [
           15,
           63,
           21.32,
           "2012-10-09 15:00:00"
          ],
          [
           16,
           72,
           20.5,
           "2012-10-09 16:00:00"
          ],
          [
           17,
           68,
           21.32,
           "2012-10-09 17:00:00"
          ],
          [
           18,
           72,
           20.5,
           "2012-10-09 18:00:00"
          ],
          [
           19,
           72,
           20.5,
           "2012-10-09 19:00:00"
          ],
          [
           20,
           72,
           20.5,
           "2012-10-09 20:00:00"
          ],
          [
           21,
           77,
           19.68,
           "2012-10-09 21:00:00"
          ],
          [
           22,
           77,
           19.68,
           "2012-10-09 22:00:00"
          ],
          [
           23,
           77,
           19.68,
           "2012-10-09 23:00:00"
          ],
          [
           0,
           88,
           18.86,
           "2012-10-10 00:00:00"
          ],
          [
           1,
           88,
           18.86,
           "2012-10-10 01:00:00"
          ],
          [
           2,
           88,
           18.86,
           "2012-10-10 02:00:00"
          ],
          [
           3,
           88,
           18.86,
           "2012-10-10 03:00:00"
          ],
          [
           4,
           88,
           18.86,
           "2012-10-10 04:00:00"
          ],
          [
           5,
           88,
           18.86,
           "2012-10-10 05:00:00"
          ],
          [
           6,
           88,
           18.86,
           "2012-10-10 06:00:00"
          ],
          [
           7,
           82,
           18.86,
           "2012-10-10 07:00:00"
          ],
          [
           8,
           77,
           20.5,
           "2012-10-10 08:00:00"
          ],
          [
           9,
           60,
           22.14,
           "2012-10-10 09:00:00"
          ],
          [
           10,
           52,
           22.96,
           "2012-10-10 10:00:00"
          ],
          [
           11,
           52,
           22.14,
           "2012-10-10 11:00:00"
          ],
          [
           12,
           56,
           22.14,
           "2012-10-10 12:00:00"
          ],
          [
           13,
           49,
           22.96,
           "2012-10-10 13:00:00"
          ],
          [
           14,
           40,
           24.6,
           "2012-10-10 14:00:00"
          ],
          [
           15,
           40,
           24.6,
           "2012-10-10 15:00:00"
          ],
          [
           16,
           40,
           24.6,
           "2012-10-10 16:00:00"
          ],
          [
           17,
           43,
           23.78,
           "2012-10-10 17:00:00"
          ],
          [
           18,
           49,
           22.96,
           "2012-10-10 18:00:00"
          ],
          [
           19,
           46,
           22.96,
           "2012-10-10 19:00:00"
          ],
          [
           20,
           48,
           21.32,
           "2012-10-10 20:00:00"
          ],
          [
           21,
           51,
           20.5,
           "2012-10-10 21:00:00"
          ],
          [
           22,
           55,
           18.86,
           "2012-10-10 22:00:00"
          ],
          [
           23,
           58,
           18.04,
           "2012-10-10 23:00:00"
          ],
          [
           0,
           51,
           18.04,
           "2012-10-11 00:00:00"
          ],
          [
           1,
           47,
           18.04,
           "2012-10-11 01:00:00"
          ],
          [
           2,
           50,
           17.22,
           "2012-10-11 02:00:00"
          ],
          [
           3,
           47,
           17.22,
           "2012-10-11 03:00:00"
          ],
          [
           4,
           50,
           16.4,
           "2012-10-11 04:00:00"
          ],
          [
           5,
           50,
           14.76,
           "2012-10-11 05:00:00"
          ],
          [
           6,
           50,
           14.76,
           "2012-10-11 06:00:00"
          ],
          [
           7,
           50,
           14.76,
           "2012-10-11 07:00:00"
          ],
          [
           8,
           46,
           15.58,
           "2012-10-11 08:00:00"
          ],
          [
           9,
           43,
           16.4,
           "2012-10-11 09:00:00"
          ],
          [
           10,
           41,
           18.04,
           "2012-10-11 10:00:00"
          ],
          [
           11,
           36,
           18.86,
           "2012-10-11 11:00:00"
          ],
          [
           12,
           36,
           18.86,
           "2012-10-11 12:00:00"
          ],
          [
           13,
           31,
           20.5,
           "2012-10-11 13:00:00"
          ],
          [
           14,
           32,
           21.32,
           "2012-10-11 14:00:00"
          ],
          [
           15,
           34,
           21.32,
           "2012-10-11 15:00:00"
          ],
          [
           16,
           36,
           20.5,
           "2012-10-11 16:00:00"
          ],
          [
           17,
           39,
           20.5,
           "2012-10-11 17:00:00"
          ],
          [
           18,
           44,
           18.86,
           "2012-10-11 18:00:00"
          ],
          [
           19,
           51,
           18.04,
           "2012-10-11 19:00:00"
          ],
          [
           20,
           62,
           17.22,
           "2012-10-11 20:00:00"
          ],
          [
           21,
           62,
           17.22,
           "2012-10-11 21:00:00"
          ],
          [
           22,
           66,
           16.4,
           "2012-10-11 22:00:00"
          ],
          [
           23,
           58,
           17.22,
           "2012-10-11 23:00:00"
          ],
          [
           0,
           66,
           16.4,
           "2012-10-12 00:00:00"
          ],
          [
           1,
           66,
           16.4,
           "2012-10-12 01:00:00"
          ],
          [
           2,
           66,
           16.4,
           "2012-10-12 02:00:00"
          ],
          [
           3,
           76,
           14.76,
           "2012-10-12 03:00:00"
          ],
          [
           4,
           76,
           14.76,
           "2012-10-12 04:00:00"
          ],
          [
           5,
           81,
           14.76,
           "2012-10-12 05:00:00"
          ],
          [
           6,
           81,
           13.94,
           "2012-10-12 06:00:00"
          ],
          [
           7,
           81,
           14.76,
           "2012-10-12 07:00:00"
          ],
          [
           8,
           71,
           17.22,
           "2012-10-12 08:00:00"
          ],
          [
           9,
           39,
           20.5,
           "2012-10-12 09:00:00"
          ],
          [
           10,
           36,
           21.32,
           "2012-10-12 10:00:00"
          ],
          [
           11,
           37,
           22.14,
           "2012-10-12 11:00:00"
          ],
          [
           12,
           39,
           22.14,
           "2012-10-12 12:00:00"
          ],
          [
           13,
           37,
           22.96,
           "2012-10-12 13:00:00"
          ],
          [
           14,
           37,
           22.96,
           "2012-10-12 14:00:00"
          ],
          [
           15,
           42,
           21.32,
           "2012-10-12 15:00:00"
          ],
          [
           16,
           41,
           18.86,
           "2012-10-12 16:00:00"
          ],
          [
           17,
           38,
           18.86,
           "2012-10-12 17:00:00"
          ],
          [
           18,
           38,
           18.04,
           "2012-10-12 18:00:00"
          ],
          [
           19,
           41,
           17.22,
           "2012-10-12 19:00:00"
          ],
          [
           20,
           47,
           17.22,
           "2012-10-12 20:00:00"
          ],
          [
           21,
           54,
           16.4,
           "2012-10-12 21:00:00"
          ],
          [
           22,
           47,
           16.4,
           "2012-10-12 22:00:00"
          ],
          [
           23,
           57,
           14.76,
           "2012-10-12 23:00:00"
          ],
          [
           0,
           57,
           14.76,
           "2012-10-13 00:00:00"
          ],
          [
           1,
           53,
           13.94,
           "2012-10-13 01:00:00"
          ],
          [
           2,
           53,
           13.94,
           "2012-10-13 02:00:00"
          ],
          [
           3,
           66,
           13.12,
           "2012-10-13 03:00:00"
          ],
          [
           4,
           65,
           12.3,
           "2012-10-13 04:00:00"
          ],
          [
           5,
           61,
           12.3,
           "2012-10-13 05:00:00"
          ],
          [
           6,
           61,
           12.3,
           "2012-10-13 06:00:00"
          ],
          [
           7,
           61,
           12.3,
           "2012-10-13 07:00:00"
          ],
          [
           8,
           53,
           13.94,
           "2012-10-13 08:00:00"
          ],
          [
           9,
           50,
           14.76,
           "2012-10-13 09:00:00"
          ],
          [
           10,
           43,
           16.4,
           "2012-10-13 10:00:00"
          ],
          [
           11,
           35,
           17.22,
           "2012-10-13 11:00:00"
          ],
          [
           12,
           35,
           18.04,
           "2012-10-13 12:00:00"
          ],
          [
           13,
           36,
           18.86,
           "2012-10-13 13:00:00"
          ],
          [
           14,
           33,
           19.68,
           "2012-10-13 14:00:00"
          ],
          [
           15,
           36,
           20.5,
           "2012-10-13 15:00:00"
          ],
          [
           16,
           31,
           20.5,
           "2012-10-13 16:00:00"
          ],
          [
           17,
           38,
           18.86,
           "2012-10-13 17:00:00"
          ],
          [
           18,
           44,
           18.86,
           "2012-10-13 18:00:00"
          ],
          [
           19,
           44,
           18.04,
           "2012-10-13 19:00:00"
          ],
          [
           20,
           54,
           16.4,
           "2012-10-13 20:00:00"
          ],
          [
           21,
           58,
           16.4,
           "2012-10-13 21:00:00"
          ],
          [
           22,
           62,
           16.4,
           "2012-10-13 22:00:00"
          ],
          [
           23,
           58,
           17.22,
           "2012-10-13 23:00:00"
          ],
          [
           0,
           71,
           16.4,
           "2012-10-14 00:00:00"
          ],
          [
           1,
           77,
           17.22,
           "2012-10-14 01:00:00"
          ],
          [
           2,
           76,
           16.4,
           "2012-10-14 02:00:00"
          ],
          [
           3,
           77,
           17.22,
           "2012-10-14 03:00:00"
          ],
          [
           4,
           77,
           17.22,
           "2012-10-14 04:00:00"
          ],
          [
           5,
           82,
           16.4,
           "2012-10-14 05:00:00"
          ],
          [
           6,
           82,
           16.4,
           "2012-10-14 06:00:00"
          ],
          [
           7,
           82,
           17.22,
           "2012-10-14 07:00:00"
          ],
          [
           8,
           77,
           18.04,
           "2012-10-14 08:00:00"
          ],
          [
           9,
           67,
           19.68,
           "2012-10-14 09:00:00"
          ],
          [
           10,
           56,
           22.14,
           "2012-10-14 10:00:00"
          ],
          [
           11,
           52,
           22.96,
           "2012-10-14 11:00:00"
          ],
          [
           12,
           46,
           25.42,
           "2012-10-14 12:00:00"
          ],
          [
           13,
           41,
           26.24,
           "2012-10-14 13:00:00"
          ],
          [
           14,
           39,
           27.06,
           "2012-10-14 14:00:00"
          ],
          [
           15,
           39,
           27.06,
           "2012-10-14 15:00:00"
          ],
          [
           16,
           41,
           26.24,
           "2012-10-14 16:00:00"
          ],
          [
           17,
           44,
           26.24,
           "2012-10-14 17:00:00"
          ],
          [
           18,
           60,
           23.78,
           "2012-10-14 18:00:00"
          ],
          [
           19,
           64,
           22.96,
           "2012-10-14 19:00:00"
          ],
          [
           20,
           73,
           22.14,
           "2012-10-14 20:00:00"
          ],
          [
           21,
           73,
           22.96,
           "2012-10-14 21:00:00"
          ],
          [
           22,
           73,
           22.96,
           "2012-10-14 22:00:00"
          ],
          [
           23,
           68,
           22.96,
           "2012-10-14 23:00:00"
          ],
          [
           0,
           73,
           22.96,
           "2012-10-15 00:00:00"
          ],
          [
           1,
           64,
           23.78,
           "2012-10-15 01:00:00"
          ],
          [
           2,
           64,
           23.78,
           "2012-10-15 02:00:00"
          ],
          [
           3,
           73,
           22.96,
           "2012-10-15 03:00:00"
          ],
          [
           4,
           68,
           22.96,
           "2012-10-15 04:00:00"
          ],
          [
           5,
           73,
           22.96,
           "2012-10-15 05:00:00"
          ],
          [
           6,
           73,
           22.96,
           "2012-10-15 06:00:00"
          ],
          [
           7,
           68,
           23.78,
           "2012-10-15 07:00:00"
          ],
          [
           8,
           64,
           24.6,
           "2012-10-15 08:00:00"
          ],
          [
           9,
           69,
           24.6,
           "2012-10-15 09:00:00"
          ],
          [
           10,
           73,
           24.6,
           "2012-10-15 10:00:00"
          ],
          [
           11,
           73,
           24.6,
           "2012-10-15 11:00:00"
          ],
          [
           12,
           78,
           24.6,
           "2012-10-15 12:00:00"
          ],
          [
           13,
           88,
           22.96,
           "2012-10-15 13:00:00"
          ],
          [
           14,
           78,
           24.6,
           "2012-10-15 14:00:00"
          ],
          [
           15,
           78,
           24.6,
           "2012-10-15 15:00:00"
          ],
          [
           16,
           64,
           22.96,
           "2012-10-15 16:00:00"
          ],
          [
           17,
           64,
           22.96,
           "2012-10-15 17:00:00"
          ],
          [
           18,
           77,
           22.14,
           "2012-10-15 18:00:00"
          ],
          [
           19,
           83,
           21.32,
           "2012-10-15 19:00:00"
          ],
          [
           20,
           72,
           21.32,
           "2012-10-15 20:00:00"
          ],
          [
           21,
           59,
           21.32,
           "2012-10-15 21:00:00"
          ],
          [
           22,
           59,
           20.5,
           "2012-10-15 22:00:00"
          ],
          [
           23,
           63,
           18.86,
           "2012-10-15 23:00:00"
          ],
          [
           0,
           63,
           18.86,
           "2012-10-16 00:00:00"
          ],
          [
           1,
           67,
           18.04,
           "2012-10-16 01:00:00"
          ],
          [
           2,
           67,
           18.04,
           "2012-10-16 02:00:00"
          ],
          [
           3,
           67,
           17.22,
           "2012-10-16 03:00:00"
          ],
          [
           4,
           67,
           17.22,
           "2012-10-16 04:00:00"
          ],
          [
           5,
           67,
           17.22,
           "2012-10-16 05:00:00"
          ],
          [
           6,
           67,
           17.22,
           "2012-10-16 06:00:00"
          ],
          [
           7,
           67,
           17.22,
           "2012-10-16 07:00:00"
          ],
          [
           8,
           62,
           18.04,
           "2012-10-16 08:00:00"
          ],
          [
           9,
           55,
           19.68,
           "2012-10-16 09:00:00"
          ],
          [
           10,
           48,
           20.5,
           "2012-10-16 10:00:00"
          ],
          [
           11,
           45,
           20.5,
           "2012-10-16 11:00:00"
          ],
          [
           12,
           45,
           21.32,
           "2012-10-16 12:00:00"
          ],
          [
           13,
           45,
           21.32,
           "2012-10-16 13:00:00"
          ],
          [
           14,
           39,
           22.14,
           "2012-10-16 14:00:00"
          ],
          [
           15,
           41,
           22.14,
           "2012-10-16 15:00:00"
          ],
          [
           16,
           39,
           22.14,
           "2012-10-16 16:00:00"
          ],
          [
           17,
           39,
           21.32,
           "2012-10-16 17:00:00"
          ],
          [
           18,
           42,
           20.5,
           "2012-10-16 18:00:00"
          ],
          [
           19,
           48,
           19.68,
           "2012-10-16 19:00:00"
          ],
          [
           20,
           55,
           18.86,
           "2012-10-16 20:00:00"
          ],
          [
           21,
           63,
           18.86,
           "2012-10-16 21:00:00"
          ],
          [
           22,
           71,
           16.4,
           "2012-10-16 22:00:00"
          ],
          [
           23,
           71,
           16.4,
           "2012-10-16 23:00:00"
          ],
          [
           0,
           76,
           15.58,
           "2012-10-17 00:00:00"
          ],
          [
           1,
           76,
           15.58,
           "2012-10-17 01:00:00"
          ],
          [
           2,
           76,
           15.58,
           "2012-10-17 02:00:00"
          ],
          [
           3,
           87,
           14.76,
           "2012-10-17 03:00:00"
          ],
          [
           4,
           81,
           14.76,
           "2012-10-17 04:00:00"
          ],
          [
           5,
           81,
           14.76,
           "2012-10-17 05:00:00"
          ],
          [
           6,
           82,
           15.58,
           "2012-10-17 06:00:00"
          ],
          [
           7,
           81,
           14.76,
           "2012-10-17 07:00:00"
          ],
          [
           8,
           76,
           16.4,
           "2012-10-17 08:00:00"
          ],
          [
           9,
           77,
           17.22,
           "2012-10-17 09:00:00"
          ],
          [
           10,
           67,
           18.86,
           "2012-10-17 10:00:00"
          ],
          [
           11,
           51,
           20.5,
           "2012-10-17 11:00:00"
          ],
          [
           12,
           48,
           21.32,
           "2012-10-17 12:00:00"
          ],
          [
           13,
           49,
           22.14,
           "2012-10-17 13:00:00"
          ],
          [
           14,
           43,
           22.96,
           "2012-10-17 14:00:00"
          ],
          [
           15,
           43,
           23.78,
           "2012-10-17 15:00:00"
          ],
          [
           16,
           52,
           22.96,
           "2012-10-17 16:00:00"
          ],
          [
           17,
           56,
           22.14,
           "2012-10-17 17:00:00"
          ],
          [
           18,
           59,
           21.32,
           "2012-10-17 18:00:00"
          ],
          [
           19,
           72,
           20.5,
           "2012-10-17 19:00:00"
          ],
          [
           20,
           72,
           20.5,
           "2012-10-17 20:00:00"
          ],
          [
           21,
           82,
           18.86,
           "2012-10-17 21:00:00"
          ],
          [
           22,
           88,
           18.86,
           "2012-10-17 22:00:00"
          ],
          [
           23,
           88,
           18.86,
           "2012-10-17 23:00:00"
          ],
          [
           0,
           88,
           18.86,
           "2012-10-18 00:00:00"
          ],
          [
           1,
           82,
           18.86,
           "2012-10-18 01:00:00"
          ],
          [
           2,
           82,
           18.86,
           "2012-10-18 02:00:00"
          ],
          [
           3,
           88,
           18.04,
           "2012-10-18 03:00:00"
          ],
          [
           4,
           88,
           18.04,
           "2012-10-18 04:00:00"
          ],
          [
           5,
           82,
           18.04,
           "2012-10-18 05:00:00"
          ],
          [
           6,
           88,
           18.04,
           "2012-10-18 06:00:00"
          ],
          [
           7,
           88,
           18.04,
           "2012-10-18 07:00:00"
          ],
          [
           8,
           82,
           18.86,
           "2012-10-18 08:00:00"
          ],
          [
           9,
           77,
           20.5,
           "2012-10-18 09:00:00"
          ],
          [
           10,
           68,
           21.32,
           "2012-10-18 10:00:00"
          ],
          [
           11,
           56,
           22.96,
           "2012-10-18 11:00:00"
          ],
          [
           12,
           53,
           24.6,
           "2012-10-18 12:00:00"
          ],
          [
           13,
           53,
           25.42,
           "2012-10-18 13:00:00"
          ],
          [
           14,
           50,
           25.42,
           "2012-10-18 14:00:00"
          ],
          [
           15,
           60,
           24.6,
           "2012-10-18 15:00:00"
          ],
          [
           16,
           56,
           24.6,
           "2012-10-18 16:00:00"
          ],
          [
           17,
           64,
           23.78,
           "2012-10-18 17:00:00"
          ],
          [
           18,
           64,
           22.96,
           "2012-10-18 18:00:00"
          ],
          [
           19,
           68,
           22.96,
           "2012-10-18 19:00:00"
          ],
          [
           20,
           68,
           22.96,
           "2012-10-18 20:00:00"
          ],
          [
           21,
           77,
           22.14,
           "2012-10-18 21:00:00"
          ],
          [
           22,
           83,
           22.14,
           "2012-10-18 22:00:00"
          ],
          [
           23,
           83,
           22.14,
           "2012-10-18 23:00:00"
          ],
          [
           0,
           83,
           22.96,
           "2012-10-19 00:00:00"
          ],
          [
           1,
           88,
           22.14,
           "2012-10-19 01:00:00"
          ],
          [
           2,
           88,
           22.14,
           "2012-10-19 02:00:00"
          ],
          [
           3,
           83,
           22.96,
           "2012-10-19 03:00:00"
          ],
          [
           4,
           83,
           22.96,
           "2012-10-19 04:00:00"
          ],
          [
           5,
           88,
           22.14,
           "2012-10-19 05:00:00"
          ],
          [
           6,
           94,
           22.14,
           "2012-10-19 06:00:00"
          ],
          [
           7,
           94,
           22.14,
           "2012-10-19 07:00:00"
          ],
          [
           8,
           94,
           22.14,
           "2012-10-19 08:00:00"
          ],
          [
           9,
           94,
           22.14,
           "2012-10-19 09:00:00"
          ],
          [
           10,
           88,
           23.78,
           "2012-10-19 10:00:00"
          ],
          [
           11,
           83,
           24.6,
           "2012-10-19 11:00:00"
          ],
          [
           12,
           69,
           26.24,
           "2012-10-19 12:00:00"
          ],
          [
           13,
           73,
           25.42,
           "2012-10-19 13:00:00"
          ],
          [
           14,
           61,
           27.06,
           "2012-10-19 14:00:00"
          ],
          [
           15,
           65,
           26.24,
           "2012-10-19 15:00:00"
          ],
          [
           16,
           69,
           25.42,
           "2012-10-19 16:00:00"
          ],
          [
           17,
           69,
           25.42,
           "2012-10-19 17:00:00"
          ],
          [
           18,
           83,
           22.96,
           "2012-10-19 18:00:00"
          ],
          [
           19,
           88,
           22.14,
           "2012-10-19 19:00:00"
          ],
          [
           20,
           77,
           21.32,
           "2012-10-19 20:00:00"
          ],
          [
           21,
           77,
           20.5,
           "2012-10-19 21:00:00"
          ],
          [
           22,
           77,
           20.5,
           "2012-10-19 22:00:00"
          ],
          [
           23,
           88,
           18.86,
           "2012-10-19 23:00:00"
          ],
          [
           0,
           57,
           14.76,
           "2012-11-01 00:00:00"
          ],
          [
           1,
           75,
           12.3,
           "2012-11-01 01:00:00"
          ],
          [
           2,
           66,
           13.12,
           "2012-11-01 02:00:00"
          ],
          [
           3,
           61,
           13.94,
           "2012-11-01 03:00:00"
          ],
          [
           4,
           66,
           13.94,
           "2012-11-01 04:00:00"
          ],
          [
           5,
           66,
           13.94,
           "2012-11-01 05:00:00"
          ],
          [
           6,
           61,
           13.94,
           "2012-11-01 06:00:00"
          ],
          [
           7,
           57,
           14.76,
           "2012-11-01 07:00:00"
          ],
          [
           8,
           56,
           14.76,
           "2012-11-01 08:00:00"
          ],
          [
           9,
           57,
           14.76,
           "2012-11-01 09:00:00"
          ],
          [
           10,
           62,
           14.76,
           "2012-11-01 10:00:00"
          ],
          [
           11,
           62,
           14.76,
           "2012-11-01 11:00:00"
          ],
          [
           12,
           62,
           15.58,
           "2012-11-01 12:00:00"
          ],
          [
           13,
           58,
           16.4,
           "2012-11-01 13:00:00"
          ],
          [
           14,
           50,
           16.4,
           "2012-11-01 14:00:00"
          ],
          [
           15,
           54,
           16.4,
           "2012-11-01 15:00:00"
          ],
          [
           16,
           54,
           16.4,
           "2012-11-01 16:00:00"
          ],
          [
           17,
           50,
           16.4,
           "2012-11-01 17:00:00"
          ],
          [
           18,
           50,
           16.4,
           "2012-11-01 18:00:00"
          ],
          [
           19,
           50,
           16.4,
           "2012-11-01 19:00:00"
          ],
          [
           20,
           54,
           15.58,
           "2012-11-01 20:00:00"
          ],
          [
           21,
           54,
           15.58,
           "2012-11-01 21:00:00"
          ],
          [
           22,
           57,
           14.76,
           "2012-11-01 22:00:00"
          ],
          [
           23,
           57,
           13.94,
           "2012-11-01 23:00:00"
          ],
          [
           0,
           57,
           13.94,
           "2012-11-02 00:00:00"
          ],
          [
           1,
           66,
           13.12,
           "2012-11-02 01:00:00"
          ],
          [
           2,
           66,
           13.12,
           "2012-11-02 02:00:00"
          ],
          [
           3,
           70,
           12.3,
           "2012-11-02 03:00:00"
          ],
          [
           4,
           70,
           12.3,
           "2012-11-02 04:00:00"
          ],
          [
           5,
           66,
           13.12,
           "2012-11-02 05:00:00"
          ],
          [
           6,
           70,
           12.3,
           "2012-11-02 06:00:00"
          ],
          [
           7,
           70,
           12.3,
           "2012-11-02 07:00:00"
          ],
          [
           8,
           57,
           13.12,
           "2012-11-02 08:00:00"
          ],
          [
           9,
           53,
           13.94,
           "2012-11-02 09:00:00"
          ],
          [
           10,
           46,
           15.58,
           "2012-11-02 10:00:00"
          ],
          [
           11,
           41,
           17.22,
           "2012-11-02 11:00:00"
          ],
          [
           12,
           41,
           17.22,
           "2012-11-02 12:00:00"
          ],
          [
           13,
           43,
           16.4,
           "2012-11-02 13:00:00"
          ],
          [
           14,
           40,
           16.4,
           "2012-11-02 14:00:00"
          ],
          [
           15,
           40,
           16.4,
           "2012-11-02 15:00:00"
          ],
          [
           16,
           40,
           15.58,
           "2012-11-02 16:00:00"
          ],
          [
           17,
           40,
           15.58,
           "2012-11-02 17:00:00"
          ],
          [
           18,
           43,
           15.58,
           "2012-11-02 18:00:00"
          ],
          [
           19,
           43,
           15.58,
           "2012-11-02 19:00:00"
          ],
          [
           20,
           46,
           14.76,
           "2012-11-02 20:00:00"
          ],
          [
           21,
           46,
           14.76,
           "2012-11-02 21:00:00"
          ],
          [
           22,
           46,
           14.76,
           "2012-11-02 22:00:00"
          ],
          [
           23,
           53,
           13.94,
           "2012-11-02 23:00:00"
          ],
          [
           0,
           53,
           13.94,
           "2012-11-03 00:00:00"
          ],
          [
           1,
           49,
           13.94,
           "2012-11-03 01:00:00"
          ],
          [
           2,
           49,
           13.94,
           "2012-11-03 02:00:00"
          ],
          [
           3,
           49,
           13.94,
           "2012-11-03 03:00:00"
          ],
          [
           4,
           49,
           13.12,
           "2012-11-03 04:00:00"
          ],
          [
           5,
           49,
           13.12,
           "2012-11-03 05:00:00"
          ],
          [
           6,
           49,
           13.12,
           "2012-11-03 06:00:00"
          ],
          [
           7,
           49,
           13.12,
           "2012-11-03 07:00:00"
          ],
          [
           8,
           46,
           13.94,
           "2012-11-03 08:00:00"
          ],
          [
           9,
           49,
           13.94,
           "2012-11-03 09:00:00"
          ],
          [
           10,
           46,
           14.76,
           "2012-11-03 10:00:00"
          ],
          [
           11,
           46,
           14.76,
           "2012-11-03 11:00:00"
          ],
          [
           12,
           46,
           14.76,
           "2012-11-03 12:00:00"
          ],
          [
           13,
           46,
           14.76,
           "2012-11-03 13:00:00"
          ],
          [
           14,
           50,
           14.76,
           "2012-11-03 14:00:00"
          ],
          [
           15,
           46,
           14.76,
           "2012-11-03 15:00:00"
          ],
          [
           16,
           46,
           14.76,
           "2012-11-03 16:00:00"
          ],
          [
           17,
           46,
           14.76,
           "2012-11-03 17:00:00"
          ],
          [
           18,
           46,
           14.76,
           "2012-11-03 18:00:00"
          ],
          [
           19,
           50,
           14.76,
           "2012-11-03 19:00:00"
          ],
          [
           20,
           53,
           13.94,
           "2012-11-03 20:00:00"
          ],
          [
           21,
           53,
           13.94,
           "2012-11-03 21:00:00"
          ],
          [
           22,
           57,
           13.12,
           "2012-11-03 22:00:00"
          ],
          [
           23,
           57,
           13.12,
           "2012-11-03 23:00:00"
          ],
          [
           0,
           61,
           12.3,
           "2012-11-04 00:00:00"
          ],
          [
           1,
           81,
           10.66,
           "2012-11-04 01:00:00"
          ],
          [
           2,
           65,
           12.3,
           "2012-11-04 02:00:00"
          ],
          [
           3,
           61,
           11.48,
           "2012-11-04 03:00:00"
          ],
          [
           4,
           65,
           10.66,
           "2012-11-04 04:00:00"
          ],
          [
           5,
           65,
           10.66,
           "2012-11-04 05:00:00"
          ],
          [
           6,
           61,
           11.48,
           "2012-11-04 06:00:00"
          ],
          [
           7,
           65,
           10.66,
           "2012-11-04 07:00:00"
          ],
          [
           8,
           56,
           12.3,
           "2012-11-04 08:00:00"
          ],
          [
           9,
           53,
           13.12,
           "2012-11-04 09:00:00"
          ],
          [
           10,
           49,
           13.94,
           "2012-11-04 10:00:00"
          ],
          [
           11,
           46,
           15.58,
           "2012-11-04 11:00:00"
          ],
          [
           12,
           46,
           15.58,
           "2012-11-04 12:00:00"
          ],
          [
           13,
           43,
           16.4,
           "2012-11-04 13:00:00"
          ],
          [
           14,
           40,
           16.4,
           "2012-11-04 14:00:00"
          ],
          [
           15,
           40,
           16.4,
           "2012-11-04 15:00:00"
          ],
          [
           16,
           40,
           16.4,
           "2012-11-04 16:00:00"
          ],
          [
           17,
           43,
           14.76,
           "2012-11-04 17:00:00"
          ],
          [
           18,
           43,
           14.76,
           "2012-11-04 18:00:00"
          ],
          [
           19,
           43,
           14.76,
           "2012-11-04 19:00:00"
          ],
          [
           20,
           53,
           13.12,
           "2012-11-04 20:00:00"
          ],
          [
           21,
           52,
           12.3,
           "2012-11-04 21:00:00"
          ],
          [
           22,
           52,
           12.3,
           "2012-11-04 22:00:00"
          ],
          [
           23,
           56,
           12.3,
           "2012-11-04 23:00:00"
          ],
          [
           0,
           56,
           12.3,
           "2012-11-05 00:00:00"
          ],
          [
           1,
           56,
           12.3,
           "2012-11-05 01:00:00"
          ],
          [
           2,
           56,
           12.3,
           "2012-11-05 02:00:00"
          ],
          [
           3,
           56,
           12.3,
           "2012-11-05 03:00:00"
          ],
          [
           4,
           52,
           12.3,
           "2012-11-05 04:00:00"
          ],
          [
           5,
           52,
           12.3,
           "2012-11-05 05:00:00"
          ],
          [
           6,
           49,
           12.3,
           "2012-11-05 06:00:00"
          ],
          [
           7,
           49,
           12.3,
           "2012-11-05 07:00:00"
          ],
          [
           8,
           49,
           12.3,
           "2012-11-05 08:00:00"
          ],
          [
           9,
           52,
           12.3,
           "2012-11-05 09:00:00"
          ],
          [
           10,
           49,
           13.12,
           "2012-11-05 10:00:00"
          ],
          [
           11,
           46,
           13.94,
           "2012-11-05 11:00:00"
          ],
          [
           12,
           43,
           14.76,
           "2012-11-05 12:00:00"
          ],
          [
           13,
           40,
           14.76,
           "2012-11-05 13:00:00"
          ],
          [
           14,
           40,
           15.58,
           "2012-11-05 14:00:00"
          ],
          [
           15,
           40,
           15.58,
           "2012-11-05 15:00:00"
          ],
          [
           16,
           43,
           14.76,
           "2012-11-05 16:00:00"
          ],
          [
           17,
           46,
           13.94,
           "2012-11-05 17:00:00"
          ],
          [
           18,
           46,
           13.94,
           "2012-11-05 18:00:00"
          ],
          [
           19,
           49,
           13.12,
           "2012-11-05 19:00:00"
          ],
          [
           20,
           49,
           13.12,
           "2012-11-05 20:00:00"
          ],
          [
           21,
           52,
           12.3,
           "2012-11-05 21:00:00"
          ],
          [
           22,
           56,
           11.48,
           "2012-11-05 22:00:00"
          ],
          [
           23,
           60,
           10.66,
           "2012-11-05 23:00:00"
          ],
          [
           0,
           60,
           9.84,
           "2012-11-06 00:00:00"
          ],
          [
           1,
           60,
           9.84,
           "2012-11-06 01:00:00"
          ],
          [
           2,
           65,
           9.84,
           "2012-11-06 02:00:00"
          ],
          [
           3,
           64,
           9.02,
           "2012-11-06 03:00:00"
          ],
          [
           4,
           69,
           9.02,
           "2012-11-06 04:00:00"
          ],
          [
           5,
           64,
           9.02,
           "2012-11-06 05:00:00"
          ],
          [
           6,
           69,
           9.02,
           "2012-11-06 06:00:00"
          ],
          [
           7,
           69,
           8.2,
           "2012-11-06 07:00:00"
          ],
          [
           8,
           69,
           9.02,
           "2012-11-06 08:00:00"
          ],
          [
           9,
           60,
           10.66,
           "2012-11-06 09:00:00"
          ],
          [
           10,
           49,
           12.3,
           "2012-11-06 10:00:00"
          ],
          [
           11,
           45,
           13.12,
           "2012-11-06 11:00:00"
          ],
          [
           12,
           45,
           13.12,
           "2012-11-06 12:00:00"
          ],
          [
           13,
           46,
           13.94,
           "2012-11-06 13:00:00"
          ],
          [
           14,
           40,
           14.76,
           "2012-11-06 14:00:00"
          ],
          [
           15,
           46,
           13.94,
           "2012-11-06 15:00:00"
          ],
          [
           16,
           46,
           13.94,
           "2012-11-06 16:00:00"
          ],
          [
           17,
           53,
           13.12,
           "2012-11-06 17:00:00"
          ],
          [
           18,
           57,
           13.12,
           "2012-11-06 18:00:00"
          ],
          [
           19,
           56,
           12.3,
           "2012-11-06 19:00:00"
          ],
          [
           20,
           61,
           12.3,
           "2012-11-06 20:00:00"
          ],
          [
           21,
           56,
           12.3,
           "2012-11-06 21:00:00"
          ],
          [
           22,
           56,
           12.3,
           "2012-11-06 22:00:00"
          ],
          [
           23,
           56,
           12.3,
           "2012-11-06 23:00:00"
          ],
          [
           0,
           56,
           12.3,
           "2012-11-07 00:00:00"
          ],
          [
           1,
           61,
           11.48,
           "2012-11-07 01:00:00"
          ],
          [
           2,
           56,
           11.48,
           "2012-11-07 02:00:00"
          ],
          [
           3,
           52,
           11.48,
           "2012-11-07 03:00:00"
          ],
          [
           4,
           52,
           11.48,
           "2012-11-07 04:00:00"
          ],
          [
           5,
           52,
           11.48,
           "2012-11-07 05:00:00"
          ],
          [
           6,
           56,
           10.66,
           "2012-11-07 06:00:00"
          ],
          [
           7,
           56,
           10.66,
           "2012-11-07 07:00:00"
          ],
          [
           8,
           60,
           10.66,
           "2012-11-07 08:00:00"
          ],
          [
           9,
           60,
           10.66,
           "2012-11-07 09:00:00"
          ],
          [
           10,
           56,
           11.48,
           "2012-11-07 10:00:00"
          ],
          [
           11,
           51,
           13.12,
           "2012-11-07 11:00:00"
          ],
          [
           12,
           53,
           13.12,
           "2012-11-07 12:00:00"
          ],
          [
           13,
           53,
           13.12,
           "2012-11-07 13:00:00"
          ],
          [
           14,
           53,
           13.12,
           "2012-11-07 14:00:00"
          ],
          [
           15,
           53,
           13.12,
           "2012-11-07 15:00:00"
          ],
          [
           16,
           53,
           13.12,
           "2012-11-07 16:00:00"
          ],
          [
           17,
           53,
           13.12,
           "2012-11-07 17:00:00"
          ],
          [
           18,
           53,
           13.12,
           "2012-11-07 18:00:00"
          ],
          [
           19,
           56,
           12.3,
           "2012-11-07 19:00:00"
          ],
          [
           20,
           49,
           13.12,
           "2012-11-07 20:00:00"
          ],
          [
           21,
           49,
           13.12,
           "2012-11-07 21:00:00"
          ],
          [
           22,
           56,
           12.3,
           "2012-11-07 22:00:00"
          ],
          [
           23,
           65,
           11.48,
           "2012-11-07 23:00:00"
          ],
          [
           0,
           61,
           11.48,
           "2012-11-08 00:00:00"
          ],
          [
           1,
           52,
           12.3,
           "2012-11-08 01:00:00"
          ],
          [
           2,
           49,
           12.3,
           "2012-11-08 02:00:00"
          ],
          [
           4,
           45,
           12.3,
           "2012-11-08 04:00:00"
          ],
          [
           5,
           42,
           12.3,
           "2012-11-08 05:00:00"
          ],
          [
           6,
           39,
           12.3,
           "2012-11-08 06:00:00"
          ],
          [
           7,
           36,
           11.48,
           "2012-11-08 07:00:00"
          ],
          [
           8,
           33,
           12.3,
           "2012-11-08 08:00:00"
          ],
          [
           9,
           31,
           13.12,
           "2012-11-08 09:00:00"
          ],
          [
           10,
           31,
           13.12,
           "2012-11-08 10:00:00"
          ],
          [
           11,
           29,
           14.76,
           "2012-11-08 11:00:00"
          ],
          [
           12,
           24,
           16.4,
           "2012-11-08 12:00:00"
          ],
          [
           13,
           18,
           18.04,
           "2012-11-08 13:00:00"
          ],
          [
           14,
           18,
           18.04,
           "2012-11-08 14:00:00"
          ],
          [
           15,
           18,
           18.04,
           "2012-11-08 15:00:00"
          ],
          [
           16,
           16,
           17.22,
           "2012-11-08 16:00:00"
          ],
          [
           17,
           20,
           16.4,
           "2012-11-08 17:00:00"
          ],
          [
           18,
           24,
           16.4,
           "2012-11-08 18:00:00"
          ],
          [
           19,
           27,
           15.58,
           "2012-11-08 19:00:00"
          ],
          [
           20,
           29,
           15.58,
           "2012-11-08 20:00:00"
          ],
          [
           21,
           37,
           14.76,
           "2012-11-08 21:00:00"
          ],
          [
           22,
           42,
           13.94,
           "2012-11-08 22:00:00"
          ],
          [
           23,
           46,
           13.94,
           "2012-11-08 23:00:00"
          ],
          [
           0,
           49,
           13.94,
           "2012-11-09 00:00:00"
          ],
          [
           1,
           53,
           13.12,
           "2012-11-09 01:00:00"
          ],
          [
           2,
           53,
           13.12,
           "2012-11-09 02:00:00"
          ],
          [
           3,
           53,
           13.12,
           "2012-11-09 03:00:00"
          ],
          [
           4,
           53,
           13.12,
           "2012-11-09 04:00:00"
          ],
          [
           5,
           56,
           12.3,
           "2012-11-09 05:00:00"
          ],
          [
           6,
           65,
           10.66,
           "2012-11-09 06:00:00"
          ],
          [
           7,
           65,
           10.66,
           "2012-11-09 07:00:00"
          ],
          [
           8,
           57,
           13.12,
           "2012-11-09 08:00:00"
          ],
          [
           9,
           53,
           13.94,
           "2012-11-09 09:00:00"
          ],
          [
           10,
           50,
           14.76,
           "2012-11-09 10:00:00"
          ],
          [
           11,
           47,
           16.4,
           "2012-11-09 11:00:00"
          ],
          [
           12,
           41,
           18.04,
           "2012-11-09 12:00:00"
          ],
          [
           13,
           38,
           18.86,
           "2012-11-09 13:00:00"
          ],
          [
           14,
           38,
           18.86,
           "2012-11-09 14:00:00"
          ],
          [
           15,
           36,
           18.86,
           "2012-11-09 15:00:00"
          ],
          [
           16,
           38,
           18.86,
           "2012-11-09 16:00:00"
          ],
          [
           17,
           44,
           17.22,
           "2012-11-09 17:00:00"
          ],
          [
           18,
           44,
           17.22,
           "2012-11-09 18:00:00"
          ],
          [
           19,
           71,
           13.94,
           "2012-11-09 19:00:00"
          ],
          [
           20,
           66,
           14.76,
           "2012-11-09 20:00:00"
          ],
          [
           21,
           76,
           13.94,
           "2012-11-09 21:00:00"
          ],
          [
           22,
           71,
           13.94,
           "2012-11-09 22:00:00"
          ],
          [
           23,
           81,
           13.12,
           "2012-11-09 23:00:00"
          ],
          [
           0,
           76,
           13.12,
           "2012-11-10 00:00:00"
          ],
          [
           1,
           81,
           12.3,
           "2012-11-10 01:00:00"
          ],
          [
           2,
           81,
           13.12,
           "2012-11-10 02:00:00"
          ],
          [
           3,
           81,
           12.3,
           "2012-11-10 03:00:00"
          ],
          [
           4,
           87,
           10.66,
           "2012-11-10 04:00:00"
          ],
          [
           5,
           87,
           11.48,
           "2012-11-10 05:00:00"
          ],
          [
           6,
           93,
           9.84,
           "2012-11-10 06:00:00"
          ],
          [
           7,
           87,
           10.66,
           "2012-11-10 07:00:00"
          ],
          [
           8,
           76,
           13.12,
           "2012-11-10 08:00:00"
          ],
          [
           9,
           66,
           14.76,
           "2012-11-10 09:00:00"
          ],
          [
           10,
           58,
           16.4,
           "2012-11-10 10:00:00"
          ],
          [
           11,
           58,
           16.4,
           "2012-11-10 11:00:00"
          ],
          [
           12,
           48,
           19.68,
           "2012-11-10 12:00:00"
          ],
          [
           13,
           39,
           21.32,
           "2012-11-10 13:00:00"
          ],
          [
           14,
           37,
           22.14,
           "2012-11-10 14:00:00"
          ],
          [
           15,
           45,
           21.32,
           "2012-11-10 15:00:00"
          ],
          [
           16,
           37,
           22.14,
           "2012-11-10 16:00:00"
          ],
          [
           17,
           45,
           20.5,
           "2012-11-10 17:00:00"
          ],
          [
           18,
           54,
           18.04,
           "2012-11-10 18:00:00"
          ],
          [
           19,
           51,
           18.86,
           "2012-11-10 19:00:00"
          ],
          [
           20,
           54,
           18.04,
           "2012-11-10 20:00:00"
          ],
          [
           21,
           66,
           16.4,
           "2012-11-10 21:00:00"
          ],
          [
           22,
           71,
           15.58,
           "2012-11-10 22:00:00"
          ],
          [
           23,
           71,
           14.76,
           "2012-11-10 23:00:00"
          ],
          [
           0,
           81,
           13.94,
           "2012-11-11 00:00:00"
          ],
          [
           1,
           76,
           13.94,
           "2012-11-11 01:00:00"
          ],
          [
           2,
           87,
           13.12,
           "2012-11-11 02:00:00"
          ],
          [
           3,
           81,
           13.94,
           "2012-11-11 03:00:00"
          ],
          [
           4,
           81,
           13.12,
           "2012-11-11 04:00:00"
          ],
          [
           5,
           87,
           12.3,
           "2012-11-11 05:00:00"
          ],
          [
           6,
           87,
           12.3,
           "2012-11-11 06:00:00"
          ],
          [
           7,
           89,
           12.3,
           "2012-11-11 07:00:00"
          ],
          [
           8,
           87,
           13.12,
           "2012-11-11 08:00:00"
          ],
          [
           9,
           77,
           14.76,
           "2012-11-11 09:00:00"
          ],
          [
           10,
           69,
           16.4,
           "2012-11-11 10:00:00"
          ],
          [
           11,
           59,
           18.86,
           "2012-11-11 11:00:00"
          ],
          [
           12,
           48,
           20.5,
           "2012-11-11 12:00:00"
          ],
          [
           13,
           45,
           22.14,
           "2012-11-11 13:00:00"
          ],
          [
           14,
           33,
           24.6,
           "2012-11-11 14:00:00"
          ],
          [
           15,
           37,
           22.96,
           "2012-11-11 15:00:00"
          ],
          [
           16,
           42,
           22.14,
           "2012-11-11 16:00:00"
          ],
          [
           17,
           45,
           22.14,
           "2012-11-11 17:00:00"
          ],
          [
           18,
           45,
           21.32,
           "2012-11-11 18:00:00"
          ],
          [
           19,
           55,
           19.68,
           "2012-11-11 19:00:00"
          ],
          [
           20,
           62,
           18.04,
           "2012-11-11 20:00:00"
          ],
          [
           21,
           67,
           18.04,
           "2012-11-11 21:00:00"
          ],
          [
           22,
           71,
           17.22,
           "2012-11-11 22:00:00"
          ],
          [
           23,
           71,
           17.22,
           "2012-11-11 23:00:00"
          ],
          [
           0,
           71,
           17.22,
           "2012-11-12 00:00:00"
          ],
          [
           1,
           76,
           16.4,
           "2012-11-12 01:00:00"
          ],
          [
           2,
           76,
           16.4,
           "2012-11-12 02:00:00"
          ],
          [
           3,
           76,
           16.4,
           "2012-11-12 03:00:00"
          ],
          [
           4,
           76,
           16.4,
           "2012-11-12 04:00:00"
          ],
          [
           5,
           87,
           15.58,
           "2012-11-12 05:00:00"
          ],
          [
           6,
           87,
           15.58,
           "2012-11-12 06:00:00"
          ],
          [
           7,
           87,
           16.4,
           "2012-11-12 07:00:00"
          ],
          [
           8,
           82,
           17.22,
           "2012-11-12 08:00:00"
          ],
          [
           9,
           88,
           18.04,
           "2012-11-12 09:00:00"
          ],
          [
           10,
           77,
           19.68,
           "2012-11-12 10:00:00"
          ],
          [
           11,
           72,
           21.32,
           "2012-11-12 11:00:00"
          ],
          [
           12,
           64,
           22.96,
           "2012-11-12 12:00:00"
          ],
          [
           13,
           60,
           24.6,
           "2012-11-12 13:00:00"
          ],
          [
           14,
           60,
           23.78,
           "2012-11-12 14:00:00"
          ],
          [
           15,
           64,
           22.96,
           "2012-11-12 15:00:00"
          ],
          [
           16,
           64,
           22.96,
           "2012-11-12 16:00:00"
          ],
          [
           17,
           64,
           22.96,
           "2012-11-12 17:00:00"
          ],
          [
           18,
           72,
           21.32,
           "2012-11-12 18:00:00"
          ],
          [
           19,
           73,
           22.14,
           "2012-11-12 19:00:00"
          ],
          [
           20,
           77,
           21.32,
           "2012-11-12 20:00:00"
          ],
          [
           21,
           73,
           22.14,
           "2012-11-12 21:00:00"
          ],
          [
           22,
           77,
           21.32,
           "2012-11-12 22:00:00"
          ],
          [
           23,
           77,
           22.14,
           "2012-11-12 23:00:00"
          ],
          [
           0,
           83,
           21.32,
           "2012-11-13 00:00:00"
          ],
          [
           1,
           88,
           18.04,
           "2012-11-13 01:00:00"
          ],
          [
           2,
           87,
           14.76,
           "2012-11-13 02:00:00"
          ],
          [
           3,
           87,
           14.76,
           "2012-11-13 03:00:00"
          ],
          [
           4,
           81,
           14.76,
           "2012-11-13 04:00:00"
          ],
          [
           5,
           87,
           13.94,
           "2012-11-13 05:00:00"
          ],
          [
           6,
           81,
           13.12,
           "2012-11-13 06:00:00"
          ],
          [
           7,
           87,
           13.12,
           "2012-11-13 07:00:00"
          ],
          [
           8,
           87,
           13.12,
           "2012-11-13 08:00:00"
          ],
          [
           9,
           81,
           13.12,
           "2012-11-13 09:00:00"
          ],
          [
           10,
           75,
           12.3,
           "2012-11-13 10:00:00"
          ],
          [
           11,
           70,
           13.12,
           "2012-11-13 11:00:00"
          ],
          [
           12,
           61,
           13.94,
           "2012-11-13 12:00:00"
          ],
          [
           13,
           53,
           13.94,
           "2012-11-13 13:00:00"
          ],
          [
           14,
           46,
           15.58,
           "2012-11-13 14:00:00"
          ],
          [
           15,
           40,
           16.4,
           "2012-11-13 15:00:00"
          ],
          [
           16,
           40,
           15.58,
           "2012-11-13 16:00:00"
          ],
          [
           17,
           49,
           13.94,
           "2012-11-13 17:00:00"
          ],
          [
           18,
           49,
           13.94,
           "2012-11-13 18:00:00"
          ],
          [
           19,
           49,
           13.12,
           "2012-11-13 19:00:00"
          ],
          [
           20,
           49,
           12.3,
           "2012-11-13 20:00:00"
          ],
          [
           21,
           49,
           12.3,
           "2012-11-13 21:00:00"
          ],
          [
           22,
           56,
           10.66,
           "2012-11-13 22:00:00"
          ],
          [
           23,
           56,
           10.66,
           "2012-11-13 23:00:00"
          ],
          [
           0,
           56,
           10.66,
           "2012-11-14 00:00:00"
          ],
          [
           1,
           60,
           9.84,
           "2012-11-14 01:00:00"
          ],
          [
           2,
           60,
           9.84,
           "2012-11-14 02:00:00"
          ],
          [
           3,
           65,
           9.84,
           "2012-11-14 03:00:00"
          ],
          [
           4,
           69,
           9.02,
           "2012-11-14 04:00:00"
          ],
          [
           5,
           69,
           9.02,
           "2012-11-14 05:00:00"
          ],
          [
           6,
           65,
           9.84,
           "2012-11-14 06:00:00"
          ],
          [
           7,
           65,
           9.84,
           "2012-11-14 07:00:00"
          ],
          [
           8,
           56,
           11.48,
           "2012-11-14 08:00:00"
          ],
          [
           9,
           52,
           12.3,
           "2012-11-14 09:00:00"
          ],
          [
           10,
           45,
           13.12,
           "2012-11-14 10:00:00"
          ],
          [
           11,
           49,
           13.12,
           "2012-11-14 11:00:00"
          ],
          [
           12,
           46,
           13.94,
           "2012-11-14 12:00:00"
          ],
          [
           13,
           43,
           14.76,
           "2012-11-14 13:00:00"
          ],
          [
           14,
           43,
           14.76,
           "2012-11-14 14:00:00"
          ],
          [
           15,
           43,
           14.76,
           "2012-11-14 15:00:00"
          ],
          [
           16,
           46,
           13.94,
           "2012-11-14 16:00:00"
          ],
          [
           17,
           49,
           13.12,
           "2012-11-14 17:00:00"
          ],
          [
           18,
           53,
           13.12,
           "2012-11-14 18:00:00"
          ],
          [
           19,
           52,
           12.3,
           "2012-11-14 19:00:00"
          ],
          [
           20,
           52,
           12.3,
           "2012-11-14 20:00:00"
          ],
          [
           21,
           56,
           12.3,
           "2012-11-14 21:00:00"
          ],
          [
           22,
           61,
           11.48,
           "2012-11-14 22:00:00"
          ],
          [
           23,
           70,
           9.84,
           "2012-11-14 23:00:00"
          ],
          [
           0,
           65,
           10.66,
           "2012-11-15 00:00:00"
          ],
          [
           1,
           65,
           10.66,
           "2012-11-15 01:00:00"
          ],
          [
           2,
           70,
           10.66,
           "2012-11-15 02:00:00"
          ],
          [
           3,
           70,
           10.66,
           "2012-11-15 03:00:00"
          ],
          [
           4,
           65,
           11.48,
           "2012-11-15 04:00:00"
          ],
          [
           5,
           61,
           12.3,
           "2012-11-15 05:00:00"
          ],
          [
           6,
           65,
           12.3,
           "2012-11-15 06:00:00"
          ],
          [
           7,
           65,
           12.3,
           "2012-11-15 07:00:00"
          ],
          [
           8,
           61,
           12.3,
           "2012-11-15 08:00:00"
          ],
          [
           9,
           61,
           13.12,
           "2012-11-15 09:00:00"
          ],
          [
           10,
           66,
           13.12,
           "2012-11-15 10:00:00"
          ],
          [
           11,
           61,
           13.94,
           "2012-11-15 11:00:00"
          ],
          [
           12,
           62,
           14.76,
           "2012-11-15 12:00:00"
          ],
          [
           13,
           54,
           15.58,
           "2012-11-15 13:00:00"
          ],
          [
           14,
           54,
           15.58,
           "2012-11-15 14:00:00"
          ],
          [
           15,
           58,
           15.58,
           "2012-11-15 15:00:00"
          ],
          [
           16,
           57,
           14.76,
           "2012-11-15 16:00:00"
          ],
          [
           17,
           57,
           14.76,
           "2012-11-15 17:00:00"
          ],
          [
           18,
           57,
           14.76,
           "2012-11-15 18:00:00"
          ],
          [
           19,
           61,
           13.94,
           "2012-11-15 19:00:00"
          ],
          [
           20,
           61,
           13.94,
           "2012-11-15 20:00:00"
          ],
          [
           21,
           66,
           13.12,
           "2012-11-15 21:00:00"
          ],
          [
           22,
           66,
           13.12,
           "2012-11-15 22:00:00"
          ],
          [
           23,
           61,
           13.12,
           "2012-11-15 23:00:00"
          ],
          [
           0,
           66,
           13.12,
           "2012-11-16 00:00:00"
          ],
          [
           1,
           65,
           12.3,
           "2012-11-16 01:00:00"
          ],
          [
           2,
           70,
           12.3,
           "2012-11-16 02:00:00"
          ],
          [
           3,
           65,
           12.3,
           "2012-11-16 03:00:00"
          ],
          [
           4,
           65,
           12.3,
           "2012-11-16 04:00:00"
          ],
          [
           5,
           65,
           12.3,
           "2012-11-16 05:00:00"
          ],
          [
           6,
           61,
           12.3,
           "2012-11-16 06:00:00"
          ],
          [
           7,
           61,
           12.3,
           "2012-11-16 07:00:00"
          ],
          [
           8,
           57,
           13.12,
           "2012-11-16 08:00:00"
          ],
          [
           9,
           53,
           13.94,
           "2012-11-16 09:00:00"
          ],
          [
           10,
           53,
           13.94,
           "2012-11-16 10:00:00"
          ],
          [
           11,
           43,
           15.58,
           "2012-11-16 11:00:00"
          ],
          [
           12,
           43,
           16.4,
           "2012-11-16 12:00:00"
          ],
          [
           13,
           38,
           17.22,
           "2012-11-16 13:00:00"
          ],
          [
           14,
           35,
           17.22,
           "2012-11-16 14:00:00"
          ],
          [
           15,
           38,
           17.22,
           "2012-11-16 15:00:00"
          ],
          [
           16,
           35,
           17.22,
           "2012-11-16 16:00:00"
          ],
          [
           17,
           46,
           14.76,
           "2012-11-16 17:00:00"
          ],
          [
           18,
           53,
           13.94,
           "2012-11-16 18:00:00"
          ],
          [
           19,
           46,
           14.76,
           "2012-11-16 19:00:00"
          ],
          [
           20,
           46,
           14.76,
           "2012-11-16 20:00:00"
          ],
          [
           21,
           49,
           13.94,
           "2012-11-16 21:00:00"
          ],
          [
           22,
           53,
           13.12,
           "2012-11-16 22:00:00"
          ],
          [
           23,
           53,
           13.12,
           "2012-11-16 23:00:00"
          ],
          [
           0,
           52,
           12.3,
           "2012-11-17 00:00:00"
          ],
          [
           1,
           60,
           10.66,
           "2012-11-17 01:00:00"
          ],
          [
           2,
           65,
           10.66,
           "2012-11-17 02:00:00"
          ],
          [
           3,
           65,
           10.66,
           "2012-11-17 03:00:00"
          ],
          [
           4,
           70,
           9.84,
           "2012-11-17 04:00:00"
          ],
          [
           5,
           70,
           9.84,
           "2012-11-17 05:00:00"
          ],
          [
           6,
           70,
           9.84,
           "2012-11-17 06:00:00"
          ],
          [
           7,
           70,
           9.84,
           "2012-11-17 07:00:00"
          ],
          [
           8,
           65,
           10.66,
           "2012-11-17 08:00:00"
          ],
          [
           9,
           49,
           13.94,
           "2012-11-17 09:00:00"
          ],
          [
           10,
           46,
           14.76,
           "2012-11-17 10:00:00"
          ],
          [
           11,
           43,
           15.58,
           "2012-11-17 11:00:00"
          ],
          [
           12,
           40,
           16.4,
           "2012-11-17 12:00:00"
          ],
          [
           13,
           38,
           17.22,
           "2012-11-17 13:00:00"
          ],
          [
           14,
           38,
           17.22,
           "2012-11-17 14:00:00"
          ],
          [
           15,
           35,
           17.22,
           "2012-11-17 15:00:00"
          ],
          [
           16,
           40,
           16.4,
           "2012-11-17 16:00:00"
          ],
          [
           17,
           40,
           15.58,
           "2012-11-17 17:00:00"
          ],
          [
           18,
           50,
           14.76,
           "2012-11-17 18:00:00"
          ],
          [
           19,
           53,
           13.94,
           "2012-11-17 19:00:00"
          ],
          [
           20,
           66,
           13.94,
           "2012-11-17 20:00:00"
          ],
          [
           21,
           57,
           13.12,
           "2012-11-17 21:00:00"
          ],
          [
           22,
           57,
           13.12,
           "2012-11-17 22:00:00"
          ],
          [
           23,
           70,
           12.3,
           "2012-11-17 23:00:00"
          ],
          [
           0,
           70,
           12.3,
           "2012-11-18 00:00:00"
          ],
          [
           1,
           70,
           12.3,
           "2012-11-18 01:00:00"
          ],
          [
           2,
           81,
           11.48,
           "2012-11-18 02:00:00"
          ],
          [
           3,
           81,
           12.3,
           "2012-11-18 03:00:00"
          ],
          [
           4,
           81,
           12.3,
           "2012-11-18 04:00:00"
          ],
          [
           5,
           81,
           11.48,
           "2012-11-18 05:00:00"
          ],
          [
           6,
           81,
           11.48,
           "2012-11-18 06:00:00"
          ],
          [
           7,
           81,
           11.48,
           "2012-11-18 07:00:00"
          ],
          [
           8,
           75,
           12.3,
           "2012-11-18 08:00:00"
          ],
          [
           9,
           70,
           13.12,
           "2012-11-18 09:00:00"
          ],
          [
           10,
           66,
           13.94,
           "2012-11-18 10:00:00"
          ],
          [
           11,
           62,
           15.58,
           "2012-11-18 11:00:00"
          ],
          [
           12,
           62,
           16.4,
           "2012-11-18 12:00:00"
          ],
          [
           13,
           62,
           16.4,
           "2012-11-18 13:00:00"
          ],
          [
           14,
           62,
           16.4,
           "2012-11-18 14:00:00"
          ],
          [
           15,
           54,
           17.22,
           "2012-11-18 15:00:00"
          ],
          [
           16,
           62,
           16.4,
           "2012-11-18 16:00:00"
          ],
          [
           17,
           66,
           15.58,
           "2012-11-18 17:00:00"
          ],
          [
           18,
           66,
           14.76,
           "2012-11-18 18:00:00"
          ],
          [
           19,
           66,
           14.76,
           "2012-11-18 19:00:00"
          ],
          [
           20,
           66,
           14.76,
           "2012-11-18 20:00:00"
          ],
          [
           21,
           66,
           14.76,
           "2012-11-18 21:00:00"
          ],
          [
           22,
           66,
           14.76,
           "2012-11-18 22:00:00"
          ],
          [
           23,
           66,
           14.76,
           "2012-11-18 23:00:00"
          ],
          [
           0,
           66,
           14.76,
           "2012-11-19 00:00:00"
          ],
          [
           1,
           66,
           14.76,
           "2012-11-19 01:00:00"
          ],
          [
           2,
           66,
           14.76,
           "2012-11-19 02:00:00"
          ],
          [
           3,
           66,
           14.76,
           "2012-11-19 03:00:00"
          ],
          [
           4,
           66,
           14.76,
           "2012-11-19 04:00:00"
          ],
          [
           5,
           66,
           14.76,
           "2012-11-19 05:00:00"
          ],
          [
           6,
           66,
           14.76,
           "2012-11-19 06:00:00"
          ],
          [
           7,
           66,
           14.76,
           "2012-11-19 07:00:00"
          ],
          [
           8,
           66,
           14.76,
           "2012-11-19 08:00:00"
          ],
          [
           9,
           66,
           14.76,
           "2012-11-19 09:00:00"
          ],
          [
           10,
           66,
           14.76,
           "2012-11-19 10:00:00"
          ],
          [
           11,
           66,
           15.58,
           "2012-11-19 11:00:00"
          ],
          [
           12,
           62,
           16.4,
           "2012-11-19 12:00:00"
          ],
          [
           13,
           54,
           18.04,
           "2012-11-19 13:00:00"
          ],
          [
           14,
           54,
           18.04,
           "2012-11-19 14:00:00"
          ],
          [
           15,
           54,
           18.04,
           "2012-11-19 15:00:00"
          ],
          [
           16,
           58,
           17.22,
           "2012-11-19 16:00:00"
          ],
          [
           17,
           58,
           17.22,
           "2012-11-19 17:00:00"
          ],
          [
           18,
           58,
           16.4,
           "2012-11-19 18:00:00"
          ],
          [
           19,
           58,
           16.4,
           "2012-11-19 19:00:00"
          ],
          [
           20,
           62,
           15.58,
           "2012-11-19 20:00:00"
          ],
          [
           21,
           54,
           15.58,
           "2012-11-19 21:00:00"
          ],
          [
           22,
           66,
           13.94,
           "2012-11-19 22:00:00"
          ],
          [
           23,
           66,
           13.94,
           "2012-11-19 23:00:00"
          ],
          [
           0,
           81,
           10.66,
           "2012-12-01 00:00:00"
          ],
          [
           1,
           81,
           10.66,
           "2012-12-01 01:00:00"
          ],
          [
           2,
           81,
           10.66,
           "2012-12-01 02:00:00"
          ],
          [
           3,
           81,
           10.66,
           "2012-12-01 03:00:00"
          ],
          [
           4,
           81,
           10.66,
           "2012-12-01 04:00:00"
          ],
          [
           5,
           87,
           9.84,
           "2012-12-01 05:00:00"
          ],
          [
           6,
           87,
           9.84,
           "2012-12-01 06:00:00"
          ],
          [
           7,
           87,
           9.84,
           "2012-12-01 07:00:00"
          ],
          [
           8,
           87,
           9.84,
           "2012-12-01 08:00:00"
          ],
          [
           9,
           93,
           10.66,
           "2012-12-01 09:00:00"
          ],
          [
           10,
           89,
           11.48,
           "2012-12-01 10:00:00"
          ],
          [
           11,
           76,
           13.12,
           "2012-12-01 11:00:00"
          ],
          [
           12,
           81,
           13.12,
           "2012-12-01 12:00:00"
          ],
          [
           13,
           76,
           13.94,
           "2012-12-01 13:00:00"
          ],
          [
           14,
           71,
           14.76,
           "2012-12-01 14:00:00"
          ],
          [
           15,
           62,
           16.4,
           "2012-12-01 15:00:00"
          ],
          [
           16,
           66,
           15.58,
           "2012-12-01 16:00:00"
          ],
          [
           17,
           76,
           13.94,
           "2012-12-01 17:00:00"
          ],
          [
           18,
           76,
           13.94,
           "2012-12-01 18:00:00"
          ],
          [
           19,
           81,
           13.12,
           "2012-12-01 19:00:00"
          ],
          [
           20,
           81,
           13.12,
           "2012-12-01 20:00:00"
          ],
          [
           21,
           87,
           12.3,
           "2012-12-01 21:00:00"
          ],
          [
           22,
           87,
           12.3,
           "2012-12-01 22:00:00"
          ],
          [
           23,
           81,
           13.12,
           "2012-12-01 23:00:00"
          ],
          [
           0,
           87,
           12.3,
           "2012-12-02 00:00:00"
          ],
          [
           1,
           87,
           12.3,
           "2012-12-02 01:00:00"
          ],
          [
           2,
           87,
           12.3,
           "2012-12-02 02:00:00"
          ],
          [
           3,
           93,
           10.66,
           "2012-12-02 03:00:00"
          ],
          [
           4,
           93,
           10.66,
           "2012-12-02 04:00:00"
          ],
          [
           5,
           93,
           10.66,
           "2012-12-02 05:00:00"
          ],
          [
           6,
           93,
           9.84,
           "2012-12-02 06:00:00"
          ],
          [
           7,
           93,
           9.84,
           "2012-12-02 07:00:00"
          ],
          [
           8,
           93,
           10.66,
           "2012-12-02 08:00:00"
          ],
          [
           9,
           93,
           11.48,
           "2012-12-02 09:00:00"
          ],
          [
           10,
           87,
           12.3,
           "2012-12-02 10:00:00"
          ],
          [
           11,
           81,
           13.12,
           "2012-12-02 11:00:00"
          ],
          [
           12,
           81,
           13.94,
           "2012-12-02 12:00:00"
          ],
          [
           13,
           71,
           16.4,
           "2012-12-02 13:00:00"
          ],
          [
           14,
           62,
           18.04,
           "2012-12-02 14:00:00"
          ],
          [
           15,
           67,
           18.04,
           "2012-12-02 15:00:00"
          ],
          [
           16,
           67,
           18.04,
           "2012-12-02 16:00:00"
          ],
          [
           17,
           76,
           16.4,
           "2012-12-02 17:00:00"
          ],
          [
           18,
           72,
           18.04,
           "2012-12-02 18:00:00"
          ],
          [
           19,
           82,
           16.4,
           "2012-12-02 19:00:00"
          ],
          [
           20,
           82,
           17.22,
           "2012-12-02 20:00:00"
          ],
          [
           21,
           77,
           18.04,
           "2012-12-02 21:00:00"
          ],
          [
           22,
           77,
           18.04,
           "2012-12-02 22:00:00"
          ],
          [
           23,
           82,
           17.22,
           "2012-12-02 23:00:00"
          ],
          [
           0,
           82,
           17.22,
           "2012-12-03 00:00:00"
          ],
          [
           1,
           82,
           16.4,
           "2012-12-03 01:00:00"
          ],
          [
           2,
           77,
           17.22,
           "2012-12-03 02:00:00"
          ],
          [
           3,
           87,
           15.58,
           "2012-12-03 03:00:00"
          ],
          [
           4,
           93,
           14.76,
           "2012-12-03 04:00:00"
          ],
          [
           5,
           93,
           13.94,
           "2012-12-03 05:00:00"
          ],
          [
           6,
           93,
           14.76,
           "2012-12-03 06:00:00"
          ],
          [
           7,
           93,
           13.94,
           "2012-12-03 07:00:00"
          ],
          [
           8,
           93,
           14.76,
           "2012-12-03 08:00:00"
          ],
          [
           9,
           87,
           16.4,
           "2012-12-03 09:00:00"
          ],
          [
           10,
           77,
           18.04,
           "2012-12-03 10:00:00"
          ],
          [
           11,
           77,
           19.68,
           "2012-12-03 11:00:00"
          ],
          [
           12,
           68,
           21.32,
           "2012-12-03 12:00:00"
          ],
          [
           13,
           56,
           23.78,
           "2012-12-03 13:00:00"
          ],
          [
           14,
           53,
           24.6,
           "2012-12-03 14:00:00"
          ],
          [
           15,
           56,
           24.6,
           "2012-12-03 15:00:00"
          ],
          [
           16,
           53,
           24.6,
           "2012-12-03 16:00:00"
          ],
          [
           17,
           63,
           21.32,
           "2012-12-03 17:00:00"
          ],
          [
           18,
           68,
           20.5,
           "2012-12-03 18:00:00"
          ],
          [
           19,
           68,
           20.5,
           "2012-12-03 19:00:00"
          ],
          [
           20,
           77,
           18.86,
           "2012-12-03 20:00:00"
          ],
          [
           21,
           82,
           18.04,
           "2012-12-03 21:00:00"
          ],
          [
           22,
           82,
           17.22,
           "2012-12-03 22:00:00"
          ],
          [
           23,
           82,
           17.22,
           "2012-12-03 23:00:00"
          ],
          [
           0,
           88,
           17.22,
           "2012-12-04 00:00:00"
          ],
          [
           1,
           82,
           17.22,
           "2012-12-04 01:00:00"
          ],
          [
           2,
           88,
           17.22,
           "2012-12-04 02:00:00"
          ],
          [
           3,
           87,
           16.4,
           "2012-12-04 03:00:00"
          ],
          [
           4,
           87,
           16.4,
           "2012-12-04 04:00:00"
          ],
          [
           5,
           88,
           18.04,
           "2012-12-04 05:00:00"
          ],
          [
           6,
           93,
           14.76,
           "2012-12-04 06:00:00"
          ],
          [
           7,
           88,
           17.22,
           "2012-12-04 07:00:00"
          ],
          [
           8,
           88,
           18.04,
           "2012-12-04 08:00:00"
          ],
          [
           9,
           82,
           18.86,
           "2012-12-04 09:00:00"
          ],
          [
           10,
           82,
           18.86,
           "2012-12-04 10:00:00"
          ],
          [
           11,
           77,
           19.68,
           "2012-12-04 11:00:00"
          ],
          [
           12,
           68,
           21.32,
           "2012-12-04 12:00:00"
          ],
          [
           13,
           64,
           22.14,
           "2012-12-04 13:00:00"
          ],
          [
           14,
           56,
           23.78,
           "2012-12-04 14:00:00"
          ],
          [
           15,
           49,
           24.6,
           "2012-12-04 15:00:00"
          ],
          [
           16,
           49,
           23.78,
           "2012-12-04 16:00:00"
          ],
          [
           17,
           59,
           21.32,
           "2012-12-04 17:00:00"
          ],
          [
           18,
           63,
           20.5,
           "2012-12-04 18:00:00"
          ],
          [
           19,
           67,
           19.68,
           "2012-12-04 19:00:00"
          ],
          [
           20,
           63,
           20.5,
           "2012-12-04 20:00:00"
          ],
          [
           21,
           63,
           20.5,
           "2012-12-04 21:00:00"
          ],
          [
           22,
           63,
           20.5,
           "2012-12-04 22:00:00"
          ],
          [
           23,
           67,
           19.68,
           "2012-12-04 23:00:00"
          ],
          [
           0,
           59,
           20.5,
           "2012-12-05 00:00:00"
          ],
          [
           1,
           55,
           21.32,
           "2012-12-05 01:00:00"
          ],
          [
           2,
           67,
           18.86,
           "2012-12-05 02:00:00"
          ],
          [
           3,
           67,
           19.68,
           "2012-12-05 03:00:00"
          ],
          [
           4,
           63,
           20.5,
           "2012-12-05 04:00:00"
          ],
          [
           5,
           59,
           20.5,
           "2012-12-05 05:00:00"
          ],
          [
           6,
           55,
           19.68,
           "2012-12-05 06:00:00"
          ],
          [
           7,
           59,
           18.86,
           "2012-12-05 07:00:00"
          ],
          [
           8,
           58,
           18.04,
           "2012-12-05 08:00:00"
          ],
          [
           9,
           51,
           18.04,
           "2012-12-05 09:00:00"
          ],
          [
           10,
           47,
           18.04,
           "2012-12-05 10:00:00"
          ],
          [
           11,
           44,
           18.04,
           "2012-12-05 11:00:00"
          ],
          [
           12,
           41,
           18.04,
           "2012-12-05 12:00:00"
          ],
          [
           13,
           41,
           18.86,
           "2012-12-05 13:00:00"
          ],
          [
           14,
           33,
           19.68,
           "2012-12-05 14:00:00"
          ],
          [
           15,
           33,
           19.68,
           "2012-12-05 15:00:00"
          ],
          [
           16,
           33,
           18.86,
           "2012-12-05 16:00:00"
          ],
          [
           17,
           35,
           18.04,
           "2012-12-05 17:00:00"
          ],
          [
           18,
           35,
           17.22,
           "2012-12-05 18:00:00"
          ],
          [
           19,
           43,
           15.58,
           "2012-12-05 19:00:00"
          ],
          [
           20,
           46,
           13.94,
           "2012-12-05 20:00:00"
          ],
          [
           21,
           46,
           13.94,
           "2012-12-05 21:00:00"
          ],
          [
           22,
           45,
           13.12,
           "2012-12-05 22:00:00"
          ],
          [
           23,
           49,
           12.3,
           "2012-12-05 23:00:00"
          ],
          [
           0,
           48,
           10.66,
           "2012-12-06 00:00:00"
          ],
          [
           1,
           48,
           10.66,
           "2012-12-06 01:00:00"
          ],
          [
           2,
           52,
           9.84,
           "2012-12-06 02:00:00"
          ],
          [
           3,
           55,
           9.02,
           "2012-12-06 03:00:00"
          ],
          [
           4,
           55,
           9.02,
           "2012-12-06 04:00:00"
          ],
          [
           5,
           55,
           9.02,
           "2012-12-06 05:00:00"
          ],
          [
           6,
           55,
           9.02,
           "2012-12-06 06:00:00"
          ],
          [
           7,
           51,
           9.02,
           "2012-12-06 07:00:00"
          ],
          [
           8,
           51,
           9.02,
           "2012-12-06 08:00:00"
          ],
          [
           9,
           48,
           9.84,
           "2012-12-06 09:00:00"
          ],
          [
           10,
           52,
           9.84,
           "2012-12-06 10:00:00"
          ],
          [
           11,
           48,
           10.66,
           "2012-12-06 11:00:00"
          ],
          [
           12,
           41,
           11.48,
           "2012-12-06 12:00:00"
          ],
          [
           13,
           39,
           12.3,
           "2012-12-06 13:00:00"
          ],
          [
           14,
           42,
           12.3,
           "2012-12-06 14:00:00"
          ],
          [
           15,
           39,
           13.12,
           "2012-12-06 15:00:00"
          ],
          [
           16,
           42,
           13.12,
           "2012-12-06 16:00:00"
          ],
          [
           17,
           45,
           12.3,
           "2012-12-06 17:00:00"
          ],
          [
           18,
           45,
           11.48,
           "2012-12-06 18:00:00"
          ],
          [
           19,
           60,
           10.66,
           "2012-12-06 19:00:00"
          ],
          [
           20,
           60,
           9.84,
           "2012-12-06 20:00:00"
          ],
          [
           21,
           60,
           9.84,
           "2012-12-06 21:00:00"
          ],
          [
           22,
           65,
           9.84,
           "2012-12-06 22:00:00"
          ],
          [
           23,
           65,
           9.84,
           "2012-12-06 23:00:00"
          ],
          [
           0,
           70,
           9.84,
           "2012-12-07 00:00:00"
          ],
          [
           1,
           70,
           9.84,
           "2012-12-07 01:00:00"
          ],
          [
           2,
           70,
           10.66,
           "2012-12-07 02:00:00"
          ],
          [
           3,
           81,
           10.66,
           "2012-12-07 03:00:00"
          ],
          [
           4,
           75,
           10.66,
           "2012-12-07 04:00:00"
          ],
          [
           5,
           81,
           10.66,
           "2012-12-07 05:00:00"
          ],
          [
           6,
           75,
           11.48,
           "2012-12-07 06:00:00"
          ],
          [
           7,
           81,
           11.48,
           "2012-12-07 07:00:00"
          ],
          [
           8,
           75,
           12.3,
           "2012-12-07 08:00:00"
          ],
          [
           9,
           81,
           12.3,
           "2012-12-07 09:00:00"
          ],
          [
           10,
           76,
           13.12,
           "2012-12-07 10:00:00"
          ],
          [
           11,
           76,
           13.12,
           "2012-12-07 11:00:00"
          ],
          [
           12,
           71,
           13.94,
           "2012-12-07 12:00:00"
          ],
          [
           13,
           66,
           14.76,
           "2012-12-07 13:00:00"
          ],
          [
           14,
           71,
           14.76,
           "2012-12-07 14:00:00"
          ],
          [
           15,
           71,
           14.76,
           "2012-12-07 15:00:00"
          ],
          [
           16,
           76,
           14.76,
           "2012-12-07 16:00:00"
          ],
          [
           17,
           66,
           15.58,
           "2012-12-07 17:00:00"
          ],
          [
           18,
           71,
           15.58,
           "2012-12-07 18:00:00"
          ],
          [
           19,
           76,
           15.58,
           "2012-12-07 19:00:00"
          ],
          [
           20,
           76,
           15.58,
           "2012-12-07 20:00:00"
          ],
          [
           21,
           93,
           14.76,
           "2012-12-07 21:00:00"
          ],
          [
           22,
           93,
           14.76,
           "2012-12-07 22:00:00"
          ],
          [
           23,
           93,
           14.76,
           "2012-12-07 23:00:00"
          ],
          [
           0,
           93,
           14.76,
           "2012-12-08 00:00:00"
          ],
          [
           1,
           93,
           14.76,
           "2012-12-08 01:00:00"
          ],
          [
           2,
           93,
           14.76,
           "2012-12-08 02:00:00"
          ],
          [
           3,
           93,
           14.76,
           "2012-12-08 03:00:00"
          ],
          [
           4,
           93,
           14.76,
           "2012-12-08 04:00:00"
          ],
          [
           5,
           93,
           14.76,
           "2012-12-08 05:00:00"
          ],
          [
           6,
           93,
           14.76,
           "2012-12-08 06:00:00"
          ],
          [
           7,
           100,
           14.76,
           "2012-12-08 07:00:00"
          ],
          [
           8,
           94,
           15.58,
           "2012-12-08 08:00:00"
          ],
          [
           9,
           94,
           15.58,
           "2012-12-08 09:00:00"
          ],
          [
           10,
           87,
           16.4,
           "2012-12-08 10:00:00"
          ],
          [
           11,
           87,
           16.4,
           "2012-12-08 11:00:00"
          ],
          [
           12,
           87,
           16.4,
           "2012-12-08 12:00:00"
          ],
          [
           13,
           87,
           16.4,
           "2012-12-08 13:00:00"
          ],
          [
           14,
           87,
           16.4,
           "2012-12-08 14:00:00"
          ],
          [
           15,
           82,
           17.22,
           "2012-12-08 15:00:00"
          ],
          [
           16,
           82,
           17.22,
           "2012-12-08 16:00:00"
          ],
          [
           17,
           87,
           15.58,
           "2012-12-08 17:00:00"
          ],
          [
           18,
           87,
           16.4,
           "2012-12-08 18:00:00"
          ],
          [
           19,
           87,
           16.4,
           "2012-12-08 19:00:00"
          ],
          [
           20,
           100,
           14.76,
           "2012-12-08 20:00:00"
          ],
          [
           21,
           100,
           14.76,
           "2012-12-08 21:00:00"
          ],
          [
           22,
           94,
           15.58,
           "2012-12-08 22:00:00"
          ],
          [
           23,
           94,
           16.4,
           "2012-12-08 23:00:00"
          ],
          [
           0,
           87,
           16.4,
           "2012-12-09 00:00:00"
          ],
          [
           1,
           87,
           16.4,
           "2012-12-09 01:00:00"
          ],
          [
           2,
           87,
           16.4,
           "2012-12-09 02:00:00"
          ],
          [
           3,
           87,
           16.4,
           "2012-12-09 03:00:00"
          ],
          [
           4,
           94,
           16.4,
           "2012-12-09 04:00:00"
          ],
          [
           5,
           87,
           16.4,
           "2012-12-09 05:00:00"
          ],
          [
           6,
           94,
           16.4,
           "2012-12-09 06:00:00"
          ],
          [
           7,
           87,
           16.4,
           "2012-12-09 07:00:00"
          ],
          [
           8,
           87,
           16.4,
           "2012-12-09 08:00:00"
          ],
          [
           9,
           87,
           16.4,
           "2012-12-09 09:00:00"
          ],
          [
           10,
           87,
           16.4,
           "2012-12-09 10:00:00"
          ],
          [
           11,
           87,
           16.4,
           "2012-12-09 11:00:00"
          ],
          [
           12,
           82,
           16.4,
           "2012-12-09 12:00:00"
          ],
          [
           13,
           87,
           15.58,
           "2012-12-09 13:00:00"
          ],
          [
           14,
           87,
           15.58,
           "2012-12-09 14:00:00"
          ],
          [
           15,
           93,
           14.76,
           "2012-12-09 15:00:00"
          ],
          [
           16,
           93,
           14.76,
           "2012-12-09 16:00:00"
          ],
          [
           17,
           93,
           14.76,
           "2012-12-09 17:00:00"
          ],
          [
           18,
           93,
           14.76,
           "2012-12-09 18:00:00"
          ],
          [
           19,
           94,
           15.58,
           "2012-12-09 19:00:00"
          ],
          [
           20,
           100,
           14.76,
           "2012-12-09 20:00:00"
          ],
          [
           21,
           100,
           14.76,
           "2012-12-09 21:00:00"
          ],
          [
           22,
           93,
           14.76,
           "2012-12-09 22:00:00"
          ],
          [
           23,
           100,
           14.76,
           "2012-12-09 23:00:00"
          ],
          [
           0,
           100,
           14.76,
           "2012-12-10 00:00:00"
          ],
          [
           1,
           100,
           14.76,
           "2012-12-10 01:00:00"
          ],
          [
           2,
           94,
           15.58,
           "2012-12-10 02:00:00"
          ],
          [
           3,
           94,
           15.58,
           "2012-12-10 03:00:00"
          ],
          [
           4,
           94,
           15.58,
           "2012-12-10 04:00:00"
          ],
          [
           5,
           94,
           15.58,
           "2012-12-10 05:00:00"
          ],
          [
           6,
           94,
           15.58,
           "2012-12-10 06:00:00"
          ],
          [
           7,
           94,
           15.58,
           "2012-12-10 07:00:00"
          ],
          [
           8,
           100,
           17.22,
           "2012-12-10 08:00:00"
          ],
          [
           9,
           100,
           17.22,
           "2012-12-10 09:00:00"
          ],
          [
           10,
           94,
           18.04,
           "2012-12-10 10:00:00"
          ],
          [
           11,
           94,
           18.86,
           "2012-12-10 11:00:00"
          ],
          [
           12,
           100,
           18.04,
           "2012-12-10 12:00:00"
          ],
          [
           13,
           100,
           18.04,
           "2012-12-10 13:00:00"
          ],
          [
           14,
           94,
           20.5,
           "2012-12-10 14:00:00"
          ],
          [
           15,
           87,
           20.5,
           "2012-12-10 15:00:00"
          ],
          [
           16,
           88,
           20.5,
           "2012-12-10 16:00:00"
          ],
          [
           17,
           82,
           19.68,
           "2012-12-10 17:00:00"
          ],
          [
           18,
           88,
           18.86,
           "2012-12-10 18:00:00"
          ],
          [
           19,
           77,
           21.32,
           "2012-12-10 19:00:00"
          ],
          [
           20,
           88,
           18.86,
           "2012-12-10 20:00:00"
          ],
          [
           21,
           94,
           18.86,
           "2012-12-10 21:00:00"
          ],
          [
           22,
           82,
           20.5,
           "2012-12-10 22:00:00"
          ],
          [
           23,
           88,
           18.86,
           "2012-12-10 23:00:00"
          ],
          [
           0,
           77,
           18.86,
           "2012-12-11 00:00:00"
          ],
          [
           1,
           71,
           17.22,
           "2012-12-11 01:00:00"
          ],
          [
           2,
           66,
           16.4,
           "2012-12-11 02:00:00"
          ],
          [
           3,
           76,
           14.76,
           "2012-12-11 03:00:00"
          ],
          [
           4,
           76,
           13.94,
           "2012-12-11 04:00:00"
          ],
          [
           5,
           71,
           13.94,
           "2012-12-11 05:00:00"
          ],
          [
           6,
           71,
           13.94,
           "2012-12-11 06:00:00"
          ],
          [
           7,
           66,
           13.94,
           "2012-12-11 07:00:00"
          ],
          [
           8,
           61,
           13.94,
           "2012-12-11 08:00:00"
          ],
          [
           9,
           61,
           13.94,
           "2012-12-11 09:00:00"
          ],
          [
           10,
           57,
           14.76,
           "2012-12-11 10:00:00"
          ],
          [
           11,
           53,
           14.76,
           "2012-12-11 11:00:00"
          ],
          [
           12,
           53,
           14.76,
           "2012-12-11 12:00:00"
          ],
          [
           13,
           50,
           15.58,
           "2012-12-11 13:00:00"
          ],
          [
           14,
           50,
           15.58,
           "2012-12-11 14:00:00"
          ],
          [
           15,
           50,
           15.58,
           "2012-12-11 15:00:00"
          ],
          [
           16,
           50,
           15.58,
           "2012-12-11 16:00:00"
          ],
          [
           17,
           53,
           13.12,
           "2012-12-11 17:00:00"
          ],
          [
           18,
           53,
           13.12,
           "2012-12-11 18:00:00"
          ],
          [
           19,
           53,
           13.12,
           "2012-12-11 19:00:00"
          ],
          [
           20,
           53,
           13.12,
           "2012-12-11 20:00:00"
          ],
          [
           21,
           53,
           13.12,
           "2012-12-11 21:00:00"
          ],
          [
           22,
           56,
           12.3,
           "2012-12-11 22:00:00"
          ],
          [
           23,
           52,
           12.3,
           "2012-12-11 23:00:00"
          ],
          [
           0,
           52,
           12.3,
           "2012-12-12 00:00:00"
          ],
          [
           1,
           61,
           11.48,
           "2012-12-12 01:00:00"
          ],
          [
           2,
           56,
           11.48,
           "2012-12-12 02:00:00"
          ],
          [
           3,
           60,
           10.66,
           "2012-12-12 03:00:00"
          ],
          [
           4,
           60,
           10.66,
           "2012-12-12 04:00:00"
          ],
          [
           5,
           60,
           10.66,
           "2012-12-12 05:00:00"
          ],
          [
           6,
           60,
           10.66,
           "2012-12-12 06:00:00"
          ],
          [
           7,
           60,
           10.66,
           "2012-12-12 07:00:00"
          ],
          [
           8,
           65,
           10.66,
           "2012-12-12 08:00:00"
          ],
          [
           9,
           61,
           11.48,
           "2012-12-12 09:00:00"
          ],
          [
           10,
           56,
           12.3,
           "2012-12-12 10:00:00"
          ],
          [
           11,
           49,
           13.12,
           "2012-12-12 11:00:00"
          ],
          [
           12,
           42,
           13.94,
           "2012-12-12 12:00:00"
          ],
          [
           13,
           42,
           13.94,
           "2012-12-12 13:00:00"
          ],
          [
           14,
           46,
           13.94,
           "2012-12-12 14:00:00"
          ],
          [
           15,
           46,
           13.94,
           "2012-12-12 15:00:00"
          ],
          [
           16,
           46,
           13.94,
           "2012-12-12 16:00:00"
          ],
          [
           17,
           53,
           13.12,
           "2012-12-12 17:00:00"
          ],
          [
           18,
           49,
           13.12,
           "2012-12-12 18:00:00"
          ],
          [
           19,
           56,
           12.3,
           "2012-12-12 19:00:00"
          ],
          [
           20,
           52,
           12.3,
           "2012-12-12 20:00:00"
          ],
          [
           21,
           52,
           12.3,
           "2012-12-12 21:00:00"
          ],
          [
           22,
           52,
           12.3,
           "2012-12-12 22:00:00"
          ],
          [
           23,
           56,
           11.48,
           "2012-12-12 23:00:00"
          ],
          [
           0,
           52,
           11.48,
           "2012-12-13 00:00:00"
          ],
          [
           1,
           52,
           11.48,
           "2012-12-13 01:00:00"
          ],
          [
           2,
           56,
           10.66,
           "2012-12-13 02:00:00"
          ],
          [
           3,
           56,
           10.66,
           "2012-12-13 03:00:00"
          ],
          [
           4,
           56,
           10.66,
           "2012-12-13 04:00:00"
          ],
          [
           5,
           56,
           10.66,
           "2012-12-13 05:00:00"
          ],
          [
           6,
           56,
           10.66,
           "2012-12-13 06:00:00"
          ],
          [
           7,
           60,
           9.84,
           "2012-12-13 07:00:00"
          ],
          [
           8,
           60,
           9.84,
           "2012-12-13 08:00:00"
          ],
          [
           9,
           52,
           11.48,
           "2012-12-13 09:00:00"
          ],
          [
           10,
           45,
           13.12,
           "2012-12-13 10:00:00"
          ],
          [
           11,
           42,
           13.94,
           "2012-12-13 11:00:00"
          ],
          [
           12,
           40,
           14.76,
           "2012-12-13 12:00:00"
          ],
          [
           13,
           34,
           14.76,
           "2012-12-13 13:00:00"
          ],
          [
           14,
           34,
           14.76,
           "2012-12-13 14:00:00"
          ],
          [
           15,
           34,
           14.76,
           "2012-12-13 15:00:00"
          ],
          [
           16,
           39,
           13.94,
           "2012-12-13 16:00:00"
          ],
          [
           17,
           42,
           13.12,
           "2012-12-13 17:00:00"
          ],
          [
           18,
           42,
           13.12,
           "2012-12-13 18:00:00"
          ],
          [
           19,
           45,
           12.3,
           "2012-12-13 19:00:00"
          ],
          [
           20,
           45,
           12.3,
           "2012-12-13 20:00:00"
          ],
          [
           21,
           48,
           11.48,
           "2012-12-13 21:00:00"
          ],
          [
           22,
           60,
           10.66,
           "2012-12-13 22:00:00"
          ],
          [
           23,
           60,
           10.66,
           "2012-12-13 23:00:00"
          ],
          [
           0,
           64,
           9.02,
           "2012-12-14 00:00:00"
          ],
          [
           1,
           69,
           9.02,
           "2012-12-14 01:00:00"
          ],
          [
           2,
           69,
           9.02,
           "2012-12-14 02:00:00"
          ],
          [
           3,
           69,
           8.2,
           "2012-12-14 03:00:00"
          ],
          [
           4,
           75,
           8.2,
           "2012-12-14 04:00:00"
          ],
          [
           5,
           69,
           8.2,
           "2012-12-14 05:00:00"
          ],
          [
           6,
           80,
           6.56,
           "2012-12-14 06:00:00"
          ],
          [
           7,
           72,
           8.2,
           "2012-12-14 07:00:00"
          ],
          [
           8,
           69,
           8.2,
           "2012-12-14 08:00:00"
          ],
          [
           9,
           75,
           9.84,
           "2012-12-14 09:00:00"
          ],
          [
           10,
           81,
           10.66,
           "2012-12-14 10:00:00"
          ],
          [
           11,
           65,
           13.12,
           "2012-12-14 11:00:00"
          ],
          [
           12,
           50,
           14.76,
           "2012-12-14 12:00:00"
          ],
          [
           13,
           50,
           14.76,
           "2012-12-14 13:00:00"
          ],
          [
           14,
           43,
           16.4,
           "2012-12-14 14:00:00"
          ],
          [
           15,
           47,
           16.4,
           "2012-12-14 15:00:00"
          ],
          [
           16,
           54,
           15.58,
           "2012-12-14 16:00:00"
          ],
          [
           17,
           57,
           13.94,
           "2012-12-14 17:00:00"
          ],
          [
           18,
           46,
           14.76,
           "2012-12-14 18:00:00"
          ],
          [
           19,
           53,
           13.94,
           "2012-12-14 19:00:00"
          ],
          [
           20,
           61,
           13.12,
           "2012-12-14 20:00:00"
          ],
          [
           21,
           75,
           12.3,
           "2012-12-14 21:00:00"
          ],
          [
           22,
           75,
           11.48,
           "2012-12-14 22:00:00"
          ],
          [
           23,
           75,
           11.48,
           "2012-12-14 23:00:00"
          ],
          [
           0,
           70,
           12.3,
           "2012-12-15 00:00:00"
          ],
          [
           1,
           81,
           10.66,
           "2012-12-15 01:00:00"
          ],
          [
           2,
           81,
           10.66,
           "2012-12-15 02:00:00"
          ],
          [
           3,
           81,
           9.84,
           "2012-12-15 03:00:00"
          ],
          [
           4,
           87,
           9.84,
           "2012-12-15 04:00:00"
          ],
          [
           5,
           75,
           10.66,
           "2012-12-15 05:00:00"
          ],
          [
           6,
           75,
           9.84,
           "2012-12-15 06:00:00"
          ],
          [
           7,
           75,
           9.84,
           "2012-12-15 07:00:00"
          ],
          [
           8,
           75,
           10.66,
           "2012-12-15 08:00:00"
          ],
          [
           9,
           75,
           10.66,
           "2012-12-15 09:00:00"
          ],
          [
           10,
           61,
           13.12,
           "2012-12-15 10:00:00"
          ],
          [
           11,
           61,
           13.94,
           "2012-12-15 11:00:00"
          ],
          [
           12,
           50,
           15.58,
           "2012-12-15 12:00:00"
          ],
          [
           13,
           54,
           15.58,
           "2012-12-15 13:00:00"
          ],
          [
           14,
           50,
           16.4,
           "2012-12-15 14:00:00"
          ],
          [
           15,
           47,
           17.22,
           "2012-12-15 15:00:00"
          ],
          [
           16,
           50,
           16.4,
           "2012-12-15 16:00:00"
          ],
          [
           17,
           50,
           16.4,
           "2012-12-15 17:00:00"
          ],
          [
           18,
           58,
           15.58,
           "2012-12-15 18:00:00"
          ],
          [
           19,
           62,
           14.76,
           "2012-12-15 19:00:00"
          ],
          [
           20,
           57,
           14.76,
           "2012-12-15 20:00:00"
          ],
          [
           21,
           62,
           14.76,
           "2012-12-15 21:00:00"
          ],
          [
           22,
           62,
           14.76,
           "2012-12-15 22:00:00"
          ],
          [
           23,
           62,
           14.76,
           "2012-12-15 23:00:00"
          ],
          [
           0,
           62,
           14.76,
           "2012-12-16 00:00:00"
          ],
          [
           1,
           76,
           13.94,
           "2012-12-16 01:00:00"
          ],
          [
           2,
           87,
           13.94,
           "2012-12-16 02:00:00"
          ],
          [
           3,
           87,
           13.94,
           "2012-12-16 03:00:00"
          ],
          [
           4,
           87,
           13.94,
           "2012-12-16 04:00:00"
          ],
          [
           5,
           87,
           13.94,
           "2012-12-16 05:00:00"
          ],
          [
           6,
           87,
           13.94,
           "2012-12-16 06:00:00"
          ],
          [
           7,
           87,
           13.94,
           "2012-12-16 07:00:00"
          ],
          [
           8,
           87,
           14.76,
           "2012-12-16 08:00:00"
          ],
          [
           9,
           87,
           14.76,
           "2012-12-16 09:00:00"
          ],
          [
           10,
           87,
           14.76,
           "2012-12-16 10:00:00"
          ],
          [
           11,
           87,
           14.76,
           "2012-12-16 11:00:00"
          ],
          [
           12,
           82,
           15.58,
           "2012-12-16 12:00:00"
          ],
          [
           13,
           76,
           15.58,
           "2012-12-16 13:00:00"
          ],
          [
           14,
           76,
           15.58,
           "2012-12-16 14:00:00"
          ],
          [
           15,
           82,
           15.58,
           "2012-12-16 15:00:00"
          ],
          [
           16,
           82,
           15.58,
           "2012-12-16 16:00:00"
          ],
          [
           17,
           82,
           15.58,
           "2012-12-16 17:00:00"
          ],
          [
           18,
           82,
           15.58,
           "2012-12-16 18:00:00"
          ],
          [
           19,
           93,
           14.76,
           "2012-12-16 19:00:00"
          ],
          [
           20,
           82,
           15.58,
           "2012-12-16 20:00:00"
          ],
          [
           21,
           93,
           14.76,
           "2012-12-16 21:00:00"
          ],
          [
           22,
           82,
           16.4,
           "2012-12-16 22:00:00"
          ],
          [
           23,
           93,
           14.76,
           "2012-12-16 23:00:00"
          ],
          [
           0,
           87,
           15.58,
           "2012-12-17 00:00:00"
          ],
          [
           1,
           87,
           15.58,
           "2012-12-17 01:00:00"
          ],
          [
           2,
           94,
           15.58,
           "2012-12-17 02:00:00"
          ],
          [
           3,
           93,
           14.76,
           "2012-12-17 03:00:00"
          ],
          [
           4,
           100,
           14.76,
           "2012-12-17 04:00:00"
          ],
          [
           5,
           87,
           15.58,
           "2012-12-17 05:00:00"
          ],
          [
           6,
           93,
           14.76,
           "2012-12-17 06:00:00"
          ],
          [
           7,
           93,
           14.76,
           "2012-12-17 07:00:00"
          ],
          [
           8,
           87,
           15.58,
           "2012-12-17 08:00:00"
          ],
          [
           9,
           87,
           16.4,
           "2012-12-17 09:00:00"
          ],
          [
           10,
           87,
           15.58,
           "2012-12-17 10:00:00"
          ],
          [
           11,
           87,
           16.4,
           "2012-12-17 11:00:00"
          ],
          [
           12,
           87,
           16.4,
           "2012-12-17 12:00:00"
          ],
          [
           13,
           87,
           16.4,
           "2012-12-17 13:00:00"
          ],
          [
           14,
           87,
           16.4,
           "2012-12-17 14:00:00"
          ],
          [
           15,
           88,
           17.22,
           "2012-12-17 15:00:00"
          ],
          [
           16,
           94,
           16.4,
           "2012-12-17 16:00:00"
          ],
          [
           17,
           94,
           16.4,
           "2012-12-17 17:00:00"
          ],
          [
           18,
           94,
           16.4,
           "2012-12-17 18:00:00"
          ],
          [
           19,
           88,
           17.22,
           "2012-12-17 19:00:00"
          ],
          [
           20,
           94,
           17.22,
           "2012-12-17 20:00:00"
          ],
          [
           21,
           94,
           17.22,
           "2012-12-17 21:00:00"
          ],
          [
           22,
           94,
           17.22,
           "2012-12-17 22:00:00"
          ],
          [
           23,
           94,
           17.22,
           "2012-12-17 23:00:00"
          ],
          [
           0,
           94,
           18.04,
           "2012-12-18 00:00:00"
          ],
          [
           1,
           94,
           18.04,
           "2012-12-18 01:00:00"
          ],
          [
           2,
           88,
           18.04,
           "2012-12-18 02:00:00"
          ],
          [
           3,
           88,
           17.22,
           "2012-12-18 03:00:00"
          ],
          [
           4,
           82,
           17.22,
           "2012-12-18 04:00:00"
          ],
          [
           5,
           87,
           15.58,
           "2012-12-18 05:00:00"
          ],
          [
           6,
           93,
           14.76,
           "2012-12-18 06:00:00"
          ],
          [
           7,
           93,
           14.76,
           "2012-12-18 07:00:00"
          ],
          [
           8,
           94,
           15.58,
           "2012-12-18 08:00:00"
          ],
          [
           9,
           87,
           16.4,
           "2012-12-18 09:00:00"
          ],
          [
           10,
           77,
           18.04,
           "2012-12-18 10:00:00"
          ],
          [
           11,
           63,
           19.68,
           "2012-12-18 11:00:00"
          ],
          [
           12,
           48,
           19.68,
           "2012-12-18 12:00:00"
          ],
          [
           13,
           42,
           20.5,
           "2012-12-18 13:00:00"
          ],
          [
           14,
           47,
           18.86,
           "2012-12-18 14:00:00"
          ],
          [
           15,
           44,
           18.86,
           "2012-12-18 15:00:00"
          ],
          [
           16,
           41,
           18.04,
           "2012-12-18 16:00:00"
          ],
          [
           17,
           47,
           16.4,
           "2012-12-18 17:00:00"
          ],
          [
           18,
           46,
           15.58,
           "2012-12-18 18:00:00"
          ],
          [
           19,
           46,
           15.58,
           "2012-12-18 19:00:00"
          ],
          [
           20,
           50,
           14.76,
           "2012-12-18 20:00:00"
          ],
          [
           21,
           50,
           14.76,
           "2012-12-18 21:00:00"
          ],
          [
           22,
           49,
           13.94,
           "2012-12-18 22:00:00"
          ],
          [
           23,
           49,
           13.94,
           "2012-12-18 23:00:00"
          ],
          [
           0,
           61,
           12.3,
           "2012-12-19 00:00:00"
          ],
          [
           1,
           65,
           12.3,
           "2012-12-19 01:00:00"
          ],
          [
           2,
           65,
           11.48,
           "2012-12-19 02:00:00"
          ],
          [
           3,
           75,
           10.66,
           "2012-12-19 03:00:00"
          ],
          [
           4,
           75,
           9.84,
           "2012-12-19 04:00:00"
          ],
          [
           5,
           75,
           10.66,
           "2012-12-19 05:00:00"
          ],
          [
           6,
           75,
           9.84,
           "2012-12-19 06:00:00"
          ],
          [
           7,
           75,
           10.66,
           "2012-12-19 07:00:00"
          ],
          [
           8,
           87,
           9.84,
           "2012-12-19 08:00:00"
          ],
          [
           9,
           75,
           11.48,
           "2012-12-19 09:00:00"
          ],
          [
           10,
           70,
           13.12,
           "2012-12-19 10:00:00"
          ],
          [
           11,
           54,
           16.4,
           "2012-12-19 11:00:00"
          ],
          [
           12,
           54,
           16.4,
           "2012-12-19 12:00:00"
          ],
          [
           13,
           50,
           17.22,
           "2012-12-19 13:00:00"
          ],
          [
           14,
           50,
           17.22,
           "2012-12-19 14:00:00"
          ],
          [
           15,
           50,
           17.22,
           "2012-12-19 15:00:00"
          ],
          [
           16,
           50,
           17.22,
           "2012-12-19 16:00:00"
          ],
          [
           17,
           50,
           16.4,
           "2012-12-19 17:00:00"
          ],
          [
           18,
           50,
           15.58,
           "2012-12-19 18:00:00"
          ],
          [
           19,
           50,
           15.58,
           "2012-12-19 19:00:00"
          ],
          [
           20,
           57,
           14.76,
           "2012-12-19 20:00:00"
          ],
          [
           21,
           61,
           13.94,
           "2012-12-19 21:00:00"
          ],
          [
           22,
           61,
           13.94,
           "2012-12-19 22:00:00"
          ],
          [
           23,
           66,
           13.12,
           "2012-12-19 23:00:00"
          ]
         ],
         "hovertemplate": "index=%{x}<br>res=%{y}<br>heure=%{customdata[0]}<br>humidity=%{customdata[1]}<br>temp=%{customdata[2]}<br>date=%{customdata[3]}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000,
          1001,
          1002,
          1003,
          1004,
          1005,
          1006,
          1007,
          1008,
          1009,
          1010,
          1011,
          1012,
          1013,
          1014,
          1015,
          1016,
          1017,
          1018,
          1019,
          1020,
          1021,
          1022,
          1023,
          1024,
          1025,
          1026,
          1027,
          1028,
          1029,
          1030,
          1031,
          1032,
          1033,
          1034,
          1035,
          1036,
          1037,
          1038,
          1039,
          1040,
          1041,
          1042,
          1043,
          1044,
          1045,
          1046,
          1047,
          1048,
          1049,
          1050,
          1051,
          1052,
          1053,
          1054,
          1055,
          1056,
          1057,
          1058,
          1059,
          1060,
          1061,
          1062,
          1063,
          1064,
          1065,
          1066,
          1067,
          1068,
          1069,
          1070,
          1071,
          1072,
          1073,
          1074,
          1075,
          1076,
          1077,
          1078,
          1079,
          1080,
          1081,
          1082,
          1083,
          1084,
          1085,
          1086,
          1087,
          1088,
          1089,
          1090,
          1091,
          1092,
          1093,
          1094,
          1095,
          1096,
          1097,
          1098,
          1099,
          1100,
          1101,
          1102,
          1103,
          1104,
          1105,
          1106,
          1107,
          1108,
          1109,
          1110,
          1111,
          1112,
          1113,
          1114,
          1115,
          1116,
          1117,
          1118,
          1119,
          1120,
          1121,
          1122,
          1123,
          1124,
          1125,
          1126,
          1127,
          1128,
          1129,
          1130,
          1131,
          1132,
          1133,
          1134,
          1135,
          1136,
          1137,
          1138,
          1139,
          1140,
          1141,
          1142,
          1143,
          1144,
          1145,
          1146,
          1147,
          1148,
          1149,
          1150,
          1151,
          1152,
          1153,
          1154,
          1155,
          1156,
          1157,
          1158,
          1159,
          1160,
          1161,
          1162,
          1163,
          1164,
          1165,
          1166,
          1167,
          1168,
          1169,
          1170,
          1171,
          1172,
          1173,
          1174,
          1175,
          1176,
          1177,
          1178,
          1179,
          1180,
          1181,
          1182,
          1183,
          1184,
          1185,
          1186,
          1187,
          1188,
          1189,
          1190,
          1191,
          1192,
          1193,
          1194,
          1195,
          1196,
          1197,
          1198,
          1199,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1207,
          1208,
          1209,
          1210,
          1211,
          1212,
          1213,
          1214,
          1215,
          1216,
          1217,
          1218,
          1219,
          1220,
          1221,
          1222,
          1223,
          1224,
          1225,
          1226,
          1227,
          1228,
          1229,
          1230,
          1231,
          1232,
          1233,
          1234,
          1235,
          1236,
          1237,
          1238,
          1239,
          1240,
          1241,
          1242,
          1243,
          1244,
          1245,
          1246,
          1247,
          1248,
          1249,
          1250,
          1251,
          1252,
          1253,
          1254,
          1255,
          1256,
          1257,
          1258,
          1259,
          1260,
          1261,
          1262,
          1263,
          1264,
          1265,
          1266,
          1267,
          1268,
          1269,
          1270,
          1271,
          1272,
          1273,
          1274,
          1275,
          1276,
          1277,
          1278,
          1279,
          1280,
          1281,
          1282,
          1283,
          1284,
          1285,
          1286,
          1287,
          1288,
          1289,
          1290,
          1291,
          1292,
          1293,
          1294,
          1295,
          1296,
          1297,
          1298,
          1299,
          1300,
          1301,
          1302,
          1303,
          1304,
          1305,
          1306,
          1307,
          1308,
          1309,
          1310,
          1311,
          1312,
          1313,
          1314,
          1315,
          1316,
          1317,
          1318,
          1319,
          1320,
          1321,
          1322,
          1323,
          1324,
          1325,
          1326,
          1327,
          1328,
          1329,
          1330,
          1331,
          1332,
          1333,
          1334,
          1335,
          1336,
          1337,
          1338,
          1339,
          1340,
          1341,
          1342,
          1343,
          1344,
          1345,
          1346,
          1347,
          1348,
          1349,
          1350,
          1351,
          1352,
          1353,
          1354,
          1355,
          1356,
          1357,
          1358,
          1359,
          1360,
          1361,
          1362,
          1363,
          1364,
          1365,
          1366,
          1367,
          1368,
          1369,
          1370,
          1371,
          1372,
          1373,
          1374,
          1375,
          1376,
          1377,
          1378,
          1379,
          1380,
          1381,
          1382,
          1383,
          1384,
          1385,
          1386,
          1387,
          1388,
          1389,
          1390,
          1391,
          1392,
          1393,
          1394,
          1395,
          1396,
          1397,
          1398,
          1399,
          1400,
          1401,
          1402,
          1403,
          1404,
          1405,
          1406,
          1407,
          1408,
          1409,
          1410,
          1411,
          1412,
          1413,
          1414,
          1415,
          1416,
          1417,
          1418,
          1419,
          1420,
          1421,
          1422,
          1423,
          1424,
          1425,
          1426,
          1427,
          1428,
          1429,
          1430,
          1431,
          1432,
          1433,
          1434,
          1435,
          1436,
          1437,
          1438,
          1439,
          1440,
          1441,
          1442,
          1443,
          1444,
          1445,
          1446,
          1447,
          1448,
          1449,
          1450,
          1451,
          1452,
          1453,
          1454,
          1455,
          1456,
          1457,
          1458,
          1459,
          1460,
          1461,
          1462,
          1463,
          1464,
          1465,
          1466,
          1467,
          1468,
          1469,
          1470,
          1471,
          1472,
          1473,
          1474,
          1475,
          1476,
          1477,
          1478,
          1479,
          1480,
          1481,
          1482,
          1483,
          1484,
          1485,
          1486,
          1487,
          1488,
          1489,
          1490,
          1491,
          1492,
          1493,
          1494,
          1495,
          1496,
          1497,
          1498,
          1499,
          1500,
          1501,
          1502,
          1503,
          1504,
          1505,
          1506,
          1507,
          1508,
          1509,
          1510,
          1511,
          1512,
          1513,
          1514,
          1515,
          1516,
          1517,
          1518,
          1519,
          1520,
          1521,
          1522,
          1523,
          1524,
          1525,
          1526,
          1527,
          1528,
          1529,
          1530,
          1531,
          1532,
          1533,
          1534,
          1535,
          1536,
          1537,
          1538,
          1539,
          1540,
          1541,
          1542,
          1543,
          1544,
          1545,
          1546,
          1547,
          1548,
          1549,
          1550,
          1551,
          1552,
          1553,
          1554,
          1555,
          1556,
          1557,
          1558,
          1559,
          1560,
          1561,
          1562,
          1563,
          1564,
          1565,
          1566,
          1567,
          1568,
          1569,
          1570,
          1571,
          1572,
          1573,
          1574,
          1575,
          1576,
          1577,
          1578,
          1579,
          1580,
          1581,
          1582,
          1583,
          1584,
          1585,
          1586,
          1587,
          1588,
          1589,
          1590,
          1591,
          1592,
          1593,
          1594,
          1595,
          1596,
          1597,
          1598,
          1599,
          1600,
          1601,
          1602,
          1603,
          1604,
          1605,
          1606,
          1607,
          1608,
          1609,
          1610,
          1611,
          1612,
          1613,
          1614,
          1615,
          1616,
          1617,
          1618,
          1619,
          1620,
          1621,
          1622,
          1623,
          1624,
          1625,
          1626,
          1627,
          1628,
          1629,
          1630,
          1631,
          1632,
          1633,
          1634,
          1635,
          1636,
          1637,
          1638,
          1639,
          1640,
          1641,
          1642,
          1643,
          1644,
          1645,
          1646,
          1647,
          1648,
          1649,
          1650,
          1651,
          1652,
          1653,
          1654,
          1655,
          1656,
          1657,
          1658,
          1659,
          1660,
          1661,
          1662,
          1663,
          1664,
          1665,
          1666,
          1667,
          1668,
          1669,
          1670,
          1671,
          1672,
          1673,
          1674,
          1675,
          1676,
          1677,
          1678,
          1679,
          1680,
          1681,
          1682,
          1683,
          1684,
          1685,
          1686,
          1687,
          1688,
          1689,
          1690,
          1691,
          1692,
          1693,
          1694,
          1695,
          1696,
          1697,
          1698,
          1699,
          1700,
          1701,
          1702,
          1703,
          1704,
          1705,
          1706,
          1707,
          1708,
          1709,
          1710,
          1711,
          1712,
          1713,
          1714,
          1715,
          1716,
          1717,
          1718,
          1719,
          1720,
          1721,
          1722,
          1723,
          1724,
          1725,
          1726,
          1727,
          1728,
          1729,
          1730,
          1731,
          1732,
          1733,
          1734,
          1735,
          1736,
          1737,
          1738,
          1739,
          1740,
          1741,
          1742,
          1743,
          1744,
          1745,
          1746,
          1747,
          1748,
          1749,
          1750,
          1751,
          1752,
          1753,
          1754,
          1755,
          1756,
          1757,
          1758,
          1759,
          1760,
          1761,
          1762,
          1763,
          1764,
          1765,
          1766,
          1767,
          1768,
          1769,
          1770,
          1771,
          1772,
          1773,
          1774,
          1775,
          1776,
          1777,
          1778,
          1779,
          1780,
          1781,
          1782,
          1783,
          1784,
          1785,
          1786,
          1787,
          1788,
          1789,
          1790,
          1791,
          1792,
          1793,
          1794,
          1795,
          1796,
          1797,
          1798,
          1799,
          1800,
          1801,
          1802,
          1803,
          1804,
          1805,
          1806,
          1807,
          1808,
          1809,
          1810,
          1811,
          1812,
          1813,
          1814,
          1815,
          1816,
          1817,
          1818,
          1819,
          1820,
          1821,
          1822
         ],
         "xaxis": "x",
         "y": [
          10.205001831054688,
          -46.201324462890625,
          -15.309745788574219,
          -6.185905456542969,
          -4.186511993408203,
          16.140738487243652,
          16.659025192260742,
          -21.964271545410156,
          -32.231109619140625,
          -5.5677032470703125,
          20.41058349609375,
          6.9031982421875,
          -35.939361572265625,
          15.35784912109375,
          52.888946533203125,
          102.77902221679688,
          18.165802001953125,
          23.951324462890625,
          4.8907470703125,
          -31.578826904296875,
          -114.65875244140625,
          10.500930786132812,
          -73.20111083984375,
          -25.350723266601562,
          -51.48844909667969,
          -38.55940246582031,
          4.142768859863281,
          1.71099853515625,
          12.626733779907227,
          1.677830696105957,
          -14.177139282226562,
          19.878767013549805,
          -62.40350341796875,
          -31.880706787109375,
          40.702667236328125,
          54.746002197265625,
          138.42623901367188,
          109.88827514648438,
          115.08328247070312,
          -13.618896484375,
          7.65020751953125,
          8.9937744140625,
          62.951873779296875,
          -27.385009765625,
          -133.2452392578125,
          -79.63165283203125,
          64.70118713378906,
          12.301132202148438,
          -31.464431762695312,
          -30.418014526367188,
          5.713962554931641,
          26.572693347930908,
          40.24837303161621,
          35.82060241699219,
          -10.63627815246582,
          -102.71401977539062,
          -93.4542236328125,
          -106.045166015625,
          23.431304931640625,
          45.940826416015625,
          37.886688232421875,
          65.3878173828125,
          134.89163208007812,
          36.220184326171875,
          66.28021240234375,
          20.992584228515625,
          -93.79864501953125,
          -36.98614501953125,
          -55.297088623046875,
          -144.797119140625,
          -126.602294921875,
          -153.7598419189453,
          -11.241691589355469,
          -12.5146484375,
          -20.382465362548828,
          -2.5744876861572266,
          -2.6872005462646484,
          0.13851547241210938,
          3.596527099609375,
          75.0560302734375,
          22.77642822265625,
          -27.98809814453125,
          -59.8426513671875,
          -55.15303039550781,
          -10.559326171875,
          19.129226684570312,
          32.06733703613281,
          -0.82342529296875,
          101.02615356445312,
          218.9339599609375,
          114.86798095703125,
          29.673828125,
          -14.229248046875,
          -28.52886962890625,
          -53.571807861328125,
          -67.83367919921875,
          -26.580638885498047,
          2.08994197845459,
          8.234600186347961,
          -9.640301704406738,
          -8.640301704406738,
          6.507530212402344,
          38.156890869140625,
          60.425323486328125,
          61.2557373046875,
          -37.45892333984375,
          -1.9549713134765625,
          -31.632904052734375,
          -16.785430908203125,
          -50.69427490234375,
          -57.42474365234375,
          -17.91705322265625,
          78.74945068359375,
          91.56671142578125,
          108.65411376953125,
          114.3140869140625,
          -4.45233154296875,
          -7.58770751953125,
          -19.074569702148438,
          -14.629837036132812,
          16.088504791259766,
          -4.8068084716796875,
          5.5793750286102295,
          14.906662464141846,
          -6.563702583312988,
          5.651172637939453,
          29.375518798828125,
          48.77606201171875,
          187.3546142578125,
          -52.94856262207031,
          -58.66822052001953,
          -134.43386840820312,
          -137.52886962890625,
          -63.02757263183594,
          -47.90045166015625,
          -37.97869873046875,
          50.906402587890625,
          196.25634765625,
          144.05621337890625,
          58.772735595703125,
          12.8939208984375,
          15.1416015625,
          29.095550537109375,
          56.616607666015625,
          45.80217361450195,
          4.539787292480469,
          -4.032305717468262,
          -2.4204463958740234,
          -1.946401596069336,
          2.87933349609375,
          -28.251449584960938,
          67.91830444335938,
          110.5823974609375,
          20.19573974609375,
          -4.6873321533203125,
          57.41291809082031,
          36.474456787109375,
          72.15316772460938,
          2.594818115234375,
          29.717071533203125,
          41.7691650390625,
          -25.140869140625,
          56.11541748046875,
          0.64654541015625,
          -48.58953857421875,
          -14.820159912109375,
          79.4180908203125,
          126.47450256347656,
          5.2071533203125,
          21.374053955078125,
          44.0803108215332,
          22.214248657226562,
          18.021037101745605,
          5.772188186645508,
          8.423316955566406,
          49.49009704589844,
          46.3214111328125,
          58.43170166015625,
          72.40023803710938,
          170.43948364257812,
          206.97866821289062,
          157.17294311523438,
          105.07366943359375,
          288.137939453125,
          -191.91738891601562,
          -109.30307006835938,
          -90.83819580078125,
          31.923507690429688,
          -15.131378173828125,
          44.139617919921875,
          43.845367431640625,
          93.77914810180664,
          3.208709716796875,
          20.579238891601562,
          22.309425354003906,
          18.268518447875977,
          6.658794403076172,
          44.90000343322754,
          5.1183624267578125,
          -37.524688720703125,
          -3.7547607421875,
          37.552459716796875,
          79.1986083984375,
          78.37896728515625,
          185.48883056640625,
          108.33349609375,
          52.716796875,
          109.244140625,
          102.6202392578125,
          42.66058349609375,
          10.582763671875,
          45.134307861328125,
          44.009002685546875,
          -64.79132080078125,
          -10.8616943359375,
          -67.75808715820312,
          -21.170848846435547,
          -22.373756408691406,
          1.373927116394043,
          -8.506023406982422,
          -15.506023406982422,
          2.9573440551757812,
          15.337005615234375,
          37.44696044921875,
          88.30511474609375,
          35.1263427734375,
          1.8091278076171875,
          1.225341796875,
          33.110107421875,
          1.041168212890625,
          46.175689697265625,
          29.16754150390625,
          22.06695556640625,
          50.83612060546875,
          235.25537109375,
          112.718505859375,
          -44.8802490234375,
          -40.36224365234375,
          -71.06269836425781,
          -79.43983459472656,
          -36.32647705078125,
          -24.251968383789062,
          -13.934860229492188,
          -6.601799964904785,
          -6.335301399230957,
          3.832134246826172,
          47.576263427734375,
          147.97540283203125,
          173.3260498046875,
          21.71771240234375,
          -18.83721923828125,
          2.018096923828125,
          10.226593017578125,
          8.186859130859375,
          -76.11233520507812,
          -26.027008056640625,
          32.906219482421875,
          131.25360107421875,
          64.73980712890625,
          57.54180908203125,
          57.8143310546875,
          8.144256591796875,
          5.821258544921875,
          -16.85015106201172,
          -12.60671615600586,
          -10.195932388305664,
          -7.613128662109375,
          -8.397343635559082,
          -10.231093406677246,
          8.465343475341797,
          38.049652099609375,
          147.22149658203125,
          125.40948486328125,
          -16.800628662109375,
          -8.517654418945312,
          -13.824981689453125,
          0.603546142578125,
          -32.64788818359375,
          -42.733551025390625,
          -13.263671875,
          23.69500732421875,
          73.01300048828125,
          217.29296875,
          109.3076171875,
          57.918670654296875,
          -2.04046630859375,
          -3.5157318115234375,
          -8.379440307617188,
          -6.245231628417969,
          -2.5755748748779297,
          -7.674840927124023,
          -5.10926628112793,
          -10.10926628112793,
          15.361888885498047,
          28.850433349609375,
          177.40142822265625,
          128.45391845703125,
          4.091339111328125,
          11.265762329101562,
          18.2508544921875,
          -14.58270263671875,
          -47.09967041015625,
          -51.328521728515625,
          33.94476318359375,
          1.134521484375,
          39.72955322265625,
          131.9534912109375,
          124.91363525390625,
          89.96212768554688,
          14.16229248046875,
          46.87017822265625,
          44.616172790527344,
          23.75476837158203,
          8.165531158447266,
          13.121257781982422,
          0.9370222091674805,
          -1.0629777908325195,
          5.367351531982422,
          -17.2027587890625,
          68.07937622070312,
          153.57611083984375,
          31.971435546875,
          21.3177490234375,
          30.702285766601562,
          94.81463623046875,
          100.12893676757812,
          78.34603881835938,
          64.74627685546875,
          109.01019287109375,
          69.8011474609375,
          17.94317626953125,
          -13.67626953125,
          -17.9761962890625,
          17.39398193359375,
          92.18205261230469,
          37.64289855957031,
          51.68742370605469,
          -10.691184997558594,
          20.102882385253906,
          6.064935684204102,
          3.518979072570801,
          -15.486347198486328,
          -14.94912338256836,
          -29.7779541015625,
          -21.524276733398438,
          59.86981201171875,
          19.982879638671875,
          92.239990234375,
          76.53387451171875,
          86.52642822265625,
          111.28424072265625,
          92.1092529296875,
          218.7569580078125,
          114.69439697265625,
          77.61669921875,
          49.100799560546875,
          22.544830322265625,
          24.629486083984375,
          76.47767639160156,
          101.49781036376953,
          5.4364776611328125,
          8.175529479980469,
          18.55754852294922,
          18.679588317871094,
          0.4629178047180176,
          6.26576566696167,
          6.830598831176758,
          -33.96092987060547,
          -90.19438171386719,
          36.508331298828125,
          62.04351806640625,
          44.845703125,
          70.52166748046875,
          114.3232421875,
          59.0428466796875,
          -52.87896728515625,
          42.22979736328125,
          6.4581298828125,
          -49.3614501953125,
          -24.410400390625,
          7.3450927734375,
          -88.8917236328125,
          -63.44456481933594,
          -24.06707000732422,
          -14.824832916259766,
          -10.800268173217773,
          -3.0174903869628906,
          -8.397343635559082,
          -1.8017005920410156,
          2.961925506591797,
          1.7486724853515625,
          88.882080078125,
          102.7330322265625,
          -41.36578369140625,
          -13.430007934570312,
          20.457733154296875,
          7.586334228515625,
          52.1119384765625,
          84.77186584472656,
          60.038421630859375,
          105.82794189453125,
          101.32904052734375,
          124.73077392578125,
          31.69769287109375,
          4.9134521484375,
          157.30550384521484,
          114.42960929870605,
          60.152753829956055,
          2.4205846786499023,
          4.507857322692871,
          13.652520179748535,
          4.15199077129364,
          38.64404106140137,
          44.352795362472534,
          33.68058776855469,
          -84.65313720703125,
          46.621826171875,
          -58.5546875,
          36.346336364746094,
          -27.417739868164062,
          -38.792823791503906,
          -106.51123046875,
          153.5138063430786,
          8.28570556640625,
          23.701141357421875,
          -5.45001220703125,
          -198.3916015625,
          -59.3284912109375,
          34.61778259277344,
          53.73368835449219,
          136.9026393890381,
          10.498260498046875,
          -12.19393539428711,
          -2.151134490966797,
          -2.7148995399475098,
          5.89709734916687,
          2.208303928375244,
          22.07259750366211,
          5.5487823486328125,
          140.73678588867188,
          197.62750244140625,
          6.3516845703125,
          -22.365814208984375,
          5.7038726806640625,
          -2.239715576171875,
          -24.723388671875,
          -2.64715576171875,
          9.30120849609375,
          19.3895263671875,
          51.37860107421875,
          137.10333251953125,
          55.182373046875,
          28.774383544921875,
          48.37005615234375,
          -25.07427978515625,
          -43.16905212402344,
          -27.780731201171875,
          -13.470588684082031,
          -7.430727005004883,
          -9.681657791137695,
          -1.1795883178710938,
          -4.985218048095703,
          -11.326690673828125,
          25.594024658203125,
          165.08856201171875,
          -4.496337890625,
          -62.30561828613281,
          10.194671630859375,
          38.75970458984375,
          22.123260498046875,
          -21.314300537109375,
          51.30621337890625,
          15.559295654296875,
          178.40869140625,
          -45.61065673828125,
          26.579345703125,
          57.78639221191406,
          13.174957275390625,
          151.4206428527832,
          58.737083435058594,
          -14.042121887207031,
          -14.686712265014648,
          -14.202186584472656,
          2.3641750812530518,
          11.999454617500305,
          20.360107421875,
          103.28578186035156,
          47.25480651855469,
          -258.659912109375,
          -73.720458984375,
          -30.220680236816406,
          19.507652282714844,
          -54.24114990234375,
          25.914794921875,
          89.68191528320312,
          94.73519897460938,
          202.97708129882812,
          401.290771484375,
          409.358642578125,
          158.50579833984375,
          163.51951599121094,
          276.9898958206177,
          154.7920379638672,
          2.6775588989257812,
          24.466472625732422,
          9.563583374023438,
          9.953917622566223,
          14.097078323364258,
          21.168766021728516,
          20.385783195495605,
          49.08583068847656,
          123.45437622070312,
          250.128173828125,
          49.870574951171875,
          -20.993621826171875,
          23.840835571289062,
          95.19168090820312,
          38.78466796875,
          3.833770751953125,
          14.93853759765625,
          81.376708984375,
          128.8143310546875,
          51.297607421875,
          28.1685791015625,
          73.02664184570312,
          -76.373779296875,
          -42.020904541015625,
          61.0380859375,
          33.88014221191406,
          15.563583374023438,
          -23.264171600341797,
          18.682344913482666,
          0.672938346862793,
          35.72897672653198,
          78.0705680847168,
          9.434417724609375,
          73.96466064453125,
          71.09671020507812,
          13.392837524414062,
          -2.8928985595703125,
          6.499481201171875,
          26.726409912109375,
          8.0037841796875,
          31.29486083984375,
          37.32867431640625,
          67.1812744140625,
          104.84375,
          -44.0465087890625,
          26.022796630859375,
          11.0784912109375,
          -39.4097900390625,
          3.73236083984375,
          30.03784942626953,
          13.786247253417969,
          -19.27310562133789,
          -10.443426132202148,
          -15.609676361083984,
          -9.823429107666016,
          -40.551544189453125,
          31.144622802734375,
          104.50897216796875,
          27.7557373046875,
          7.13818359375,
          61.204132080078125,
          166.70950317382812,
          148.80563354492188,
          111.70016479492188,
          134.43179321289062,
          163.71142578125,
          57.7071533203125,
          -12.5950927734375,
          6.629608154296875,
          -4.02001953125,
          -5.316802978515625,
          52.57757568359375,
          43.021087646484375,
          53.530914306640625,
          44.54529571533203,
          -8.377578735351562,
          26.942150115966797,
          -7.957820892333984,
          2.2995781898498535,
          -12.145854949951172,
          -35.32884216308594,
          40.78663635253906,
          97.86801147460938,
          159.373291015625,
          179.07589721679688,
          198.73846435546875,
          219.64266967773438,
          102.17279052734375,
          55.1470947265625,
          78.09124755859375,
          171.57708740234375,
          68.8162841796875,
          -29.134857177734375,
          29.487457275390625,
          40.364898681640625,
          44.85711669921875,
          55.721649169921875,
          20.53081512451172,
          24.344078063964844,
          21.653884887695312,
          -17.832046508789062,
          -1.7487668991088867,
          -11.678924560546875,
          -9.782386779785156,
          16.206661224365234,
          -87.92448425292969,
          -57.50604248046875,
          -121.64453125,
          19.004852294921875,
          51.844268798828125,
          -36.075347900390625,
          -1.55474853515625,
          65.90951538085938,
          123.31661987304688,
          -19.687026977539062,
          -48.23149108886719,
          -125.38809204101562,
          1.7847518920898438,
          20.266891479492188,
          11.527069091796875,
          39.125858306884766,
          -37.04412841796875,
          -28.22228240966797,
          -15.088659286499023,
          3.0476765632629395,
          -6.64439582824707,
          12.80122709274292,
          20.22461700439453,
          86.7038803100586,
          193.19834899902344,
          134.0800018310547,
          48.46968078613281,
          -17.79107666015625,
          -29.395782470703125,
          5.486053466796875,
          92.05740356445312,
          102.35183715820312,
          127.64347839355469,
          153.5601806640625,
          123.0628662109375,
          44.681427001953125,
          147.40094757080078,
          -8.329116821289062,
          23.297195434570312,
          -36.245513916015625,
          19.900623321533203,
          -10.860954284667969,
          -10.77177619934082,
          -13.524312973022461,
          -15.89718246459961,
          -8.86137580871582,
          39.49028015136719,
          -36.935882568359375,
          91.946044921875,
          2.026092529296875,
          -64.42935180664062,
          -83.75137329101562,
          -60.749114990234375,
          -59.78369140625,
          -10.858963012695312,
          -23.156890869140625,
          29.627777099609375,
          128.99053955078125,
          86.53857421875,
          -0.115234375,
          35.589019775390625,
          -5.2425384521484375,
          -40.06181335449219,
          -57.138763427734375,
          -11.809467315673828,
          -14.29948616027832,
          -3.909151077270508,
          -2.7239818572998047,
          -1.6163086891174316,
          6.500858306884766,
          23.213973999023438,
          31.2750244140625,
          202.7896728515625,
          5.273406982421875,
          14.261032104492188,
          42.445281982421875,
          92.76821899414062,
          22.638275146484375,
          -47.73748779296875,
          -30.4871826171875,
          80.9970703125,
          139.17132568359375,
          142.68402099609375,
          82.35665893554688,
          86.3829345703125,
          0.163421630859375,
          -4.41265869140625,
          -23.753494262695312,
          -15.3402099609375,
          -17.245004653930664,
          -3.565237045288086,
          -8.002537727355957,
          2.2676796913146973,
          6.4246978759765625,
          42.29150390625,
          65.86770629882812,
          139.203369140625,
          -21.69134521484375,
          -42.596435546875,
          -21.81805419921875,
          -24.181060791015625,
          -98.32778930664062,
          15.819610595703125,
          85.54061889648438,
          -13.20672607421875,
          74.47515869140625,
          59.99468994140625,
          247.531982421875,
          62.314453125,
          -34.27569580078125,
          -21.309982299804688,
          3.438690185546875,
          20.234756469726562,
          14.697250366210938,
          6.884403228759766,
          -4.666013717651367,
          -1.0867490768432617,
          2.62744140625,
          15.309501647949219,
          -15.549224853515625,
          100.1156005859375,
          -21.496612548828125,
          13.14910888671875,
          47.73211669921875,
          67.02093505859375,
          64.60064697265625,
          109.00003051757812,
          137.714599609375,
          149.77981567382812,
          156.8109130859375,
          9.49420166015625,
          10.719573974609375,
          -38.342376708984375,
          -72.19204711914062,
          -32.937530517578125,
          -20.377578735351562,
          147.9170150756836,
          67.0810546875,
          7.171054840087891,
          -0.186248779296875,
          4.1539154052734375,
          3.5991106033325195,
          -0.17577743530273438,
          33.89628219604492,
          35.3848876953125,
          53.74040222167969,
          4.349884033203125,
          116.2396240234375,
          84.04376220703125,
          180.9940185546875,
          48.23291015625,
          99.0052490234375,
          85.87969970703125,
          93.19732666015625,
          124.54827880859375,
          10.20220947265625,
          78.41264343261719,
          66.87677001953125,
          61.23876190185547,
          -5.6611785888671875,
          11.409957885742188,
          43.52691650390625,
          5.463584899902344,
          6.991077423095703,
          -0.5722169876098633,
          14.14188528060913,
          -8.620292663574219,
          -41.696441650390625,
          -117.38119506835938,
          -57.72454833984375,
          47.30413818359375,
          23.853485107421875,
          -4.79840087890625,
          33.0704345703125,
          -4.79779052734375,
          -44.080810546875,
          9.01220703125,
          -47.61669921875,
          -60.70745849609375,
          -73.76959228515625,
          39.73809814453125,
          -44.19914245605469,
          -60.942626953125,
          8.220489501953125,
          15.571388244628906,
          4.331531524658203,
          -4.791534423828125,
          9.017819881439209,
          12.964135885238647,
          17.07731819152832,
          -0.4252471923828125,
          23.640655517578125,
          82.54559326171875,
          154.5238494873047,
          -63.409912109375,
          26.134735107421875,
          105.03804016113281,
          24.05188751220703,
          -58.31089782714844,
          -1.0511474609375,
          32.602935791015625,
          -38.84063720703125,
          138.44247436523438,
          -58.055328369140625,
          -73.24850463867188,
          -46.1536865234375,
          -108.33457946777344,
          -89.63166809082031,
          -13.294303894042969,
          -15.192073822021484,
          -15.384796142578125,
          -9.627043724060059,
          -3.688028335571289,
          17.74453353881836,
          9.801422119140625,
          101.78875732421875,
          169.428955078125,
          -42.14312744140625,
          -38.3887939453125,
          -60.920166015625,
          24.95843505859375,
          27.33941650390625,
          -0.638916015625,
          30.186309814453125,
          -7.57568359375,
          203.25848388671875,
          132.76068115234375,
          13.0870361328125,
          72.17572021484375,
          -89.20687866210938,
          -7.9015045166015625,
          61.25318908691406,
          11.462566375732422,
          -12.121402740478516,
          -1.9892292022705078,
          0.1390061378479004,
          -5.777077674865723,
          11.695486068725586,
          47.77299499511719,
          53.32916259765625,
          182.5447998046875,
          20.402191162109375,
          12.488754272460938,
          -24.9132080078125,
          60.605743408203125,
          39.695098876953125,
          21.452484130859375,
          5.7099609375,
          56.340911865234375,
          177.6591796875,
          192.94134521484375,
          -27.6197509765625,
          42.496490478515625,
          137.0234832763672,
          97.67987823486328,
          34.21617889404297,
          11.189434051513672,
          -13.764989852905273,
          -8.351871490478516,
          -3.2593555450439453,
          -3.2593555450439453,
          4.842430114746094,
          -21.988754272460938,
          69.13485717773438,
          173.60345458984375,
          6.948272705078125,
          -7.5892333984375,
          38.74858093261719,
          97.77212524414062,
          39.7884521484375,
          53.882293701171875,
          82.21502685546875,
          32.100830078125,
          114.41168212890625,
          68.7554931640625,
          42.622589111328125,
          34.132080078125,
          60.931121826171875,
          97.05270385742188,
          40.36597442626953,
          29.857160568237305,
          14.439457535743713,
          3.48004150390625,
          7.643967390060425,
          8.643967390060425,
          7.1363677978515625,
          97.80470657348633,
          -38.861968994140625,
          -47.87890625,
          78.99838256835938,
          74.77200317382812,
          103.7630615234375,
          49.47344970703125,
          99.07443237304688,
          90.573974609375,
          89.627685546875,
          346.4812316894531,
          -51.997344970703125,
          -337.0914306640625,
          -218.75537109375,
          -85.56436157226562,
          -65.01300048828125,
          -29.352584838867188,
          17.55040740966797,
          14.351387023925781,
          5.190481185913086,
          7.840888977050781,
          -1.330648422241211,
          8.249080181121826,
          12.312768936157227,
          14.198623657226562,
          22.0592041015625,
          52.8330078125,
          97.32138061523438,
          -75.28634643554688,
          -65.27690124511719,
          -25.535507202148438,
          -9.53564453125,
          -55.28401184082031,
          -46.557647705078125,
          31.43170166015625,
          232.21408081054688,
          180.556884765625,
          72.98577880859375,
          38.336456298828125,
          51.73963928222656,
          19.21514892578125,
          -13.851089477539062,
          2.3336029052734375,
          2.1243896484375,
          -0.8730278015136719,
          -8.452460289001465,
          -5.391477584838867,
          -2.2649593353271484,
          -7.818115234375,
          -4.488128662109375,
          60.23748779296875,
          37.044769287109375,
          -34.737548828125,
          -46.633392333984375,
          -37.748626708984375,
          -27.344329833984375,
          -22.129150390625,
          0.628814697265625,
          44.439422607421875,
          28.85357666015625,
          -47.29473876953125,
          -53.645294189453125,
          -28.198394775390625,
          -60.21763610839844,
          -37.662841796875,
          -13.216232299804688,
          4.509529113769531,
          38.06985092163086,
          4.004035949707031,
          18.39949321746826,
          18.128762006759644,
          11.329218864440918,
          0.10634613037109375,
          22.990711212158203,
          -1.059295654296875,
          32.87666320800781,
          26.6885986328125,
          21.389404296875,
          44.86102294921875,
          99.5743408203125,
          126.35635375976562,
          117.16436767578125,
          73.6531982421875,
          161.54844665527344,
          64.89407348632812,
          -6.626434326171875,
          7.9708709716796875,
          9.68670654296875,
          -0.9513702392578125,
          35.5262451171875,
          6.046592712402344,
          90.53329467773438,
          -22.78195571899414,
          -16.485191345214844,
          0.9374618530273438,
          -0.7114038467407227,
          -12.415470123291016,
          57.7699933052063,
          33.34873962402344,
          32.06425476074219,
          84.44952392578125,
          90.88204956054688,
          100.3072509765625,
          44.38397216796875,
          58.77978515625,
          9.602874755859375,
          -9.002105712890625,
          3.8753662109375,
          -60.959716796875,
          -30.915008544921875,
          -42.12629699707031,
          -67.10589599609375,
          -57.44189453125,
          -13.175796508789062,
          -16.23461151123047,
          -23.247562408447266,
          -15.892627716064453,
          -0.45485639572143555,
          21.800591945648193,
          18.967504501342773,
          39.6568603515625,
          102.8189697265625,
          57.05596923828125,
          -57.23828125,
          -39.17140197753906,
          -73.42630004882812,
          -68.1729736328125,
          -104.81100463867188,
          -117.17083740234375,
          -107.79833984375,
          15.508056640625,
          110.39666748046875,
          43.6605224609375,
          23.9112548828125,
          -27.536590576171875,
          -78.49337768554688,
          -59.706298828125,
          -70.43051147460938,
          -22.09477996826172,
          -18.55307960510254,
          -13.248363494873047,
          -6.297233581542969,
          -2.6755409240722656,
          10.665750503540039,
          22.414474487304688,
          40.39453125,
          15.5782470703125,
          44.454376220703125,
          48.41943359375,
          11.087020874023438,
          -10.267974853515625,
          8.997772216796875,
          -66.62713623046875,
          3.578033447265625,
          83.8624267578125,
          123.52642822265625,
          28.0091552734375,
          32.415863037109375,
          -47.787506103515625,
          -49.74530029296875,
          -26.859954833984375,
          76.36973571777344,
          259.2653064727783,
          76.7747392654419,
          72.8476892709732,
          14.439549922943115,
          17.190497398376465,
          5.362497329711914,
          2.4326171875,
          -30.9560546875,
          16.49957275390625,
          57.456085205078125,
          2.76470947265625,
          -60.48260498046875,
          -30.555068969726562,
          -52.146087646484375,
          -60.408782958984375,
          -21.773696899414062,
          -7.482940673828125,
          42.660369873046875,
          19.176361083984375,
          5.822509765625,
          13.842086791992188,
          -75.46913146972656,
          -212.2379150390625,
          -140.28732299804688,
          -46.071876525878906,
          -27.272846221923828,
          4.523816108703613,
          14.734261989593506,
          2.6259803771972656,
          -21.221572875976562,
          42.268218994140625,
          98.188720703125,
          -62.86541748046875,
          -46.613922119140625,
          -84.50785827636719,
          -90.9599609375,
          -146.14199829101562,
          -174.36279296875,
          -155.33462524414062,
          -59.980255126953125,
          -8.4500732421875,
          -67.51141357421875,
          -19.842559814453125,
          -14.31439208984375,
          -18.30462646484375,
          -35.57539367675781,
          -47.177154541015625,
          28.445341110229492,
          0.31452369689941406,
          -2.3535356521606445,
          -10.213567733764648,
          -3.098329544067383,
          -7.832183837890625,
          -0.407684326171875,
          -11.436431884765625,
          64.8505859375,
          -15.05108642578125,
          -22.53265380859375,
          6.7622833251953125,
          -67.25543212890625,
          -49.7449951171875,
          -53.68505859375,
          3.36627197265625,
          25.653778076171875,
          -14.1842041015625,
          -134.53594970703125,
          -2.218780517578125,
          -20.06622314453125,
          -18.285491943359375,
          -6.8727874755859375,
          56.126991271972656,
          22.925384521484375,
          1.533294677734375,
          -17.905189514160156,
          -6.787084579467773,
          1.593094825744629,
          1.804276466369629,
          -9.310676574707031,
          83.18368244171143,
          22.510330200195312,
          67.71107482910156,
          35.7015380859375,
          103.92318725585938,
          149.40066528320312,
          132.1806640625,
          117.33535766601562,
          85.81655883789062,
          86.26690673828125,
          80.07839965820312,
          25.54144287109375,
          -23.00836181640625,
          10.486190795898438,
          73.92298889160156,
          66.54898834228516,
          67.32775115966797,
          32.01941680908203,
          38.668296813964844,
          15.645145416259766,
          23.2097225189209,
          3.416043758392334,
          8.048884153366089,
          -7.030857086181641,
          39.84246063232422,
          18.078872680664062,
          78.75726318359375,
          95.0404052734375,
          116.20846557617188,
          123.31771850585938,
          210.08218383789062,
          42.21923828125,
          161.70220947265625,
          134.7734375,
          73.38357543945312,
          22.304168701171875,
          -107.84136962890625,
          43.89741516113281,
          14.5758056640625,
          22.349456787109375,
          25.91040802001953,
          -44.46540069580078,
          -29.03917694091797,
          -24.563194274902344,
          -5.204460144042969,
          3.2952470779418945,
          4.523601531982422,
          8.454681396484375,
          58.18367004394531,
          228.82818603515625,
          68.00244140625,
          -102.86795043945312,
          -45.04180908203125,
          -43.471435546875,
          -39.69781494140625,
          -30.266021728515625,
          -90.72384643554688,
          -41.256927490234375,
          61.20343017578125,
          133.857666015625,
          -75.17071533203125,
          52.72831726074219,
          84.98185729980469,
          -95.53030395507812,
          -73.51936340332031,
          -14.197269439697266,
          14.02747631072998,
          -7.036312103271484,
          1.6060514450073242,
          10.831892728805542,
          1.5798873901367188,
          -69.767578125,
          -139.2225799560547,
          -219.36175537109375,
          -44.05244445800781,
          9.56353759765625,
          -41.1016845703125,
          -64.83358764648438,
          -44.887481689453125,
          -85.27389526367188,
          -115.86532592773438,
          -64.34149169921875,
          78.3092041015625,
          65.10781860351562,
          13.758209228515625,
          -40.346221923828125,
          -37.28428649902344,
          -39.70391845703125,
          -35.94654846191406,
          -16.654510498046875,
          -13.286237716674805,
          -14.27116584777832,
          -4.82794189453125,
          -6.677452087402344,
          5.843479156494141,
          15.083084106445312,
          49.1397705078125,
          85.20306396484375,
          12.87811279296875,
          -27.964996337890625,
          -47.959625244140625,
          -47.1802978515625,
          -98.87811279296875,
          -111.22634887695312,
          -48.35296630859375,
          16.29522705078125,
          86.9874267578125,
          86.26605224609375,
          52.1055908203125,
          -6.371673583984375,
          -25.005340576171875,
          -3.113067626953125,
          -9.297409057617188,
          -8.195808410644531,
          -6.554529190063477,
          -6.529480934143066,
          -14.866960525512695,
          -7.108519554138184,
          11.818761825561523,
          34.45429229736328,
          35.687103271484375,
          45.640869140625,
          -11.986663818359375,
          -26.159713745117188,
          -34.76924133300781,
          -39.75262451171875,
          -43.71746826171875,
          -37.922760009765625,
          -28.12969970703125,
          43.91424560546875,
          59.358062744140625,
          99.15701293945312,
          53.095947265625,
          1.45904541015625,
          27.664306640625,
          -8.7890625,
          21.393226623535156,
          33.788869857788086,
          -7.350618362426758,
          -4.529480934143066,
          -6.108519554138184,
          -5.014425277709961,
          -0.2895851135253906,
          -0.896881103515625,
          13.227447509765625,
          114.425537109375,
          6.044769287109375,
          -6.1621246337890625,
          -35.40220642089844,
          -30.205352783203125,
          -85.9376220703125,
          -101.96759033203125,
          -100.78121948242188,
          -14.49969482421875,
          44.66796875,
          -0.242950439453125,
          -50.81500244140625,
          -54.506103515625,
          -58.01576232910156,
          -35.658203125,
          -10.94012451171875,
          9.338973999023438,
          16.42383575439453,
          -6.9774169921875,
          -1.470102310180664,
          4.679962873458862,
          8.954202890396118,
          -0.036525726318359375,
          66.63449382781982,
          118.07036590576172,
          56.08708190917969,
          23.2845458984375,
          54.104248046875,
          18.8489990234375,
          38.3157958984375,
          81.50588989257812,
          61.595489501953125,
          34.558837890625,
          -7.01617431640625,
          17.561904907226562,
          -5.179534912109375,
          32.79386901855469,
          12.818222045898438,
          55.223175048828125,
          91.67880249023438,
          47.97026062011719,
          27.970130920410156,
          21.663009643554688,
          35.21273326873779,
          23.859292030334473,
          10.848361730575562,
          -3.6750965118408203,
          55.58405685424805,
          1.7377090454101562,
          32.31098937988281,
          56.27099609375,
          22.360015869140625,
          59.360992431640625,
          65.16592407226562,
          51.713348388671875,
          -19.201171875,
          15.301177978515625,
          -36.0126953125,
          20.698928833007812,
          -32.25263977050781,
          -40.95036315917969,
          -48.451690673828125,
          -40.15763854980469,
          -38.01409149169922,
          -3.454866409301758,
          11.090269565582275,
          6.4757399559021,
          10.586851119995117,
          20.586851119995117,
          24.99138069152832,
          22.454124450683594,
          -12.6658935546875,
          31.55718994140625,
          -79.27001953125,
          -71.79377746582031,
          -43.19093322753906,
          -38.842010498046875,
          -59.249298095703125,
          -65.03057861328125,
          -50.923736572265625,
          45.099700927734375,
          19.8580322265625,
          75.91839599609375,
          15.810577392578125,
          -6.5400390625,
          -37.378814697265625,
          -73.21348571777344,
          -52.35411071777344,
          10.620903015136719,
          -11.23760986328125,
          -9.396354675292969,
          4.312361717224121,
          -8.657696723937988,
          5.3329176902771,
          7.559223175048828,
          100.82880401611328,
          128.82484436035156,
          96.95126342773438,
          53.12188720703125,
          146.5100555419922,
          173.7012939453125,
          232.38824462890625,
          202.68276977539062,
          141.14501953125,
          128.23681640625,
          124.70820617675781,
          110.22236633300781,
          89.48406982421875,
          55.6070556640625,
          64.2550277709961,
          79.93001556396484,
          86.3476791381836,
          18.605751037597656,
          15.937042236328125,
          9.367500305175781,
          -4.941946029663086,
          -9.196840286254883,
          -8.436239242553711,
          -6.108919143676758,
          66.83103942871094,
          61.43453407287598,
          78.3924560546875,
          79.26301574707031,
          115.36238098144531,
          239.1361083984375,
          53.98797607421875,
          52.8736572265625,
          4.16436767578125,
          113.67019653320312,
          109.33119201660156,
          -50.12849426269531,
          -26.886276245117188,
          91.85126113891602,
          -37.78193664550781,
          -9.608177185058594,
          4.575092315673828,
          -21.416912078857422,
          -20.245620727539062,
          -6.953769683837891,
          -5.829785346984863,
          -3.769014358520508,
          4.051116943359375,
          13.253875732421875,
          67.50289916992188,
          108.33306884765625,
          -39.35595703125,
          -98.12130737304688,
          -31.959381103515625,
          -49.688232421875,
          35.071929931640625,
          -14.241546630859375,
          -15.9114990234375,
          10.7191162109375,
          56.296142578125,
          28.4456787109375,
          -88.525634765625,
          3.039642333984375,
          26.497817993164062,
          -20.780502319335938,
          -26.863479614257812,
          7.472858428955078,
          -2.8560829162597656,
          -8.56654167175293,
          -1.9854512214660645,
          1.0145487785339355,
          13.383617401123047,
          45.80645751953125,
          91.71905517578125,
          139.7218017578125,
          -64.11117553710938,
          -86.80966186523438,
          -45.27113342285156,
          20.248779296875,
          3.12774658203125,
          35.637054443359375,
          54.80174255371094,
          38.753387451171875,
          105.30938720703125,
          70.93988037109375,
          -89.00244140625,
          -45.494110107421875,
          35.77693176269531,
          -13.02508544921875,
          -58.28929138183594,
          -15.691608428955078,
          -13.764455795288086,
          -10.188026428222656,
          -11.253154754638672,
          -6.302417755126953,
          13.855838775634766,
          67.80351257324219,
          70.86294555664062,
          120.12591552734375,
          10.23876953125,
          -110.37989807128906,
          -94.89956665039062,
          -89.28167724609375,
          -104.684814453125,
          -108.623046875,
          -54.18414306640625,
          -18.59906005859375,
          -79.38116455078125,
          -12.4376220703125,
          -16.0352783203125,
          5.949493408203125,
          -50.83399963378906,
          -93.57463073730469,
          -54.48591613769531,
          12.246980667114258,
          -1.5688133239746094,
          3.938872814178467,
          -7.449126243591309,
          -2.088498115539551,
          -0.33526611328125,
          9.603988647460938,
          78.7110595703125,
          89.59576416015625,
          -26.22515869140625,
          -9.11785888671875,
          14.652923583984375,
          -10.367034912109375,
          -45.94989013671875,
          -35.42854309082031,
          -19.49053955078125,
          13.171661376953125,
          128.47982788085938,
          126.7147216796875,
          68.4337158203125,
          13.264572143554688,
          21.596755981445312,
          -23.2724609375,
          -11.866851806640625,
          6.168895721435547,
          4.158266067504883,
          -3.2041664123535156,
          3.7451679706573486,
          -5.1055192947387695,
          0.41237831115722656,
          -40.152915954589844,
          -16.829147338867188,
          -157.8095703125,
          15.451080322265625,
          -1.6656494140625,
          6.7384796142578125,
          -1.7167816162109375,
          -31.8924560546875,
          5.1949920654296875,
          83.22467041015625,
          89.86380004882812,
          83.08880615234375,
          31.786895751953125,
          -8.088470458984375,
          40.37763977050781,
          43.516395568847656,
          66.25528717041016,
          54.861976623535156,
          22.511940002441406,
          40.83507537841797,
          14.451351165771484,
          12.619461059570312,
          12.678557813167572,
          7.233017444610596,
          0.27915191650390625,
          41.5329794883728,
          -6.117332458496094,
          -1.3929595947265625,
          27.105987548828125,
          117.34588623046875,
          188.136962890625,
          249.54473876953125,
          263.6891784667969,
          181.26022338867188,
          156.15313720703125,
          77.04898071289062,
          52.086029052734375,
          3.8076019287109375,
          142.2899398803711,
          187.19877815246582,
          111.48149108886719,
          109.9602279663086,
          17.221267700195312,
          29.377037048339844,
          16.14931869506836,
          24.970367431640625,
          12.51932442188263,
          2.5839200019836426,
          -27.93122100830078,
          1.6650257110595703,
          25.946517944335938,
          -87.36856079101562,
          -63.030548095703125,
          -44.721649169921875,
          13.82891845703125,
          -5.766632080078125,
          -40.322296142578125,
          72.27584838867188,
          96.91375732421875,
          167.5691032409668,
          144.23544311523438,
          -16.801345825195312,
          25.983871459960938,
          35.292076110839844,
          57.76261520385742,
          7.999805450439453,
          -0.7486362457275391,
          45.56533432006836,
          2.312415599822998,
          4.497585892677307,
          12.497585892677307,
          3.1940250396728516,
          15.174964904785156,
          -42.15478515625,
          39.61505126953125,
          -52.55340576171875,
          -87.31874084472656,
          -13.864898681640625,
          28.470138549804688,
          96.69085693359375,
          14.213821411132812,
          11.828933715820312,
          50.946746826171875,
          107.83419799804688,
          144.41827392578125,
          -69.1962890625,
          47.55517578125,
          75.50096130371094,
          -58.85987854003906,
          11.211616516113281,
          -26.333091735839844,
          -25.845561981201172,
          4.449288845062256,
          -21.918609619140625,
          8.713558375835419,
          -3.3417587280273438,
          9.009117126464844,
          -18.570404052734375,
          88.3978271484375,
          -14.854766845703125,
          -58.62005615234375,
          -59.21282958984375,
          -37.90106201171875,
          -29.5711669921875,
          -54.831573486328125,
          -9.24078369140625,
          30.252471923828125,
          112.46347045898438,
          79.35797119140625,
          83.98974609375,
          -23.1123046875,
          -29.478378295898438,
          -83.91145324707031,
          -72.98097229003906,
          -0.8403472900390625,
          -10.390874862670898,
          -13.739423751831055,
          -4.5313873291015625,
          -12.862974166870117,
          3.0876693725585938,
          20.543678283691406,
          25.392059326171875,
          116.46484375,
          -27.0211181640625,
          -35.88349914550781,
          -35.335723876953125,
          -49.548675537109375,
          -35.0474853515625,
          -9.514739990234375,
          -5.811126708984375,
          43.71307373046875,
          96.5682373046875,
          107.21942138671875,
          78.33624267578125,
          -2.242706298828125,
          -9.269180297851562,
          -68.38383483886719,
          -49.59819030761719,
          13.396308898925781,
          24.253745555877686,
          5.923865079879761,
          6.739299774169922,
          -1.8334999084472656,
          -2.884998321533203,
          -19.28143310546875,
          42.54754638671875,
          88.36175537109375,
          10.23846435546875,
          -20.086334228515625,
          -41.65789794921875,
          -36.426025390625,
          -56.86407470703125,
          -60.9288330078125,
          -45.24700927734375,
          64.77706909179688,
          22.38818359375,
          -33.92242431640625,
          -1.174896240234375,
          -34.681854248046875,
          -2.0052490234375,
          -37.098175048828125,
          -5.898719787597656,
          14.696186065673828,
          2.2066307067871094,
          -4.518396377563477,
          -0.48863792419433594,
          -1.9006271362304688,
          1.0322952270507812,
          -2.8769073486328125,
          -28.102081298828125,
          69.56842041015625,
          32.7896728515625,
          59.16493225097656,
          14.617218017578125,
          -3.430938720703125,
          36.293609619140625,
          6.478485107421875,
          16.59002685546875,
          86.43289184570312,
          109.57391357421875,
          -52.158782958984375,
          -61.838226318359375,
          -57.733795166015625,
          -40.87672424316406,
          -11.820022583007812,
          30.978851318359375,
          -1.6147537231445312,
          22.173194885253906,
          3.5888214111328125,
          1.1443843841552734,
          2.1207644939422607,
          -2.074885368347168,
          -7.784942626953125,
          71.33426666259766,
          83.8881607055664,
          89.1021728515625,
          19.123519897460938,
          63.79644775390625,
          41.197235107421875,
          45.38134765625,
          20.525665283203125,
          7.6954345703125,
          15.01837158203125,
          11.42083740234375,
          -33.91650390625,
          22.031814575195312,
          48.45530700683594,
          46.47526550292969,
          43.829193115234375,
          58.95964050292969,
          9.561111450195312,
          2.2400894165039062,
          27.150466918945312,
          26.70806312561035,
          5.318922996520996,
          3.0795254707336426,
          -15.971878051757812,
          11.284746170043945,
          0.26387786865234375,
          -9.833999633789062,
          28.60693359375,
          36.87799072265625,
          95.8651123046875,
          18.748504638671875,
          -1.7572021484375,
          58.012908935546875,
          120.53280639648438,
          11.1871337890625,
          -33.7271728515625,
          -69.57756042480469,
          29.46466064453125,
          38.76805114746094,
          37.6591682434082,
          11.899580001831055,
          2.694730758666992,
          -3.773923873901367,
          1.2047450542449951,
          6.999552965164185,
          40.5954475402832,
          -6.609651565551758,
          0.240966796875,
          -11.440948486328125,
          -3.2332763671875,
          -35.87908935546875,
          -42.66673278808594,
          13.333648681640625,
          23.89190673828125,
          16.183944702148438,
          3.2265625,
          3.9457244873046875,
          244.36675262451172,
          194.12881469726562,
          187.4903564453125,
          -19.27838134765625,
          -7.5275115966796875,
          -45.58241271972656,
          -64.86705780029297,
          -30.362167358398438,
          -3.0952701568603516,
          0.8808708190917969,
          7.942321956157684,
          0.3983302116394043,
          -11.67242431640625,
          -2.6049461364746094,
          -7.771003723144531,
          -19.548126220703125,
          22.77960205078125,
          -21.35595703125,
          -53.872711181640625,
          1.8353271484375,
          97.56562805175781,
          -58.504913330078125,
          -21.350982666015625,
          -47.549224853515625,
          10.667755126953125,
          33.519775390625,
          -28.39312744140625,
          -73.957763671875,
          -14.64544677734375,
          -78.42410278320312,
          -49.97496032714844,
          -63.645599365234375,
          -5.4521331787109375,
          -14.821062088012695,
          -15.818485260009766,
          -10.452581405639648,
          -5.881372451782227,
          -7.759674072265625,
          -16.297744750976562,
          9.863861083984375,
          109.76422119140625,
          -4.281402587890625,
          -21.993865966796875,
          -45.28776550292969,
          -46.770965576171875,
          -94.88803100585938,
          -57.8428955078125,
          -43.4368896484375,
          48.7918701171875,
          46.02288818359375,
          62.8018798828125,
          -85.85507202148438,
          -37.190582275390625,
          -78.08287048339844,
          -61.877166748046875,
          -57.08134460449219
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "index"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "res"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test_res = X_test\n",
    "X_test_res[\"res\"] = res\n",
    "X_test_res[\"date\"] = date\n",
    "\n",
    "fig = px.scatter(X_test_res,y=\"res\",hover_data=[\"heure\",\"humidity\",\"temp\",\"date\"])\n",
    "#fig.update_traces(mode=\"markers\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.470716593459095"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_analyses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17122/1615466619.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmasque\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdf_analyses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"heure\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmasque\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_analyses' is not defined"
     ]
    }
   ],
   "source": [
    "masque = [df_analyses[\"heure\"]==3]\n",
    "masque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "      <th>heure</th>\n",
       "      <th>jour</th>\n",
       "      <th>mois</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3691</th>\n",
       "      <td>2011-09-04 17:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.16</td>\n",
       "      <td>36.365</td>\n",
       "      <td>66</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>204</td>\n",
       "      <td>172</td>\n",
       "      <td>376</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9152</th>\n",
       "      <td>2012-09-04 17:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31.16</td>\n",
       "      <td>36.365</td>\n",
       "      <td>70</td>\n",
       "      <td>23.9994</td>\n",
       "      <td>110</td>\n",
       "      <td>746</td>\n",
       "      <td>856</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780</th>\n",
       "      <td>2011-09-08 12:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27.06</td>\n",
       "      <td>29.545</td>\n",
       "      <td>94</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>17</td>\n",
       "      <td>85</td>\n",
       "      <td>102</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9243</th>\n",
       "      <td>2012-09-08 12:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.80</td>\n",
       "      <td>37.880</td>\n",
       "      <td>55</td>\n",
       "      <td>32.9975</td>\n",
       "      <td>220</td>\n",
       "      <td>474</td>\n",
       "      <td>694</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>2011-09-08 15:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27.06</td>\n",
       "      <td>29.545</td>\n",
       "      <td>89</td>\n",
       "      <td>19.9995</td>\n",
       "      <td>24</td>\n",
       "      <td>115</td>\n",
       "      <td>139</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9246</th>\n",
       "      <td>2012-09-08 15:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.96</td>\n",
       "      <td>26.515</td>\n",
       "      <td>88</td>\n",
       "      <td>16.9979</td>\n",
       "      <td>175</td>\n",
       "      <td>337</td>\n",
       "      <td>512</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>2011-09-10 18:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.52</td>\n",
       "      <td>33.335</td>\n",
       "      <td>58</td>\n",
       "      <td>12.9980</td>\n",
       "      <td>119</td>\n",
       "      <td>241</td>\n",
       "      <td>360</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9297</th>\n",
       "      <td>2012-09-10 18:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.42</td>\n",
       "      <td>31.060</td>\n",
       "      <td>35</td>\n",
       "      <td>19.9995</td>\n",
       "      <td>111</td>\n",
       "      <td>857</td>\n",
       "      <td>968</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>2011-09-12 18:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.70</td>\n",
       "      <td>32.575</td>\n",
       "      <td>54</td>\n",
       "      <td>12.9980</td>\n",
       "      <td>56</td>\n",
       "      <td>515</td>\n",
       "      <td>571</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9345</th>\n",
       "      <td>2012-09-12 18:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.06</td>\n",
       "      <td>31.060</td>\n",
       "      <td>44</td>\n",
       "      <td>16.9979</td>\n",
       "      <td>91</td>\n",
       "      <td>886</td>\n",
       "      <td>977</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>2011-09-15 16:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22.14</td>\n",
       "      <td>25.760</td>\n",
       "      <td>77</td>\n",
       "      <td>31.0009</td>\n",
       "      <td>29</td>\n",
       "      <td>193</td>\n",
       "      <td>222</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9415</th>\n",
       "      <td>2012-09-15 16:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.06</td>\n",
       "      <td>31.060</td>\n",
       "      <td>36</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>350</td>\n",
       "      <td>433</td>\n",
       "      <td>783</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4087</th>\n",
       "      <td>2011-10-02 08:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.94</td>\n",
       "      <td>16.665</td>\n",
       "      <td>76</td>\n",
       "      <td>12.9980</td>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9551</th>\n",
       "      <td>2012-10-02 08:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24.60</td>\n",
       "      <td>27.275</td>\n",
       "      <td>88</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>134</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>2011-10-02 16:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14.76</td>\n",
       "      <td>17.425</td>\n",
       "      <td>87</td>\n",
       "      <td>12.9980</td>\n",
       "      <td>44</td>\n",
       "      <td>162</td>\n",
       "      <td>206</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9559</th>\n",
       "      <td>2012-10-02 16:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25.42</td>\n",
       "      <td>28.030</td>\n",
       "      <td>88</td>\n",
       "      <td>8.9981</td>\n",
       "      <td>46</td>\n",
       "      <td>328</td>\n",
       "      <td>374</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4096</th>\n",
       "      <td>2011-10-02 17:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14.76</td>\n",
       "      <td>17.425</td>\n",
       "      <td>87</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>32</td>\n",
       "      <td>135</td>\n",
       "      <td>167</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9560</th>\n",
       "      <td>2012-10-02 17:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25.42</td>\n",
       "      <td>28.030</td>\n",
       "      <td>88</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>38</td>\n",
       "      <td>677</td>\n",
       "      <td>715</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4097</th>\n",
       "      <td>2011-10-02 18:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14.76</td>\n",
       "      <td>17.425</td>\n",
       "      <td>81</td>\n",
       "      <td>12.9980</td>\n",
       "      <td>16</td>\n",
       "      <td>158</td>\n",
       "      <td>174</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>2012-10-02 18:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25.42</td>\n",
       "      <td>27.275</td>\n",
       "      <td>94</td>\n",
       "      <td>6.0032</td>\n",
       "      <td>48</td>\n",
       "      <td>639</td>\n",
       "      <td>687</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4100</th>\n",
       "      <td>2011-10-02 21:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.76</td>\n",
       "      <td>17.425</td>\n",
       "      <td>71</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>17</td>\n",
       "      <td>71</td>\n",
       "      <td>88</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9564</th>\n",
       "      <td>2012-10-02 21:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25.42</td>\n",
       "      <td>27.275</td>\n",
       "      <td>94</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>24</td>\n",
       "      <td>265</td>\n",
       "      <td>289</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111</th>\n",
       "      <td>2011-10-03 08:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14.76</td>\n",
       "      <td>18.180</td>\n",
       "      <td>71</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>13</td>\n",
       "      <td>359</td>\n",
       "      <td>372</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9575</th>\n",
       "      <td>2012-10-03 08:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25.42</td>\n",
       "      <td>28.030</td>\n",
       "      <td>88</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>28</td>\n",
       "      <td>781</td>\n",
       "      <td>809</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4188</th>\n",
       "      <td>2011-10-06 13:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.96</td>\n",
       "      <td>26.515</td>\n",
       "      <td>46</td>\n",
       "      <td>6.0032</td>\n",
       "      <td>33</td>\n",
       "      <td>158</td>\n",
       "      <td>191</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9652</th>\n",
       "      <td>2012-10-06 13:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.24</td>\n",
       "      <td>31.060</td>\n",
       "      <td>57</td>\n",
       "      <td>35.0008</td>\n",
       "      <td>310</td>\n",
       "      <td>400</td>\n",
       "      <td>710</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>2011-10-10 08:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.32</td>\n",
       "      <td>25.000</td>\n",
       "      <td>83</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>27</td>\n",
       "      <td>227</td>\n",
       "      <td>254</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9743</th>\n",
       "      <td>2012-10-10 08:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.50</td>\n",
       "      <td>24.240</td>\n",
       "      <td>77</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>33</td>\n",
       "      <td>806</td>\n",
       "      <td>839</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4314</th>\n",
       "      <td>2011-10-11 19:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.78</td>\n",
       "      <td>27.275</td>\n",
       "      <td>83</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>33</td>\n",
       "      <td>285</td>\n",
       "      <td>318</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9778</th>\n",
       "      <td>2012-10-11 19:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.04</td>\n",
       "      <td>21.970</td>\n",
       "      <td>51</td>\n",
       "      <td>8.9981</td>\n",
       "      <td>81</td>\n",
       "      <td>662</td>\n",
       "      <td>743</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432</th>\n",
       "      <td>2011-10-16 17:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.78</td>\n",
       "      <td>27.275</td>\n",
       "      <td>49</td>\n",
       "      <td>31.0009</td>\n",
       "      <td>152</td>\n",
       "      <td>253</td>\n",
       "      <td>405</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9896</th>\n",
       "      <td>2012-10-16 17:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.32</td>\n",
       "      <td>25.000</td>\n",
       "      <td>39</td>\n",
       "      <td>12.9980</td>\n",
       "      <td>104</td>\n",
       "      <td>839</td>\n",
       "      <td>943</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502</th>\n",
       "      <td>2011-10-19 16:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.96</td>\n",
       "      <td>26.515</td>\n",
       "      <td>94</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>21</td>\n",
       "      <td>180</td>\n",
       "      <td>201</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9967</th>\n",
       "      <td>2012-10-19 16:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25.42</td>\n",
       "      <td>30.305</td>\n",
       "      <td>69</td>\n",
       "      <td>23.9994</td>\n",
       "      <td>131</td>\n",
       "      <td>434</td>\n",
       "      <td>565</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504</th>\n",
       "      <td>2011-10-19 18:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.96</td>\n",
       "      <td>26.515</td>\n",
       "      <td>100</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>8</td>\n",
       "      <td>132</td>\n",
       "      <td>140</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9969</th>\n",
       "      <td>2012-10-19 18:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.96</td>\n",
       "      <td>26.515</td>\n",
       "      <td>83</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>21</td>\n",
       "      <td>212</td>\n",
       "      <td>233</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4505</th>\n",
       "      <td>2011-10-19 19:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24.60</td>\n",
       "      <td>27.275</td>\n",
       "      <td>88</td>\n",
       "      <td>8.9981</td>\n",
       "      <td>8</td>\n",
       "      <td>189</td>\n",
       "      <td>197</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>2012-10-19 19:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.14</td>\n",
       "      <td>25.760</td>\n",
       "      <td>88</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>19</td>\n",
       "      <td>213</td>\n",
       "      <td>232</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4527</th>\n",
       "      <td>2011-11-01 17:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.04</td>\n",
       "      <td>21.970</td>\n",
       "      <td>54</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>36</td>\n",
       "      <td>470</td>\n",
       "      <td>506</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>2012-11-01 17:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16.40</td>\n",
       "      <td>20.455</td>\n",
       "      <td>50</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>37</td>\n",
       "      <td>652</td>\n",
       "      <td>689</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4654</th>\n",
       "      <td>2011-11-07 00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.94</td>\n",
       "      <td>18.180</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10119</th>\n",
       "      <td>2012-11-07 00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.30</td>\n",
       "      <td>14.395</td>\n",
       "      <td>56</td>\n",
       "      <td>19.0012</td>\n",
       "      <td>49</td>\n",
       "      <td>234</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676</th>\n",
       "      <td>2011-11-07 22:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.76</td>\n",
       "      <td>18.180</td>\n",
       "      <td>81</td>\n",
       "      <td>6.0032</td>\n",
       "      <td>6</td>\n",
       "      <td>102</td>\n",
       "      <td>108</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10141</th>\n",
       "      <td>2012-11-07 22:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12.30</td>\n",
       "      <td>14.395</td>\n",
       "      <td>56</td>\n",
       "      <td>16.9979</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>60</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4763</th>\n",
       "      <td>2011-11-11 13:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.58</td>\n",
       "      <td>19.695</td>\n",
       "      <td>37</td>\n",
       "      <td>36.9974</td>\n",
       "      <td>57</td>\n",
       "      <td>179</td>\n",
       "      <td>236</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10227</th>\n",
       "      <td>2012-11-11 13:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.14</td>\n",
       "      <td>25.760</td>\n",
       "      <td>45</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>262</td>\n",
       "      <td>424</td>\n",
       "      <td>686</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4782</th>\n",
       "      <td>2011-11-12 08:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>70</td>\n",
       "      <td>12.9980</td>\n",
       "      <td>14</td>\n",
       "      <td>87</td>\n",
       "      <td>101</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10246</th>\n",
       "      <td>2012-11-12 08:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.22</td>\n",
       "      <td>21.210</td>\n",
       "      <td>82</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>50</td>\n",
       "      <td>490</td>\n",
       "      <td>540</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4806</th>\n",
       "      <td>2011-11-13 08:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.94</td>\n",
       "      <td>17.425</td>\n",
       "      <td>66</td>\n",
       "      <td>6.0032</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10270</th>\n",
       "      <td>2012-11-13 08:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13.12</td>\n",
       "      <td>15.150</td>\n",
       "      <td>87</td>\n",
       "      <td>16.9979</td>\n",
       "      <td>4</td>\n",
       "      <td>207</td>\n",
       "      <td>211</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>2011-12-01 13:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.40</td>\n",
       "      <td>20.455</td>\n",
       "      <td>40</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>17</td>\n",
       "      <td>137</td>\n",
       "      <td>154</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10443</th>\n",
       "      <td>2012-12-01 13:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.94</td>\n",
       "      <td>18.180</td>\n",
       "      <td>76</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>123</td>\n",
       "      <td>386</td>\n",
       "      <td>509</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>2011-12-01 14:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.40</td>\n",
       "      <td>20.455</td>\n",
       "      <td>40</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>20</td>\n",
       "      <td>130</td>\n",
       "      <td>150</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10444</th>\n",
       "      <td>2012-12-01 14:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14.76</td>\n",
       "      <td>18.940</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>110</td>\n",
       "      <td>369</td>\n",
       "      <td>479</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>2011-12-02 12:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.76</td>\n",
       "      <td>17.425</td>\n",
       "      <td>57</td>\n",
       "      <td>8.9981</td>\n",
       "      <td>18</td>\n",
       "      <td>186</td>\n",
       "      <td>204</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10466</th>\n",
       "      <td>2012-12-02 12:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.94</td>\n",
       "      <td>16.665</td>\n",
       "      <td>81</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>111</td>\n",
       "      <td>409</td>\n",
       "      <td>520</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>2011-12-08 13:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.30</td>\n",
       "      <td>13.635</td>\n",
       "      <td>49</td>\n",
       "      <td>23.9994</td>\n",
       "      <td>9</td>\n",
       "      <td>115</td>\n",
       "      <td>124</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10611</th>\n",
       "      <td>2012-12-08 13:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16.40</td>\n",
       "      <td>20.455</td>\n",
       "      <td>87</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>148</td>\n",
       "      <td>399</td>\n",
       "      <td>547</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5148</th>\n",
       "      <td>2011-12-08 14:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.12</td>\n",
       "      <td>15.150</td>\n",
       "      <td>45</td>\n",
       "      <td>16.9979</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>137</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10612</th>\n",
       "      <td>2012-12-08 14:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16.40</td>\n",
       "      <td>20.455</td>\n",
       "      <td>87</td>\n",
       "      <td>19.0012</td>\n",
       "      <td>164</td>\n",
       "      <td>378</td>\n",
       "      <td>542</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5366</th>\n",
       "      <td>2011-12-17 16:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.48</td>\n",
       "      <td>13.635</td>\n",
       "      <td>45</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>30</td>\n",
       "      <td>192</td>\n",
       "      <td>222</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10830</th>\n",
       "      <td>2012-12-17 16:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16.40</td>\n",
       "      <td>20.455</td>\n",
       "      <td>94</td>\n",
       "      <td>16.9979</td>\n",
       "      <td>15</td>\n",
       "      <td>287</td>\n",
       "      <td>302</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime  season  holiday  workingday  weather   temp  \\\n",
       "3691  2011-09-04 17:00:00       3        0           0        1  31.16   \n",
       "9152  2012-09-04 17:00:00       3        0           1        1  31.16   \n",
       "3780  2011-09-08 12:00:00       3        0           1        2  27.06   \n",
       "9243  2012-09-08 12:00:00       3        0           0        1  32.80   \n",
       "3783  2011-09-08 15:00:00       3        0           1        3  27.06   \n",
       "9246  2012-09-08 15:00:00       3        0           0        3  22.96   \n",
       "3834  2011-09-10 18:00:00       3        0           0        1  29.52   \n",
       "9297  2012-09-10 18:00:00       3        0           1        1  25.42   \n",
       "3881  2011-09-12 18:00:00       3        0           1        1  28.70   \n",
       "9345  2012-09-12 18:00:00       3        0           1        1  27.06   \n",
       "3951  2011-09-15 16:00:00       3        0           1        2  22.14   \n",
       "9415  2012-09-15 16:00:00       3        0           0        2  27.06   \n",
       "4087  2011-10-02 08:00:00       4        0           0        2  13.94   \n",
       "9551  2012-10-02 08:00:00       4        0           1        3  24.60   \n",
       "4095  2011-10-02 16:00:00       4        0           0        3  14.76   \n",
       "9559  2012-10-02 16:00:00       4        0           1        3  25.42   \n",
       "4096  2011-10-02 17:00:00       4        0           0        3  14.76   \n",
       "9560  2012-10-02 17:00:00       4        0           1        3  25.42   \n",
       "4097  2011-10-02 18:00:00       4        0           0        2  14.76   \n",
       "9561  2012-10-02 18:00:00       4        0           1        3  25.42   \n",
       "4100  2011-10-02 21:00:00       4        0           0        1  14.76   \n",
       "9564  2012-10-02 21:00:00       4        0           1        3  25.42   \n",
       "4111  2011-10-03 08:00:00       4        0           1        2  14.76   \n",
       "9575  2012-10-03 08:00:00       4        0           1        2  25.42   \n",
       "4188  2011-10-06 13:00:00       4        0           1        1  22.96   \n",
       "9652  2012-10-06 13:00:00       4        0           0        2  26.24   \n",
       "4279  2011-10-10 08:00:00       4        1           0        1  21.32   \n",
       "9743  2012-10-10 08:00:00       4        0           1        1  20.50   \n",
       "4314  2011-10-11 19:00:00       4        0           1        2  23.78   \n",
       "9778  2012-10-11 19:00:00       4        0           1        1  18.04   \n",
       "4432  2011-10-16 17:00:00       4        0           0        1  23.78   \n",
       "9896  2012-10-16 17:00:00       4        0           1        1  21.32   \n",
       "4502  2011-10-19 16:00:00       4        0           1        3  22.96   \n",
       "9967  2012-10-19 16:00:00       4        0           1        3  25.42   \n",
       "4504  2011-10-19 18:00:00       4        0           1        3  22.96   \n",
       "9969  2012-10-19 18:00:00       4        0           1        1  22.96   \n",
       "4505  2011-10-19 19:00:00       4        0           1        2  24.60   \n",
       "9970  2012-10-19 19:00:00       4        0           1        1  22.14   \n",
       "4527  2011-11-01 17:00:00       4        0           1        1  18.04   \n",
       "9992  2012-11-01 17:00:00       4        0           1        3  16.40   \n",
       "4654  2011-11-07 00:00:00       4        0           1        1  13.94   \n",
       "10119 2012-11-07 00:00:00       4        0           1        2  12.30   \n",
       "4676  2011-11-07 22:00:00       4        0           1        1  14.76   \n",
       "10141 2012-11-07 22:00:00       4        0           1        3  12.30   \n",
       "4763  2011-11-11 13:00:00       4        1           0        1  15.58   \n",
       "10227 2012-11-11 13:00:00       4        0           0        1  22.14   \n",
       "4782  2011-11-12 08:00:00       4        0           0        1  10.66   \n",
       "10246 2012-11-12 08:00:00       4        1           0        1  17.22   \n",
       "4806  2011-11-13 08:00:00       4        0           0        1  13.94   \n",
       "10270 2012-11-13 08:00:00       4        0           1        3  13.12   \n",
       "4979  2011-12-01 13:00:00       4        0           1        1  16.40   \n",
       "10443 2012-12-01 13:00:00       4        0           0        2  13.94   \n",
       "4980  2011-12-01 14:00:00       4        0           1        1  16.40   \n",
       "10444 2012-12-01 14:00:00       4        0           0        2  14.76   \n",
       "5002  2011-12-02 12:00:00       4        0           1        1  14.76   \n",
       "10466 2012-12-02 12:00:00       4        0           0        2  13.94   \n",
       "5147  2011-12-08 13:00:00       4        0           1        1  12.30   \n",
       "10611 2012-12-08 13:00:00       4        0           0        2  16.40   \n",
       "5148  2011-12-08 14:00:00       4        0           1        1  13.12   \n",
       "10612 2012-12-08 14:00:00       4        0           0        2  16.40   \n",
       "5366  2011-12-17 16:00:00       4        0           0        1  11.48   \n",
       "10830 2012-12-17 16:00:00       4        0           1        3  16.40   \n",
       "\n",
       "        atemp  humidity  windspeed  casual  registered  count  heure  jour  \\\n",
       "3691   36.365        66    15.0013     204         172    376     17     4   \n",
       "9152   36.365        70    23.9994     110         746    856     17     4   \n",
       "3780   29.545        94    15.0013      17          85    102     12     8   \n",
       "9243   37.880        55    32.9975     220         474    694     12     8   \n",
       "3783   29.545        89    19.9995      24         115    139     15     8   \n",
       "9246   26.515        88    16.9979     175         337    512     15     8   \n",
       "3834   33.335        58    12.9980     119         241    360     18    10   \n",
       "9297   31.060        35    19.9995     111         857    968     18    10   \n",
       "3881   32.575        54    12.9980      56         515    571     18    12   \n",
       "9345   31.060        44    16.9979      91         886    977     18    12   \n",
       "3951   25.760        77    31.0009      29         193    222     16    15   \n",
       "9415   31.060        36    15.0013     350         433    783     16    15   \n",
       "4087   16.665        76    12.9980      14          50     64      8     2   \n",
       "9551   27.275        88     0.0000       6         128    134      8     2   \n",
       "4095   17.425        87    12.9980      44         162    206     16     2   \n",
       "9559   28.030        88     8.9981      46         328    374     16     2   \n",
       "4096   17.425        87    11.0014      32         135    167     17     2   \n",
       "9560   28.030        88     7.0015      38         677    715     17     2   \n",
       "4097   17.425        81    12.9980      16         158    174     18     2   \n",
       "9561   27.275        94     6.0032      48         639    687     18     2   \n",
       "4100   17.425        71    15.0013      17          71     88     21     2   \n",
       "9564   27.275        94     7.0015      24         265    289     21     2   \n",
       "4111   18.180        71     7.0015      13         359    372      8     3   \n",
       "9575   28.030        88     7.0015      28         781    809      8     3   \n",
       "4188   26.515        46     6.0032      33         158    191     13     6   \n",
       "9652   31.060        57    35.0008     310         400    710     13     6   \n",
       "4279   25.000        83     0.0000      27         227    254      8    10   \n",
       "9743   24.240        77    11.0014      33         806    839      8    10   \n",
       "4314   27.275        83    15.0013      33         285    318     19    11   \n",
       "9778   21.970        51     8.9981      81         662    743     19    11   \n",
       "4432   27.275        49    31.0009     152         253    405     17    16   \n",
       "9896   25.000        39    12.9980     104         839    943     17    16   \n",
       "4502   26.515        94    11.0014      21         180    201     16    19   \n",
       "9967   30.305        69    23.9994     131         434    565     16    19   \n",
       "4504   26.515       100    11.0014       8         132    140     18    19   \n",
       "9969   26.515        83     7.0015      21         212    233     18    19   \n",
       "4505   27.275        88     8.9981       8         189    197     19    19   \n",
       "9970   25.760        88    11.0014      19         213    232     19    19   \n",
       "4527   21.970        54    11.0014      36         470    506     17     1   \n",
       "9992   20.455        50    15.0013      37         652    689     17     1   \n",
       "4654   18.180        87     0.0000       1          14     15      0     7   \n",
       "10119  14.395        56    19.0012      49         234    283      0     7   \n",
       "4676   18.180        81     6.0032       6         102    108     22     7   \n",
       "10141  14.395        56    16.9979       4          56     60     22     7   \n",
       "4763   19.695        37    36.9974      57         179    236     13    11   \n",
       "10227  25.760        45     7.0015     262         424    686     13    11   \n",
       "4782   12.880        70    12.9980      14          87    101      8    12   \n",
       "10246  21.210        82    11.0014      50         490    540      8    12   \n",
       "4806   17.425        66     6.0032      24          55     79      8    13   \n",
       "10270  15.150        87    16.9979       4         207    211      8    13   \n",
       "4979   20.455        40    15.0013      17         137    154     13     1   \n",
       "10443  18.180        76     0.0000     123         386    509     13     1   \n",
       "4980   20.455        40    15.0013      20         130    150     14     1   \n",
       "10444  18.940        71     0.0000     110         369    479     14     1   \n",
       "5002   17.425        57     8.9981      18         186    204     12     2   \n",
       "10466  16.665        81    11.0014     111         409    520     12     2   \n",
       "5147   13.635        49    23.9994       9         115    124     13     8   \n",
       "10611  20.455        87    11.0014     148         399    547     13     8   \n",
       "5148   15.150        45    16.9979      16         121    137     14     8   \n",
       "10612  20.455        87    19.0012     164         378    542     14     8   \n",
       "5366   13.635        45    15.0013      30         192    222     16    17   \n",
       "10830  20.455        94    16.9979      15         287    302     16    17   \n",
       "\n",
       "       mois  \n",
       "3691      9  \n",
       "9152      9  \n",
       "3780      9  \n",
       "9243      9  \n",
       "3783      9  \n",
       "9246      9  \n",
       "3834      9  \n",
       "9297      9  \n",
       "3881      9  \n",
       "9345      9  \n",
       "3951      9  \n",
       "9415      9  \n",
       "4087     10  \n",
       "9551     10  \n",
       "4095     10  \n",
       "9559     10  \n",
       "4096     10  \n",
       "9560     10  \n",
       "4097     10  \n",
       "9561     10  \n",
       "4100     10  \n",
       "9564     10  \n",
       "4111     10  \n",
       "9575     10  \n",
       "4188     10  \n",
       "9652     10  \n",
       "4279     10  \n",
       "9743     10  \n",
       "4314     10  \n",
       "9778     10  \n",
       "4432     10  \n",
       "9896     10  \n",
       "4502     10  \n",
       "9967     10  \n",
       "4504     10  \n",
       "9969     10  \n",
       "4505     10  \n",
       "9970     10  \n",
       "4527     11  \n",
       "9992     11  \n",
       "4654     11  \n",
       "10119    11  \n",
       "4676     11  \n",
       "10141    11  \n",
       "4763     11  \n",
       "10227    11  \n",
       "4782     11  \n",
       "10246    11  \n",
       "4806     11  \n",
       "10270    11  \n",
       "4979     12  \n",
       "10443    12  \n",
       "4980     12  \n",
       "10444    12  \n",
       "5002     12  \n",
       "10466    12  \n",
       "5147     12  \n",
       "10611    12  \n",
       "5148     12  \n",
       "10612    12  \n",
       "5366     12  \n",
       "10830    12  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_foireuses = list(X_test_res[abs(X_test_res[\"res\"]) > 200][\"date\"])\n",
    "df_analyses = pd.read_csv(\"Datas/train.csv\")\n",
    "df_analyses[\"datetime\"] = pd.to_datetime(df_analyses[\"datetime\"])\n",
    "\n",
    "# for i in df_analyses[\"datetime\"]:\n",
    "#     if i in \n",
    "df_analyses[\"heure\"] = [d.time().hour for d in df_analyses[\"datetime\"]]\n",
    "df_analyses[\"jour\"] = [d.day for d in df_analyses[\"datetime\"]]\n",
    "df_analyses[\"mois\"] = [d.month for d in df_analyses[\"datetime\"]]\n",
    "\n",
    "df_date = df_analyses[[str(d) in dates_foireuses for d in df_analyses[\"datetime\"]]]\n",
    "\n",
    "df_date.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "for i in range(0,df_date.shape[0]):\n",
    "    masque = (df_analyses[\"heure\"]==df_date.loc[i][\"heure\"]) & (df_analyses[\"mois\"]==df_date.loc[i][\"mois\"]) & (df_analyses[\"jour\"]==df_date.loc[i][\"jour\"])\n",
    "    #masque = [(d[\"heure\"]==row[\"heure\"]) & (d[\"jour\"]==row[\"jour\"]) & (d[\"mois\"]==row[\"mois\"]) for d in df_analyses]\n",
    "    df_test = df_test.append(df_analyses[masque])\n",
    "    \n",
    "\n",
    "df_test\n",
    "\n",
    "\n",
    "# df_date[\"datetime\"][9152]\n",
    "\n",
    "# df_test = pd.DataFrame()\n",
    "# for d in df_date:\n",
    "#     df_test = df_test.append(d)\n",
    "#     date = d[\"datetime\"]\n",
    "#     if \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "      <th>heure</th>\n",
       "      <th>jour</th>\n",
       "      <th>mois</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime  season  holiday  workingday  weather  temp   atemp  humidity  \\\n",
       "0 2011-01-01     1.0      0.0         0.0      1.0  9.84  14.395      81.0   \n",
       "\n",
       "   windspeed  casual  registered  count  heure  jour  mois  \n",
       "0        0.0     3.0        13.0   16.0    0.0   1.0   1.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame()\n",
    "df_test = df_test.append(df_analyses.loc[0])\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importance ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17122/3784692671.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mliste_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weather_4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mliste_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "liste_feature.remove(\"weather_4\")\n",
    "liste_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x7f7f8b44adf0>,\n",
       "  <matplotlib.axis.YTick at 0x7f7f8b44a670>,\n",
       "  <matplotlib.axis.YTick at 0x7f7f8bfe4280>,\n",
       "  <matplotlib.axis.YTick at 0x7f7f8b420a30>,\n",
       "  <matplotlib.axis.YTick at 0x7f7f8b42a1c0>,\n",
       "  <matplotlib.axis.YTick at 0x7f7f8b42a910>,\n",
       "  <matplotlib.axis.YTick at 0x7f7f8b39e160>,\n",
       "  <matplotlib.axis.YTick at 0x7f7f8b39e7f0>,\n",
       "  <matplotlib.axis.YTick at 0x7f7f8b42a850>,\n",
       "  <matplotlib.axis.YTick at 0x7f7f8b39e7c0>,\n",
       "  <matplotlib.axis.YTick at 0x7f7f8b398250>,\n",
       "  <matplotlib.axis.YTick at 0x7f7f8b3989a0>,\n",
       "  <matplotlib.axis.YTick at 0x7f7f8b392130>,\n",
       "  <matplotlib.axis.YTick at 0x7f7f8b392880>,\n",
       "  <matplotlib.axis.YTick at 0x7f7f8b38d0d0>,\n",
       "  <matplotlib.axis.YTick at 0x7f7f8b392400>],\n",
       " [Text(0, 0, 'season_1'),\n",
       "  Text(0, 1, 'season_2'),\n",
       "  Text(0, 2, 'season_3'),\n",
       "  Text(0, 3, 'season_4'),\n",
       "  Text(0, 4, 'weather_1'),\n",
       "  Text(0, 5, 'weather_2'),\n",
       "  Text(0, 6, 'weather_3'),\n",
       "  Text(0, 7, 'year_2011'),\n",
       "  Text(0, 8, 'year_2012'),\n",
       "  Text(0, 9, 'temp'),\n",
       "  Text(0, 10, 'humidity'),\n",
       "  Text(0, 11, 'windspeed'),\n",
       "  Text(0, 12, 'heure'),\n",
       "  Text(0, 13, 'month'),\n",
       "  Text(0, 14, 'holiday'),\n",
       "  Text(0, 15, 'workingday')])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l_one_hot = list(model_xgb[0].transformers_[0][1][\"onehotencoder\"].get_feature_names(cat_feature))\n",
    "l_standard = model_xgb[0].transformers_[1][2]\n",
    "l_reminder = [ X_train.columns[i] for i in model_xgb[0].transformers_[2][2] ]\n",
    "\n",
    "liste_feature = l_one_hot + l_standard + l_reminder\n",
    "# a automatiser ???\n",
    "liste_feature.remove(\"weather_4\")\n",
    "\n",
    "xgb_score = model_xgb[1].get_booster().get_fscore()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "y_pos = range(0,len(liste_feature))\n",
    "\n",
    "plt.barh(y_pos,list(xgb_score.values()))\n",
    "plt.yticks(y_pos,liste_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>heure</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.34</td>\n",
       "      <td>62</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.52</td>\n",
       "      <td>74</td>\n",
       "      <td>8.9981</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.70</td>\n",
       "      <td>70</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.70</td>\n",
       "      <td>70</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.70</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  holiday  workingday  weather   temp  humidity  windspeed  heure  \\\n",
       "0       3        0           0        1  30.34        62     7.0015      0   \n",
       "1       3        0           0        1  29.52        74     8.9981      1   \n",
       "2       3        0           0        1  28.70        70    11.0014      2   \n",
       "3       3        0           0        1  28.70        70     7.0015      3   \n",
       "4       3        0           0        1  28.70        70     0.0000      4   \n",
       "\n",
       "   month  year  \n",
       "0      9  2012  \n",
       "1      9  2012  \n",
       "2      9  2012  \n",
       "3      9  2012  \n",
       "4      9  2012  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:11:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:59] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:59] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:59] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:59] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:59] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:59] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:59] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:11:59] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:00] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:00] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "best score : 0.6953075261262058\n",
      "{'xgbregressor__booster': 'gbtree', 'xgbregressor__eta': 0.0001, 'xgbregressor__max_depth': 5, 'xgbregressor__min_child_weight': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\n",
    "    \"xgbregressor__eta\":[0.0001,0.001,0.01,0.1],\n",
    "    \"xgbregressor__max_depth\" : np.arange(1,10,1),\n",
    "    \"xgbregressor__min_child_weight\" : np.arange(1,5,1),\n",
    "    \"xgbregressor__booster\" : [\"gbtree\",\"gblinear\"]\n",
    "\n",
    "}\n",
    "search = GridSearchCV(pip,param_grid)\n",
    "\n",
    "search.fit(X_train,y_train)\n",
    "\n",
    "print(\"best score :\", search.best_score_)\n",
    "print(search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.71067811865476"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"xgbregressor__eta\":[0.0001,0.001,0.01,0.1],\n",
    "    \"xgbregressor__max_depth\" : np.arange(1,10,1),\n",
    "    \"xgbregressor__min_child_weight\" : np.arange(1,10,1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_best = {'xgbregressor__booster': 'gbtree', 'xgbregressor__eta': 0.0001, 'xgbregressor__max_depth': 5, 'xgbregressor__min_child_weight': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(eta=0.0001,max_depth=5)\n",
    "cat_feature = [\"season\",\"weather\",\"year\"]\n",
    "cat_pip = make_pipeline(OneHotEncoder(handle_unknown='ignore'))\n",
    "num_feature = [\"temp\",\"humidity\",\"windspeed\",\"heure\",\"month\"]\n",
    "num_pip = make_pipeline(StandardScaler())\n",
    "preprocessor = make_column_transformer((cat_pip,cat_feature),(num_pip,num_feature),remainder=\"passthrough\")\n",
    "\n",
    "pip = make_pipeline(preprocessor,xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0567959321410183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.3666391521978154"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = pip.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "print(model_xgb.score(X_train,y_train))\n",
    "model_xgb.score(X_test,y_test)\n",
    "\n",
    "#ca ne marche absolument pas"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c31f9a8c3aa1c3c728ca9635375839dde89f8ec10169db463330867a67196863"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
